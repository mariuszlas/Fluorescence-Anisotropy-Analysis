<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>flu_ani_analysis.flu_ani_analysis_module API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>flu_ani_analysis.flu_ani_analysis_module</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import csv
import re
import string
import math
from itertools import product
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.ticker as mtick
from scipy.optimize import curve_fit
import ipywidgets as wg
import warnings
from plate_mapping import plate_mapping as pm

# define custom errors
class DataError(Exception):
    pass

class PlateSizeError(Exception):
    pass

class DataTypeError(Exception):
    pass

# define well plate dimensions
plate_dim = {96:(8, 12), 384:(16, 24)}

# define header names for platemapping module
pm.header_names = {&#39;Well ID&#39;: {&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: False, &#39;short_col&#39;:False},
                &#39;Type&#39;: {&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Contents&#39;: {&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Protein Name&#39;: {&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Protein Concentration&#39;: {&#39;dtype&#39;:float, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Tracer Name&#39;: {&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Tracer Concentration&#39;: {&#39;dtype&#39;:float, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Competitor Name&#39;: {&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Competitor Concentration&#39;: {&#39;dtype&#39;:float, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                &#39;Concentration Units&#39;:{&#39;dtype&#39;:str, &#39;long&#39;:True, &#39;short_row&#39;: True, &#39;short_col&#39;:True},
                }

class FA:
    &#34;&#34;&#34;Class used for the analysis of fluorescence anisotropy data.
    
    :param data_dict: A dictionary contaning data frames with pre-processed data and metadata
    :type data_dict: dict
    :param g_factor: G-factor
    :type g_factor: float 
    :param plate_map: dataframe from a plate map csv file that defines each and every well
    :type plate_map: pandas dataframe
    &#34;&#34;&#34;
    
    def __init__(self, data_dict, g_factor, plate_map):
        self.data_dict = data_dict
        self.g_factor = g_factor
        self.plate_map = plate_map
        
        frames = []   # create list of all p and s data frames

        for repeat in self.data_dict.values():   
            metadata, data = repeat.values()
            p_channel, s_channel = data.values()
            frames.append(p_channel)
            frames.append(s_channel)
    
        new = pd.concat(frames, axis=1)   # join all p and s data frames into one df to run some stats
        nan = new.size - new.describe().loc[&#39;count&#39;].sum()   # find number of &#39;nan&#39; cells
        
        # create a data frame to store the final fitting params
        p_names = self.plate_map[&#39;Protein Name&#39;].dropna().unique()   # get all protein names
        t_names = self.plate_map[&#39;Tracer Name&#39;].dropna().unique()   # get all trcaer names 
        final_fit = pd.DataFrame(index=pd.MultiIndex.from_product([p_names, t_names]), columns=[&#39;rmin&#39;, &#39;rmin error&#39;, &#39;rmax&#39;, &#39;rmax error&#39;, &#39;lambda&#39;, &#39;Kd&#39;, &#39;Kd error&#39;])   # create the final fit df as a class variable
        final_fit[&#34;lambda&#34;] = 1   # set the default lambda value as 1
        FA.final_fit = final_fit   # add the final_fit df as a class vriable
            
        print(&#34;Data has been uploaded!\n&#34;)
        print(f&#34;Value of g-factor: {self.g_factor} \nNumber of repeats: {len(self.data_dict)} \nOverall number of empty cells is {int(nan)} in {len(frames)} data frames.&#34;)
              
              
    @classmethod
    def read_in_envision(cls, data_csv, platemap_csv, data_type=&#39;plate&#39;, size=384):
        &#34;&#34;&#34;Returns a dictionary of data frames, g-factor and platemap needed to construct the class object. 
        
        :param data_csv: File path of the raw data file in .csv format
        :type data_csv: str
        :param platemap_csv: File path of the platemap file in .csv format
        :type platemap_csv: str
        :param data_type: Format in which the raw data was exported (plate or list), defaults to plate
        :type data_type: str
        :param size: Size of the well plate (384 or 96), defaults to 384
        :type size: int
        :return: A dictionary contaning data frames with pre-processed data, g-factor, pandas data frame containing platemap
        :rtype: dict, float, pandas data frame &#34;&#34;&#34;
        
        # ensure the plate size is either 384 or 96
        if size not in plate_dim:
            raise PlateSizeError(&#39;Invalid size of the well plate, should be 384 or 96.&#39;)
        
        # try to read in data in plate format
        if data_type == &#39;plate&#39;:
            try:
                data_dict, g_factor = FA._read_in_plate(data_csv, size=size)
                plate_map_df = pm.plate_map(platemap_csv, size=size)
                return cls(data_dict, g_factor, plate_map_df)
            
            except (UnboundLocalError, IndexError, ValueError):
                raise DataError(f&#34;Error occured during data read in. Check your file contains data in the &#39;plate&#39; format and plate size is {size}.&#34;)
        
        # try to read in data in list format
        if data_type == &#39;list&#39;:
            try:
                data_dict, g_factor = FA._read_in_list(data_csv, size=size)
                plate_map_df = pm.plate_map(platemap_csv, size=size)
                return cls(data_dict, g_factor, plate_map_df)
            
            except (UnboundLocalError, IndexError):
                raise DataError(&#34;Error occured during data read in. Check your file contains data in the &#39;list&#39; format.&#34;)
        
        else:
            raise DataTypeError(f&#34;&#39;{data_type}&#39; is not one of the two valid data types: plate or list.&#34;)
    

    def _read_in_plate(csv_file, size):
        &#34;&#34;&#34;Reads the raw data file and finds the information needed to extract data. Passes those parameters to pre_process_plate function and executes it.
        Returns a tuple of two elemnts: dictionary of data frames and g-factor.

        :param csv_file: File path of the raw data file in .csv format
        :type csv_file: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A tuple of dictionary of data frames and the g-factor 
        :rtype: tuple &#34;&#34;&#34;
        
        with open(csv_file) as file:
            all_data_lines = list(csv.reader(file, delimiter=&#39;,&#39;))   # read the csv file and cast it into a list containing all lines

        blank_indexes = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows
        if blank_indexes == []:
            blank_indexes = list(index for index, item in enumerate(all_data_lines) if set(item) == {&#39;&#39;})
        blanks = np.array(blank_indexes)   # convert the list of blank indices to a numpy array
        read_in_info = []   # list to store the tuples with parameters needed for pandas to read in the csv file

        for index, item in enumerate(all_data_lines):   # iterate over all lines in the csv file
            if item != [] and re.findall(r&#34;Plate information&#34;, item[0]) == [&#39;Plate information&#39;] and re.search(r&#39;Results for&#39;, all_data_lines[index + 9][0]) == None and re.findall(r&#34;Formula&#34;, all_data_lines[index+1][10]) != [&#39;Formula&#39;]:
                skiprows = index + 9   # Set the skiprows parameter for raw data table
                skiprows_meta = index + 1   # Set the skiprows parameter for metadata table
                end_of_data = blanks[blanks &gt; skiprows].min()   # Calculate the end of data table by finding the smallest blank index after the beginning of data table
                read_in_info.append((skiprows, end_of_data - skiprows + 1, skiprows_meta))   # add the skiprows, caculated number of data lines and skiprows for metadata parameters to the list as a tuple
                data_format = &#39;plate1&#39;

            if item != [] and re.findall(r&#34;Plate information&#34;, item[0]) == [&#39;Plate information&#39;] and re.search(r&#39;Results for&#39;, all_data_lines[index + 9][0]) != None:
                skiprows = index + 10
                skiprows_meta = index + 1
                end_of_data = blanks[blanks &gt; skiprows].min()
                read_in_info.append((skiprows, end_of_data - skiprows - 1, skiprows_meta))
                data_format = &#39;plate2&#39;

            if item != [] and len(item) &gt; 1 and re.fullmatch(r&#34;G-factor&#34;, item[0]):
                g_factor = float(item[4])   
        
        return FA._pre_process_plate(csv_file, read_in_info, data_format, size), g_factor

    def _pre_process_plate(csv_file, read_in_info, data_format, size):    
        &#34;&#34;&#34;Extracts the data and metadata from the csv file, processes it and returns a nested dictionary containing data and metadata for each repeat and channel.

        :param csv_file: File path of the raw data file in .csv format
        :type csv_file: str
        :param read_in_info: Tuples with read in parameters for each channel.
        :type read_in_info: list
        :param data_format: Plate type (plate1 or plate2)
        :type data_format: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A dictionary containing data and metadata 
        :rtype: dict &#34;&#34;&#34; 
        
        data_frames = {}   # dictionary to store data frames
        counter = 1   # counter incremented by 0.5 to enable alternating labelling of data frames as &#39;p&#39; or &#39;s&#39;

        row_letters = list(string.ascii_uppercase)[0: plate_dim[size][0]]   # generate a list of letters for well IDs
        col_numbers = list(np.arange(1, plate_dim[size][1] + 1).astype(str))   # generate a list of numbers for well IDs
        well_ids = [&#39;%s%s&#39; % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the pre-processed data frames
        
        for index, item in enumerate(read_in_info):   # iterate over all tuples in the list, each tuple contains skiprows, nrows and skiprows_meta for one channel 

            if data_format == &#39;plate1&#39;:   # raw data table does not have row and column names so &#39;names&#39; parameter passed to omit the last column
                raw_data = pd.read_csv(csv_file, sep=&#39;,&#39;, names=col_numbers, index_col=False, engine=&#39;python&#39;, skiprows=item[0], nrows=item[1], encoding=&#39;utf-8&#39;)

            if data_format == &#39;plate2&#39;:   # raw data table has row and column names, so index_col=0 to set the first column as row labels
                raw_data = pd.read_csv(csv_file, sep=&#39;,&#39;, index_col=0, engine=&#39;python&#39;, skiprows=item[0], nrows=item[1], encoding=&#39;utf-8&#39;)
                if len(raw_data.columns) in [13, 25]:    
                    raw_data.drop(raw_data.columns[-1], axis=1, inplace=True)    # delete the last column because it is empty

            # generate df for metadata (number of rows of metadata table is always 1) and convert measurement time into datetime object   
            metadata = pd.read_csv(csv_file, sep=&#39;,&#39;, engine=&#39;python&#39;, skiprows=item[2], nrows=1, encoding=&#39;utf-8&#39;).astype({&#39;Measurement date&#39;: &#39;datetime64[ns]&#39;})
            # convert and reshape data frame into 1D array
            data_as_array = np.reshape(raw_data.to_numpy(), (int(size), 1)) 

            if counter % 1 == 0: 
                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=[&#39;p&#39;])   # generate new 384 (or 96) by 1 data frame with p channel data
                data_frames[f&#39;repeat_{int(counter)}&#39;] = {&#39;metadata&#39;:metadata, &#39;data&#39;: {&#39;p&#39;: new_data, &#39;s&#39;:&#39;&#39;}}   # add p channel data and metadata dfs to dictionary

            if counter % 1 != 0:
                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=[&#39;s&#39;])   # generate new 384 (or 96) by 1 data frame with s channel data
                data_frames[f&#39;repeat_{int(counter-0.5)}&#39;][&#39;data&#39;][&#39;s&#39;] = new_data   # add s channel data to dictionary

            counter = counter + 0.5
        
        return data_frames


    def _read_in_list(csv_file, size):
        &#34;&#34;&#34;Reads the raw data file and extracts the data and metadata. Passes the raw data to pre_process_list function and executes it.
        Returns a tuple of two elemnts: dictionary of data frames and g-factor.

        :param csv_file: File path of the raw data file in .csv format
        :type csv_file: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A tuple of dictionary of data frames and the g-factor
        :rtype: tuple &#34;&#34;&#34;

        with open(csv_file) as file:  
            all_data_lines = list(csv.reader(file, delimiter=&#39;,&#39;)) # read the csv file and cast it into a list containing all lines
 
        blank_indexes = list(index for index, item in enumerate(all_data_lines) if item == [] or set(item) == {&#39;&#39;})   # list containing indexes of all blank rows
        blanks = np.array(blank_indexes)   # convert the list of blank indexes to a numpy array
        
        # iterate over all lines to find beggining of the data table (&#39;skiprows&#39;) and determine the format of data  (list A, B, or C)
        for index, item in enumerate(all_data_lines):   
            if item != [] and len(item) == 1 and re.findall(r&#34;Plate information&#34;, item[0]) == [&#34;Plate information&#34;]:
                skiprows_meta = index + 1
                end_of_metadata = blanks[blanks &gt; skiprows_meta].min()   # find the end of metadata by finding the smallest blank index after the beginning of metadata
                
            if item != [] and len(item) &gt;= 2 and re.findall(r&#34;PlateNumber&#34;, item[0]) == [&#39;PlateNumber&#39;] and re.findall(r&#34;PlateRepeat&#34;, item[1]) == [&#39;PlateRepeat&#39;]:   # find line number with the beggining of the data
                skiprows = index - 1
                data_format = &#39;listA&#39;
                end_of_data = blanks[blanks &gt; skiprows].min()

            if item != [] and len(item) &gt;= 2 and re.findall(r&#34;Plate&#34;, item[0]) == [&#39;Plate&#39;] and re.findall(r&#34;Barcode&#34;, item[1]) == [&#39;Barcode&#39;]:   # find line number with the beggining of the data
                skiprows = index
                data_format = &#39;listB&#39;
                end_of_data = blanks[blanks &gt; skiprows].min()

            if item != [] and len(item) &gt;= 2 and re.findall(r&#34;Plate&#34;, item[0]) == [&#39;Plate&#39;]  and re.findall(r&#34;Well&#34;, item[1]) == [&#39;Well&#39;]:
                skiprows = index
                data_format = &#39;listC&#39;
                end_of_data = blanks[blanks &gt; skiprows].min()

            if item != [] and re.fullmatch(r&#34;G-factor&#34;, item[0]):   # find the g factor
                g_factor = float(item[4])

        nrows = end_of_data - skiprows - 1   # calculate the length of data table
        nrows_meta = end_of_metadata - skiprows_meta - 1   # calucalte the length of metadata table (number of rows depends on the number of repeats)

        raw_data = pd.read_csv(csv_file, sep=&#39;,&#39;, engine=&#39;python&#39;, skiprows=skiprows, nrows=nrows, encoding=&#39;utf-8&#39;)
        raw_metadata = pd.read_csv(csv_file, sep=&#39;,&#39;, engine=&#39;python&#39;, skiprows=skiprows_meta, nrows=nrows_meta, encoding=&#39;utf-8&#39;)

        return FA._pre_process_list(raw_data, raw_metadata, data_format, size), g_factor

    def _pre_process_list(raw_data, raw_metadata, data_format, size):
        &#34;&#34;&#34;Extracts the data and metadata for each channel and repeat from the raw data and raw metadata 
        and returns a nested dictionary containing data and metadata for each repeat and channel.

        :param raw_data: Data frame containing raw data
        :type raw_data: pandas data frame
        :param raw_metadata: Data frame containing raw metadata
        :type raw_metadata: pandas data frame
        :param data_format: Type of list (listA, listB, or listC)
        :type data_format: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A dictionary containing data and metadata
        :rtype: dict&#34;&#34;&#34;

        # remove the &#39;0&#39; from middle position of well numbers (A01 -&gt; A1), done by reassigning the &#39;Well&#39; column to a Series containing modified well numbers
        raw_data[&#39;Well&#39;] = raw_data[&#39;Well&#39;].apply(lambda x: x[0] + x[2] if x[1] == &#39;0&#39; else x)
        
        data_frames = {}   # dictionary to store data frames
        repeats = list(raw_metadata[&#39;Repeat&#39;].to_numpy())   # generate a list with repeats based on the metadata table, e.g. for 3 repeats -&gt; [1,2,3]

        row_letters = list(string.ascii_uppercase)[0: plate_dim[size][0]]   # generate a list of letters for well IDs
        col_numbers = list(np.arange(1, plate_dim[size][1] + 1).astype(str))   # generate a list of numbers for well IDs
        well_ids = [&#39;%s%s&#39; % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the pre-processed data frames
        
        for index, repeat in enumerate(repeats):   # iterate over the number of repeats
            if data_format == &#39;listA&#39;:
                groupped_data = raw_data.groupby(raw_data.PlateRepeat).get_group(repeat)   # group and extract the data by the plate repeat column, i.e. in each iteration get data only for the current repeat 

                p_groupped = groupped_data.iloc[::3, :]   # extract data only for the p channel, i.e. each third row starting from the first row
                s_groupped = groupped_data.iloc[1::3, :]   # extract data only for the s channel, i.e. each third row starting from the second row

                p_raw_data = p_groupped[[&#39;Well&#39;, &#39;Signal&#39;]]   # extract only the two relevant columns
                s_raw_data = s_groupped[[&#39;Well&#39;, &#39;Signal&#39;]]   # for each channel

            if data_format in [&#39;listB&#39;, &#39;listC&#39;]: 
                # the column naming is different for the first repeat (&#39;Signal&#39;), then it&#39;s &#39;Signal.1&#39;, &#39;Signal.2&#39;, etc.
                if repeat == 1: 
                    p_raw_data = raw_data[[&#39;Well&#39;, &#39;Signal&#39;]]   
                    s_raw_data = raw_data[[&#39;Well&#39;, f&#39;Signal.{repeat}&#39;]]
                else:
                    p_raw_data = raw_data[[&#39;Well&#39;, f&#39;Signal.{repeat + index - 1}&#39;]]   # the column cotntaining data to be extracted is calculated in each iteration
                    s_raw_data = raw_data[[&#39;Well&#39;, f&#39;Signal.{repeat + index}&#39;]]
            
            # create an empty df with no columns and indexes matching the plate size
            indexes = pd.DataFrame(well_ids, columns=[&#39;Wells&#39;])
            empty_frame = indexes.set_index(&#39;Wells&#39;)
            
            p_raw_data.set_index(&#39;Well&#39;, inplace=True)   # set the row indexes as the well numbers
            p_raw_data.set_axis([&#39;p&#39;], axis=1, inplace=True)   # rename the &#39;Signal&#39; column to &#39;p&#39;
            p_data = empty_frame.join(p_raw_data)   # join the raw data df to an empty frame based on the indexes, assigns &#39;NaN&#39; to indexes not present in the raw data table
            
            s_raw_data.set_index(&#39;Well&#39;, inplace=True) 
            s_raw_data.set_axis([&#39;s&#39;], axis=1, inplace=True)
            s_data = empty_frame.join(s_raw_data)
    
            metadata = raw_metadata.iloc[[repeat-1]].astype({&#39;Measurement date&#39;: &#39;datetime64[ns]&#39;})   # extract the row with metadata relevant for each repeat and covert date and time into a datetime object
            data_frames[f&#39;repeat_{repeat}&#39;] = {&#39;metadata&#39;: metadata, &#39;data&#39;: {&#39;p&#39;: p_data, &#39;s&#39;: s_data}}   # add data frames to the dictionary

        return data_frames
    
    
    def visualise(self, colorby=&#39;Type&#39;, labelby=&#39;Type&#39;, title=&#34;&#34;, cmap=&#39;Paired&#39;, dpi=250, export=False):
        &#34;&#34;&#34;Returns a visual representation of the plate map.
        The label and colour for each well can be customised to be a variable, for example &#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;, etc.
        It can also be the p or s anisotropy value from a specified repeat passed as a tuple of strings, for example (&#39;repeat_2&#39;, &#39;p&#39;) for p data from repeat 2
        
        :param colorby: Chooses the parameter to color code by, for example &#39;Type&#39;, &#39;Contents&#39;, &#39;Protein Concentration&#39;, (&#39;repeat_2&#39;, &#39;p&#39;), default = &#39;Type&#39;
        :type colorby: str or tuple
        :param labelby: Chooses the parameter to label code by, for example &#39;Type&#39;, &#39;Contents&#39;, &#39;Protein&#39;, (&#39;repeat_1&#39;, &#39;s&#39;), default = &#39;Type&#39;
        :type labelby: str or tuple
        :param title: Sets the title of the figure, default none
        :type title: str
        :param cmap: Sets the colormap for the color-coding, default = &#39;Paired&#39;
        :type cmap: str
        :param dpi: Size of the figure, default = 250
        :type dpi: int
        :param export: If &#39;True&#39; a .png file of the figure is saved, default = False
        :type export: bool
        :return: Visual representation of the plate map.
        :rtype: figure
        &#34;&#34;&#34;
        plate_map = self.plate_map
        size = plate_map.shape[0]
        scinot = False
        str_len = None
        
        if type(labelby) == tuple:   # option for labelling by the p or s anisotropy values
            plate_map = self.plate_map.join(self.data_dict[labelby[0]][&#39;data&#39;][labelby[1]])   # data frame containing p or s values from specified repeat is added to the platemap
            labelby = labelby[1]
        if type(colorby) == tuple:   # option for colouring by the p or s anisotropy values
            plate_map = plate_map.join(self.data_dict[colorby[0]][&#39;data&#39;][colorby[1]])
            colorby = colorby[1]
            
        if labelby in [&#39;Protein Concentration&#39;, &#39;Tracer Concentration&#39;, &#39;Competitor Concentration&#39;, &#39;p&#39;, &#39;s&#39;, &#39;p_corrected&#39;, &#39;s_corrected&#39;, &#39;r_raw&#39;, &#39;r_corrected&#39;, &#39;i_raw&#39; , &#39;i_corrected&#39;]:
            if sum((plate_map[labelby] &gt; 1000) | (plate_map[labelby] &lt; 0)) &gt; 0:   # display in sci notation if the number is greater than 1000 or less than 0
                scinot = True
                str_len = 8
        
        return pm.visualise(platemap=plate_map, title=title, size=size, export=export, cmap=cmap, colorby=colorby, labelby=labelby, dpi=dpi, scinot=scinot, str_len=str_len)
    
    def invalidate(self, valid=False, **kwargs):
        &#34;&#34;&#34;Invalidates wells, columns and/or rows. Any of the following arguments, or their combination, can be passed: wells, rows, columns. 
        For example to invalidate well A1, rows C and D and columns 7 and 8 execute the following: invalidate(wells=&#39;A1&#39;, rows=[&#39;C&#39;,&#39;D&#39;], columns=[7,8]).
        To validate previously invalidated wells, rows and/or columns, pass the additional &#39;valid&#39; argument as True.
    
        :param valid: Sets the stipulated row or rows &#39;True&#39; or &#39;False&#39;, default = False
        :type valid: bool
        :param wells: Wells to be invalidated passed as a string or a list of strings
        :type wells: str or list
        :param rows: Rows to be invalidated passed as a string or a list of strings
        :type rows: str or list
        :param columns: Columns to be invalidated passed as an integer or a list of integers
        :type columns: int or list
        &#34;&#34;&#34;
        # execute the corresponding invalidate functon from the platemapping package
        if &#39;wells&#39; in kwargs:
            pm.invalidate_wells(platemap=self.plate_map, wells=kwargs[&#39;wells&#39;], valid=valid)
        if &#39;rows&#39; in kwargs:
            rows = tuple(kwargs[&#39;rows&#39;]) # convert the rows to tuple because invalidate_rows cannot take in a list
            pm.invalidate_rows(platemap=self.plate_map, rows=rows, valid=valid)
        if &#39;columns&#39; in kwargs:
            pm.invalidate_cols(platemap=self.plate_map, cols=kwargs[&#39;columns&#39;], valid=valid)
        if len(kwargs) == 0:   # return error if neither of the keyword arguments is passed
            raise TypeError(&#39;No arguments were passed. Specify the wells, rows and/or columns to be invalidated!&#39;)
      
    
    def background_correct(self):
        &#34;&#34;&#34;Calculate background corrected values for p and s channel in all repeats.
        
        Cacluclated by subtracting the mean value of blank p or s for a given concentration from each value of compound p or s for that concentration.&#34;&#34;&#34;
        
        for key, value in self.data_dict.items(): 
            metadata, data = value.values()   

            # create joined dfs of platemap and p or s
            p_df = self.plate_map.join(data[&#39;p&#39;])  
            s_df = self.plate_map.join(data[&#39;s&#39;])
            
            # calculate p and s corrected and add them to data dictionary
            self.data_dict[key][&#39;data&#39;][&#39;p_corrected&#39;] = FA._backg_correct(p_df, &#39;p_corrected&#39;)
            self.data_dict[key][&#39;data&#39;][&#39;s_corrected&#39;] = FA._backg_correct(s_df, &#39;s_corrected&#39;)
            
            print(&#39;Background correction has been successfully performed!&#39;)
            
    def _backg_correct(df, col_name):
        &#34;&#34;&#34;Calculate background corrected p or s.
        
        :param df: Joined platemap and raw p or s values 
        :type df: pandas df
        :param col_name: Name of the column with background corrected values
        :type col_name: str
        :return: Data frame with background corrected p or s values (depending on col_name parameter)
        :rtype: pandas df&#34;&#34;&#34;
        
        df[df.columns[-1]] = df[df.columns[-1]][df[&#39;Valid&#39;] == True]   # &#39;p&#39; or &#39;s&#39; values are replaced with NaN if the well is invalidated
        no_index = df.reset_index()   # move the index to df column
        mindex = pd.MultiIndex.from_frame(no_index[[&#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;]])   # create multiindex
        reindexed = no_index.set_index(mindex).drop([&#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;], axis=1)   # add multiindex to df and drop the columns from which multiindex was created
    
        mean = reindexed.groupby(level=[0,1,2]).mean().drop(&#39;Valid&#39;, axis=1)   # calculate mean for each group of three wells and remove &#39;Valid&#39; column
        mean.rename(columns={mean.columns[-1]: &#39;Mean&#39;}, inplace=True)   # rename the last column to &#39;Mean
        blank = mean.xs(&#39;blank&#39;, level=0, drop_level=True)   # take a group with blank wells
        
        joined = reindexed.join(blank, on=[&#39;Protein Name&#39;, &#39;Protein Concentration&#39;])
        joined[col_name] = joined[joined.columns[-2]] - joined[&#39;Mean&#39;]   # calculate background corrected values
        jindexed = joined.set_index(&#39;index&#39;, append=True).reset_index(level=[0,1,2]).rename_axis(None)   # set index to &#39;well id&#39; and move multiindex to df columns
        return jindexed[[col_name]]
    
    
    def calculate_r_i(self, correct=True, plot_i=True, thr=80):
        &#34;&#34;&#34;Calculates anisotropy and fluorescence intensity.
        The fluorescence intensity (I) and anisotropy (r) are calculated using the follwing formulas: I = s + (2*g*p), r = (s - (g*p)) / I and stored 
        in data_dict as i_raw and r_raw (calculated using the uncorrected p and s channel values) 
        and i_corrected and r_corrected (if calculated using the background corrected p and s channel values, as well).
        
        :param correct: Calculate the anisotropy and intensity using the background corrected values of p and s, as well, default=True
        :type correct: bool
        :param plot_i: Displays plots of the percentage intensity against well ids for all repeats, defaults to True
        :type plot_i: bool
        :param th: Percentage intensity value above which the wells id will be reported
        :type th: int
        &#34;&#34;&#34;
        FA.th = thr   # assign the threshold value to the class variable so that it can be accessed outside of this function
    
        for key, value in self.data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            
            # calculate raw intensity and anisotropy and add them to data dictionary
            i, r = FA._calc_r_I(data[&#39;p&#39;], data[&#39;s&#39;], self.g_factor, &#39;raw&#39;)
            self.data_dict[key][&#39;data&#39;][&#39;i_raw&#39;] = i   
            self.data_dict[key][&#39;data&#39;][&#39;r_raw&#39;] = r   
            
            if correct:   # calculate intensity and anisotropy using background corrected values of p and s
                if &#39;p_corrected&#39; and &#39;s_corrected&#39; not in data:   # check if background subtraction has been done
                    raise AttributeError(&#39;The corrected anisotropy and intensity can only be calculated after background correction of the raw p and s channel data.&#39;)
                
                i_c, r_c = FA._calc_r_I(data[&#39;p_corrected&#39;], data[&#39;s_corrected&#39;], self.g_factor, &#39;corrected&#39;)
                self.data_dict[key][&#39;data&#39;][&#39;i_corrected&#39;] = i_c   
                self.data_dict[key][&#39;data&#39;][&#39;r_corrected&#39;] = r_c    
                
                self.data_dict[key][&#39;data&#39;][&#39;i_percent&#39;] = FA._calc_I_percent(i, i_c, self.plate_map)
        
        print(&#39;The fluorescence intensity and anisotropy have been successfully calculated!\n&#39;)
        
        if plot_i:   # plot the percentage intensity against the well ids for all repeats
            FA._plot_i_percent(self.data_dict, self.plate_map)

    def _calc_r_I(p, s, g, col_suffix):
        &#34;&#34;&#34;Calculates either anisotropy or intensity and labels the resulting dfs according to the parameters passed
        
        :param p: Pandas data frame with p channel data (can be both raw and background corrected)
        :type p: pandas df 
        :param s: Pandas data frame with s channel data (can be both raw and background corrected)
        :type s: pandas df
        :param g: G-factor
        :type g: float
        :param col_suffix: Suffix to add to column name of the resulting intensity or anisotropy data frame, e.g. &#39;raw&#39;, &#39;corrected&#39;
        :type col_suffix: str
        :return: Data frames with calculated anisotropy and intensity values
        :rtype: pandas df&#34;&#34;&#34;
        
        p_rn = p.rename(columns={p.columns[0]: s.columns[0]})   # rename the col name in p data frame so that both p and s dfs have the same col names to enable calculation on dfs
        i = s + (2 * g * p_rn)       # calculate intensity
        r = (s - (g * p_rn)) / i     # and anisotropy
        i_rn = i.rename(columns={i.columns[0]: &#39;i_&#39;+col_suffix})   # rename the col name using the column suffix argument
        r_rn = r.rename(columns={r.columns[0]: &#39;r_&#39;+col_suffix})           
        return i_rn, r_rn  
    
    def _calc_I_percent(ir, ic, platemap):
        &#34;&#34;&#34;Calculate the percentage intensity of blank wells compared to non-blank wells.
        
        :param ir: Data frame with corrected intensity 
        :type ir: pandas df
        :param ic: Data frame with raw intensity
        :type ic: pandas df
        :param platemap: Platemap
        :type platemap: pandas df
        :return: df containing only the non-blank and non-empty columns
        :rtype: pandas df&#34;&#34;&#34;
        
        ir_rn = ir.rename(columns={ir.columns[0]:ic.columns[0]})   # rename the col name in raw intensity df so that it&#39;s the same as in corrected intensity df
        percent = (ir_rn - ic)/ir_rn * 100   
        percent.rename(columns={&#39;i_corrected&#39;:&#39;i_percent&#39;}, inplace=True)
        joined = platemap.join(percent)   # join the percent data to platemap
        return joined[[&#39;i_percent&#39;]]
        
    def _plot_i_percent(data_d, platemap):
        &#34;&#34;&#34;Plot the percentage intensity against the well ids with a horizotanl threshold bar and preint the list of wells above the threshold for all repeats
        
        :param data_d: Dictionary with data for all repeats
        :type data_d: dict &#34;&#34;&#34;
        
        st = &#39;&#39;   # empty string to which lists of wells to be printed are appended after checking data from each repeat
        fig = plt.figure(figsize=(8*int((len(data_d) + 2 - abs(len(data_d) - 2))/2), 4*int( math.ceil((len(data_d))/2)) ), tight_layout=True)   # plot a figure with variable size depending on the number subplots (i.e. repeats)
        #fig.suptitle(&#39;The percentage intensity of a non-blank well was plotted for all repeats&#39;, fontsize=14)   # add the figure title
        
        for key, value in data_d.items():   # iterate over all repeats
            metadata, data = value.values()
            df = platemap.join(data[&#39;i_percent&#39;])
            df_per = df[(df[&#39;Type&#39;] != &#39;blank&#39;) &amp; (df[&#39;Type&#39;] != &#39;empty&#39;)]   # subset only the non-blank and non-empty columns
            
            plt.subplot(int( math.ceil((len(data_d))/2) ), int( (len(data_d) + 2 - abs(len(data_d) - 2))/2 ), int(key[-1]))
            plt.bar(df_per.index, df_per[&#39;i_percent&#39;])   # plot a bar plot with intensity percentage data 
            plt.axhline(FA.th, color=&#39;red&#39;)   # plot a horizontal line representing the threshold on the bar plot
            ax = plt.gca()   # get the axis object
            ax.set_ylabel(&#39;&#39;)
            ax.set_xlabel(&#39;wells&#39;)
            ax.set_title(key)
            ax.yaxis.set_major_formatter(mtick.PercentFormatter())   # set formatting of the y axis as percentage
            xlabels = [i if len(i) == 2 and i[1] == &#39;1&#39; else &#39;&#39; for i in list(df_per.index)]   # create a list of xtics and xticklabels consiting only of the first wells from a each row
            ax.set_xticks(xlabels)
            ax.set_xticklabels(xlabels)
        
            wells = list(df_per[df_per[&#39;i_percent&#39;] &gt; FA.th].index)   # get a list of well ids above the threshold for this repeat
            if wells != []:   # append wells above the threshold and the repective repeat number to the string with appropriate formatting
                st = st + f&#39;\t{key}: {str(wells)}\n&#39;
        
        plt.show()   # ensure the figure is displayed before printing the summary message

        if st != &#39;&#39;:   # display the summary of wells above the threshold
            print(f&#39;In the following wells the percentage intensity value was above the {FA.th}% threshold:&#39;)
            print(st)
        else:
            print(f&#39;None of the wells has the percentage intensity value above the {FA.th}% threshold.&#39;)
            
    def plot_i_percent(self):
        &#34;&#34;&#34;This function only displays the results calculated by the calculate_r_i function and does not recalculate it.&#34;&#34;&#34;
        return FA._plot_i_percent(self.data_dict, self.plate_map)
    
    
    def calc_data_to_fit(self):
        &#34;&#34;&#34;Calculates data required for fitting a curve to the plot of anisotropy (or intensity) against protein concentration.
        The following data is calcualted for both intensity and anisotropy for all repeats: mean, standard devition and standard error.
        
        Data frames for storing fitting parametres for each repeat (&#39;fit_params&#39;) and a data frame for storing
        final values of rmin, rmax and lambda for each protein-tracer pair are created.
        &#34;&#34;&#34;
        for key, value in self.data_dict.items():
            metadata, data = value.values()
               
            data[&#39;r_mean&#39;] = FA._fitting_data(data[&#39;r_corrected&#39;], self.plate_map)   # create dictionary &#39;r_mean&#39; with mean anisotropy data frames for each protein-tracer pair
            data[&#39;i_mean&#39;] = FA._fitting_data(data[&#39;i_corrected&#39;], self.plate_map)   # create dictionary &#39;i_mean&#39; with mean intensity data frames for each protein-tracer pair
            # create data frame for storing the fitting params 
            data[&#39;fit_params&#39;] = pd.DataFrame(index=FA.final_fit.index, columns=[&#39;rmin&#39;,&#39;rmin error&#39;, &#39;rmax&#39;, f&#39;rmax error&#39;, &#39;r_EC50&#39;, &#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;, &#39;Ifree&#39;, &#39;Ifree error&#39;, &#39;Ibound&#39;, &#39;Ibound error&#39;, &#39;I_EC50&#39;, &#39;I_EC50 error&#39;, &#39;I_hill&#39;, &#39;I_hill error&#39;, &#39;lambda&#39;])   # create new df for storing the fitting parameters
            data[&#39;fit_params&#39;][&#39;lambda&#39;] = 1
       
    def _fitting_data(df, plate_map):
        &#34;&#34;&#34;Calculates mean anisotropy for each protein concentration value, its standard deviation and standard error.
        Creates an empty data frame for storing the fitting parameters for each repeat and sets the lambda value as 1.
        
        :param df: Data frame with anisotropy or intensity values
        :type df: pandas df
        :param plate_map: Plate map data frame
        :type plate_map: pandas df
        :return: A dictionary with data frames for each unique protein-tracer pair and data frame for storing the fitting parameter
        :rtype: tuple (dict, pandas df)&#34;&#34;&#34;
        
        join = plate_map.join(df)   # join anisotropy values to platemap
        subset = join[(join[&#39;Type&#39;] != &#39;blank&#39;) &amp; (join[&#39;Type&#39;] != &#39;empty&#39;)]   # take only non-blank and non-empty cells
        noidx = subset.reset_index()
        group = noidx.groupby([&#39;Protein Concentration&#39;, &#39;Protein Name&#39;, &#39;Tracer Name&#39;])
        mean = group.mean()   
        std = group.std()     
        sem = group.sem()    
        meanr = mean.rename(columns={mean.columns[-1]: &#39;mean&#39;})
        stdr = std.rename(columns={std.columns[-1]: &#39;std&#39;}).drop(&#39;Valid&#39;, axis=1)   # rename the std column and remove the &#39;Valid&#39; column
        semr = sem.rename(columns={sem.columns[-1]: &#39;sem&#39;}).drop(&#39;Valid&#39;, axis=1)   # rename the sem column and remove the &#39;Valid&#39; column
        merge = pd.concat([meanr, stdr, semr], axis=1)
        tosplit = merge.reset_index()   # remove multiindex
        split = dict(tuple(tosplit.groupby([&#39;Protein Name&#39;, &#39;Tracer Name&#39;])))   # split df based on multiindex so that a new df is created for each unique combination of protein and tracer
        
        return split
            
    def calc_lambda(self, approve=True):
        &#34;&#34;&#34;Calculates lambda value for each protein-tracer pair for all repeats. 

        If &#39;approve=True&#39;, a list with calcualted lambda values with checkboxes will be displayed. To approve the proposed value 
        tick the selected checkboxes and click &#39;Update&#39; button. If &#39;approve=False&#39;, all of the calculated values will be saved and 
        the list with checkboxes will not be displayed. You can still amend any values in the fitting parameters data frame using the &#39;set_fitparams function.

        :param approve: If True a list of checkboxes will be displayed to choose the lambda values that will be saved, default True
        :type approve: bool
        :return: If approve=True, return a list of calculated lambda values along with checkboxes to be approved, 
        else save the calulated lambda values in the fitting params data frames for each repeat 
        &#34;&#34;&#34;
        w_info = []   # list of tuples with info (rep no, lambda value, etc) for generation of widgets
        
        for key, value in self.data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            df = data[&#39;fit_params&#39;].copy()    # create a copy of the fitting params df
            df[&#39;lambda&#39;] = df[&#39;Ibound&#39;]/df[&#39;Ifree&#39;]   # calculate the lambda value in a copied data frame
            
            if approve == False:   # if the user does not want to manually approve the proposed values
                self.data_dict[key][&#39;data&#39;][&#39;fit_params&#39;][&#39;lambda&#39;] = df[&#39;lambda&#39;]   # add the lambda values to fitting params df
                print(&#39;The lambda values were calculated and saved.&#39;)
            else:
                indexes = list(df.index)   # create list of tuples with protein-tracer names
                for item in indexes:   # iterate over each protein-tracer pair and create tuples with info needed for generation of widgets
                    rating = 100
                    tp = (key, item, rating, df.loc[item, &#34;lambda&#34;],  data[&#39;fit_params&#39;].loc[item, &#34;rmin&#34;],  data[&#39;fit_params&#39;].loc[item, &#34;rmax&#34;])   # tuples conataining repeat no., calculated lambda, and protein-tracer names
                    w_info.append(tp)

        if approve == True:   # execute the function for displying and handling the widgets
            return FA._widget(self.data_dict, w_info, df)
            
    def _widget(data_dict, w_info, df):
        &#34;&#34;&#34;Function for generating and displaying the widgets with lambda values.
        It generates widgets for each tuple in the w_info list.
        
        :param data_dict: Data dictionary with all repeats
        :type data_dict: dict
        :param w_info: A list of tuples containg information needed for the generation of widgets
        :type w_info: list
        :param df: Data frame with calculated lambda values
        :type df: pandas df
        &#34;&#34;&#34;
        w_info.sort(key=lambda x: x[1])   # sort the tuples by the protein name so that the widgets are displayed by protein-tracer name
        reps = [wg.HTML(f&#34;{i[0]}&#34;) for i in w_info]   # list of text widgets with repeat numbres
        proteins = [wg.HTML(f&#34;{i[1][0]}&#34;) for i in w_info]   # list of text widgets with protein names
        tracers = [wg.HTML(f&#34;{i[1][1]}&#34;) for i in w_info]   # list of text widgets with tracer names
        scores = [wg.HTML(f&#34;Score: {i[2]}&#34;) for i in w_info]   
        lambdas = [wg.Checkbox(value=False, description=&#34;lambda=%.4f&#34; % (i[3])) for i in w_info]   # list of checkbox widgets with lambda values
        rminmax = [wg.Checkbox(value=False, description=&#34;rmin=%.5f, rmax=%.5f&#34; % (i[4], i[5])) for i in w_info]   # list of checkbox widgets with rmin and rmax values
            
        v_lambdas = wg.VBox(lambdas)   # group all lambda checkbox widgets into a vertical list layout
        v_proteins = wg.VBox(proteins)   # group all protein name widgets into a vertical list layout
        v_tracers = wg.VBox(tracers)   # group all tracer name widgets into a vertical list layout
        v_reps = wg.VBox(reps)   # group all repeat number widgets into a vertical list layout
        v_scores = wg.VBox(scores)
        v_rminmax = wg.VBox(rminmax)   # group all rmin and rmax checkbox widgets into a vertical list layout
            
        hbox = wg.HBox([v_proteins, v_tracers, v_reps, v_scores, v_lambdas, v_rminmax])   # arrange the six vertical boxes into one widget box&#39;
        button = wg.Button(description=&#39;Save&#39;)   # create a button for saving the selected values
        print(&#34;&#34;&#34;Choose the lambda values that will be saved for each protein-tracer pair. \nIf you choose more than one lambda value for a given protein-tracer pair, only the first choice will be saved.\nIf you do not choose any lambda value for a given protein-trcacer pair, then you have select the rmin and rmax for this pair.&#34;&#34;&#34;)
        display(hbox, button)   # display the box with widgets and the button
            
        def btn_eventhandler(obj): 
            &#34;&#34;&#34;Function that is executed when the &#39;Save&#39; button is clicked. It checks which checkboxes were ticked and 
            updates the final fit df with the calcualted lambda values and/or rmin and rmax values. 
            Only the first value of lambda for a given protein-tracer will be saved.
            &#34;&#34;&#34;
            added_lambda = []   # protein-tracer pairs for which lambda values were added
            added_rminmax = []   # protein-tracer pairs for which rmin and rmax values were added
            
            for i in range(0, len(lambdas)):   # iterate over each checkbox widget
                index = (proteins[i].value, tracers[i].value)   # get the tuple with protein-tracer names
                
                if lambdas[i].value == True:   # if the lambda checkbox was ticked, the widget&#39;s &#39;value&#39; attribute is True 
                    if index not in added_lambda:   # if lambda for this protein-tracer pair has not yet been added 
                        FA.final_fit.loc[index, &#34;lambda&#34;] = df.loc[index, &#34;lambda&#34;]   # add the calculated lambda to the final_fit d
                        FA.final_fit.loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]] = data_dict[reps[i].value][&#39;data&#39;][&#39;fit_params&#39;].loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]]   #add rmin, rmax and their errors to the final_fit df
                        added_lambda.append(index)  
                        
                if rminmax[i].value == True:
                    if index not in added_lambda and index not in added_rminmax:   # if neither lambda nor rmin/rmax for this protein-tracer pair have been added 
                        FA.final_fit.loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]] = data_dict[reps[i].value][&#39;data&#39;][&#39;fit_params&#39;].loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]]
                        added_rminmax.append(index)
            
            print(&#39;Selected values were saved.&#39;)
        button.on_click(btn_eventhandler)   #link the button event handler function with actual clicking of the button using &#39;on_click&#39; function
        
    
    def _amount_bound(df, platemap, final_fit):

        join_pm = platemap.join(df)   # join df with corrected anisotropy to the platemap df
        subset = join_pm[(join_pm[&#39;Type&#39;] != &#39;blank&#39;) &amp; (join_pm[&#39;Type&#39;] != &#39;empty&#39;)]   # take only non-blank and non-empty wells

        re_idx = subset.set_index(pd.MultiIndex.from_frame(subset[[&#39;Protein Name&#39;, &#39;Tracer Name&#39;]])).rename_axis([None,None])   # replace the index with multiindex (protein-tracer name) and remove its names
        join_ff = re_idx.join(final_fit)   # join the final fitting parameters to the anisotropy df on multiindex (protein-tracer)

        # calcualte the amount bound (all parameters needed are already in the data frame)
        join_ff[&#39;amount&#39;] = (((((join_ff[&#34;lambda&#34;] * (join_ff[&#39;rmax&#39;]-join_ff[&#39;r_corrected&#39;])) / (join_ff[&#39;r_corrected&#39;] - join_ff[&#39;rmin&#39;]))) +1) **(-1)) * join_ff[&#39;Tracer Concentration&#39;]   

        # remove the redundant columns and set dtype of &#39;amount&#39; column as float to avoid pandas DataError
        drop = join_ff.drop([&#39;r_corrected&#39;,&#39;Valid&#39;, &#39;rmin&#39;, &#39;rmax&#39;, &#39;rmin error&#39;, &#39;rmax error&#39;, &#34;lambda&#34;, &#39;Kd&#39;], axis=1).astype({&#39;amount&#39;: &#39;float64&#39;}) 
        
        group = drop.groupby([&#39;Protein Concentration&#39;, &#39;Tracer Concentration&#39;, &#39;Protein Name&#39;, &#39;Tracer Name&#39;])
        mean = group.mean()   
        std = group.std()     
        sem = group.sem()   
        stdr = std.rename(columns={std.columns[-1]: &#39;std&#39;})  # rename column to &#39;std&#39; 
        semr = sem.rename(columns={sem.columns[-1]: &#39;sem&#39;})  # rename column to &#39;sem&#39;
        
        merge = pd.concat([mean, stdr, semr], axis=1)   # merge the amount, std and sem data frames into one df
        tosplit = merge.reset_index()   # remove multiindex
        split = dict(tuple(tosplit.groupby([&#39;Protein Name&#39;, &#39;Tracer Name&#39;])))   # dictionary a data frame for each protein-tracer pair
        return split
            
    def calc_amountbound(self):
        &#34;&#34;&#34;Calcualtes the fraction of tracer bound to the protein using the following formula: 
        L_B =( ( (λ*(rmin-rmax⁡)) / (r-rmin ) +1) )^(-1) * L_T
        Where L_B is the concentration of fluorescent tracer bound to the target protein, 
        L_T is the total tracer concertation,
        &#34;&#34;&#34;
        l = list(FA.final_fit[FA.final_fit[&#39;rmin&#39;].isna()].index)   # list of indexes for which rmin and rmax are not defined
        
        if l != []: 
            raise DataError(f&#34;The &#39;rmin&#39; and &#39;rmax&#39; values are not defined for the following protein-tracer pairs: {l}.\nUse &#39;calc_lambda&#39; function or &#39;set_fitparams&#39; to choose &#39;rmin&#39; and &#39;rmax&#39; values.&#34;)
                            
        for key, value in self.data_dict.items():
            metadata, data = value.values()
            data[&#39;amount_bound&#39;] = FA._amount_bound(data[&#39;r_corrected&#39;], self.plate_map, FA.final_fit)   # create dictionary &#39;r_mean&#39; with mean anisotropy data frames for each protein-tracer pair
            
            
    ##### Curve fitting functions #####        
            
    def _r_func(pc, rmin, rmax, EC50, hill):
        &#34;&#34;&#34;Function for fitting a curve to the plot of anisotropy (or intensity) against protein concentration, 
        where pc is protein concentration, rmin is the lower asymptote, rmax is the upper asymptote, 
        EC50 is midpoint of transition (pc at point of inflection), hill is the slope
        &#34;&#34;&#34;
        return (rmin - rmax) / (1 + (pc/EC50)**hill) + rmax
    
    def _init_params(df):
        &#34;&#34;&#34;Estimates initial parameters for the r_func that are passed to the curve fitting function
        
        :param df: Data frame containing mean values of anisotropy or intensity
        :type df: pandas df
        :return: List with estiamted parameters of min, max and EC50, hill is assumed to be 1
        :rtype: list
        &#34;&#34;&#34;
        rmin = df[&#39;mean&#39;].min()
        rmax = df[&#39;mean&#39;].max()
        mid = (rmax + rmin) / 2
        mid_idx = df[&#39;mean&#39;].sub(mid).abs().argmin()
        EC50 = df.iloc[mid_idx][&#39;Protein Concentration&#39;]
        init_param = [rmin, rmax, EC50, 1]
        return init_param
    
    def _logistic_fit(df, **kwargs):
        &#34;&#34;&#34;Fits a curve to the plot of anisotropy (or intensity) against protein concentration
        
        :param df: Data frame containing mean values of anisotropy (or intensity)
        :type df: pandas df
        :param sig: A string specifying the error data passed to the SciPy curve_fit function, either &#39;std&#39; or &#39;sem&#39;, default None
        :type sig: str
        :param **kwargs: Keyword arguments that can be passed into the scipy curve_fit function
        :return: A list of fitting parameters along with their error in proper order so that it can be added to the fitting params data frame
        :rtype: list
        &#34;&#34;&#34;
        drop = df[df[&#39;Protein Concentration&#39;] != 0].dropna(subset=[&#39;mean&#39;])   # exclude the protein concentration = 0 point and any NaN mean values from data fitting
        
        if &#39;sigma&#39; in kwargs:  
            sigma = drop[kwargs.pop(&#39;sigma&#39;)]   # take the column with std or sem error data
        else:
            sigma = None
            
        if &#39;p0&#39; not in kwargs:   # user did not pass their initial guess
            p0 = FA._init_params(drop)
        else:   # user provided initial guess, remove p0 from kwargs and assign to p0 argument so that there is only one p0 arg passed to curve fit 
            p0 = kwargs.pop(&#39;p0&#39;)
                              
        popt, pcov = curve_fit(FA._r_func, drop[&#39;Protein Concentration&#39;], drop[&#39;mean&#39;], p0=p0, sigma=sigma, **kwargs)
        perr = np.sqrt(np.diag(pcov))   # calculate the error of the fitting params
        all_params = np.insert(popt, obj=[1,2,3,4], values=perr)   # insert the errors after the respective fitting parameter value
        return list(all_params) 
    
    def logistic_fit(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], var=&#39;both&#39;, **kwargs):
        &#34;&#34;&#34;Fits a logistic curve to the plot of anisotropy (or intensity) against protein concentration.
        Returns the fitting parameters with associated errors for each repeat that are stored in the fitting paramters data frame in data dict.
        The calc_data_to_fit function must be executed prior to data fitting.
        
        :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param var: A variable for which the graphs are exported, can be either &#39;r&#39; for anisotropy or &#39;i&#39; for inteensity, defaults to &#39;both&#39;
        :type var: str
        :param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        errors = []   # list for storing the details of errors due to failed fitting
        
        for rep, value in data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            
            for pt_pair in pt_pairs:   # iterate over all protein-tracer pairs
                if var == &#39;r&#39; or var == &#39;both&#39;:
                    try:   # try fitting the curve to anisotropy data 
                        r_mean = data[&#39;r_mean&#39;][pt_pair]   # extract the df with mean anisotropy for a given protein-tracer pair
                        params_r = FA._logistic_fit(r_mean, **kwargs)   # fit the data to logistic curve using the initial parameteers
                        data[&#39;fit_params&#39;].loc[pt_pair, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;, &#39;rmax error&#39;, &#39;r_EC50&#39;, &#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;]] = params_r   # add the fitting parameters to the respective df

                    except RuntimeError as e:   # if fitting fails, added details about the error to the errors list and proceed intensity data fitting
                        r_errorinfo = (rep, &#39;r&#39;, pt_pair, e)
                        errors.append(r_errorinfo)
                
                if var == &#39;i&#39; or var == &#39;both&#39;:
                    try:   # try fitting the curve to intensity data
                        i_mean = data[&#39;i_mean&#39;][pt_pair]   # extract the df with i mean for a given protein-tracer pair
                        params_i = FA._logistic_fit(i_mean, **kwargs)
                        data[&#39;fit_params&#39;].loc[pt_pair, [&#39;Ifree&#39;, &#39;Ifree error&#39;, &#39;Ibound&#39;,&#39;Ibound error&#39;, &#39;I_EC50&#39;, &#39;I_EC50 error&#39;, &#39;I_hill&#39;, &#39;I_hill error&#39;]] = params_i

                    except RuntimeError as e:   # if fitting fails, added details about the error to the errors list and proceed to to the next protein-tracer pair
                        i_errorinfo = (rep, &#39;i&#39;, pt_pair, e)
                        errors.append(i_errorinfo)

        if errors != []:   # raise a warning if fitting failed for any protein-tracer pair
            warnings.warn(f&#34;The curve fitting failed in the following cases:\n\n{errors}\n\nTry passing additional keyword arguments to the fitting function.&#34;, RuntimeWarning)
                    
            
    def _LB(LT, PT, Kd):
        &#34;&#34;&#34;Function for fitting a curve to the plot of concentration of fluorescent tracer bound to the target protein against
        protein concentration.
        LB is the concentration of fluorescent tracer bound to the target protein
        LT is total protein concentration
        PT is total tracer concentration
        Kd is dissociation constant
        &#34;&#34;&#34;
        return ( (LT+PT+Kd) - np.sqrt( ( ((LT+PT+Kd)**2) - (4*LT*PT) ) ) ) / 2 
    

    def single_site_fit(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], **kwargs):
        &#34;&#34;&#34;Fits a curve to the plot of concentration of fluorescent tracer bound to the target protein against the 
        total protein concentration. 
        
        :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        errors = []   # list for storing the details of errors due to failed fitting
        
        if &#39;sigma&#39; in kwargs:  
            sigma = drop[kwargs.pop(&#39;sigma&#39;)]   # take the column with std or sem error data
        else:
            sigma = None
        
        for rep, value in data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            keys = list(data[&#39;amount_bound&#39;].keys())   # create a list of unique protein-tracer pairs
            
            for pt_pair in pt_pairs:   # iterate over all protein-tracer pairs
                try:   # try fitting the curve to anisotropy data 
                    amount_b = data[&#39;amount_bound&#39;][pt_pair]   # extract the df with mean amount bound for a given protein-tracer pair
                    drop = amount_b[ (amount_b[&#39;Protein Concentration&#39;] != 0) &amp; (amount_b[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
                    
                    if len(drop[&#39;Tracer Concentration&#39;].dropna().unique()) == 1:   # check if the protein is titrated to a constant amount of tracer
                        x_data, label = drop[&#39;Protein Concentration&#39;], [&#39;LT&#39;, &#39;LT error&#39;]   
                    if len(drop[&#39;Protein Concentration&#39;].dropna().unique()) == 1:   # check if the tracer is titrated to a constant amount of protein
                        x_data, label = drop[&#39;Tracer Concentration&#39;], [&#39;PT&#39;, &#39;PT error&#39;]
                    
                    popt, pcov = curve_fit(FA._LB, x_data, drop[&#39;amount&#39;], sigma=sigma, **kwargs)
                    err = np.sqrt(np.diag(pcov))
                    FA.final_fit.loc[pt_pair, ([&#39;Kd&#39;, &#39;Kd error&#39;]+label)] = [popt[1], err[1], popt[0], err[0]]   # add Kd and its error to final fit df
                    
                except RuntimeError as e:  
                    error_info = (rep, pt_pair, e)
                    errors.append(error_info)
                
        if errors != []:   # raise a warning if fitting failed for any protein-tracer pair
            warnings.warn(f&#34;The curve fitting failed in the following cases:\n\n{errors}\n\nTry passing additional keyword arguments to the fitting function&#34;, RuntimeWarning)
    
    ##### Anisotropy and biniding constant plotting functions #####
    
    def _get_items_to_plot(data_d, platemap, prot, trac, rep):
        &#34;&#34;&#34;Creates a list of tuples with protein-tracer names based on the &#39;prot&#39; and &#39;trac&#39; parameters 
        and a subset of data_dict based on the &#39;rep&#39; parameter.
        &#34;&#34;&#34;
        if prot[0] == &#39;all&#39; and trac[0] == &#39;all&#39;:   # all proteins and all tracers
            pt_pairs = list(data_d[&#39;repeat_1&#39;][&#39;data&#39;][&#39;r_mean&#39;].keys())   # &#39;r_mean&#39; dict contains all protein-tracer names as dict keys
            
        elif prot[0] != &#39;all&#39; and trac[0] == &#39;all&#39;:   # all tracers and some proteins
            trac = list(platemap[&#39;Tracer Name&#39;].dropna().unique())   # take all tracer names from the platemap
            pt_pairs = [item for item in product(prot, trac)]
            
        elif prot[0] == &#39;all&#39; and trac[0] != &#39;all&#39;:   # all proteins and some tracers
            prot = list(platemap[&#39;Protein Name&#39;].dropna().unique())   # take all protein names from the platemap
            pt_pairs = [item for item in product(prot, trac)]
            
        elif prot[0] != &#39;all&#39; and trac[0] != &#39;all&#39;:   # some proteins and some tracers
            pt_pairs = [item for item in product(prot, trac)]
        
        # define a data dictionary to iterate through based on the &#39;rep&#39; parameter:
        if rep[0] == &#39;all&#39;:   # for all repeats use the whole data_dict
            data_dict = data_d
        else:   # for specific repeats use the subset of data_dict containg only the repeats specified in &#39;rep&#39; parameter
            data_dict = {key: value for key, value in data_d.items() if int(key[-1]) in rep}
        
        return data_dict, pt_pairs
    
    
    def _plot_ani(data_df, params_df, pt_pair, fig, axs, err, var, rep, export, display, labels, dpi=250):
        &#34;&#34;&#34;General function for plotting the anisotropy and intensity and saving the figures.
        
        :param data_df: Data frame with mean values of anisotropy or intensity and their associated errors
        :type data_df: pandas df
        :params_df: Data frame with fitting parameters
        :type params_df: pandas df
        :param pt_pair: protein-tracer pair for which the graph is to be generated
        :type pt_pair: tuple
        :param fig: Figure on which the data is plotted, needed for saving the figure as png file
        :type fig: matplotlib Figure
        :param axs: Indexed axis object on which the data is to be plotted, (e.g. axs[0, 1])
        :type axs: matplotlib AxesSubplot
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param var: Variable for which the plot is to be generated (&#39;r&#39; or &#39;i&#39;)
        :type var: str
        :param repeat: Repeat number for labelling of the graph
        :type repeat: &#39;str&#39;
        :param export: Determines whether the figure will be saved, can be either bool or string with directory path
        :type export: bool or &#39;str&#39;
        :param display: Determines whether the figure will be displayed after plotting, default True
        :type display: bool
        :param labels: Determines whether the legend and box with fitting parameters will be displayed on the figure, default True
        :type labels: bool
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        #r = [i for i in list(params_df.columns) if i[0]==&#39;r&#39; and i[-1] != &#39;r&#39;]
        #rp = params_df.loc[pt_pair, r].to_list()
        if var == &#39;r&#39;:   # define the parameters, legend text and legend coordinates characteristic for anisotropy data
            params = [params_df.loc[pt_pair, &#39;rmin&#39;], params_df.loc[pt_pair, &#39;rmax&#39;], params_df.loc[pt_pair, &#39;r_EC50&#39;], params_df.loc[pt_pair, &#39;r_hill&#39;]]
            #text = &#34;$r_{min}$ = %.2f \u00B1 %.4f\n$r_{max}$ = %.2f \u00B1 %.4f\n$EC_{50}$ = %.0f \u00B1%.0f\n$hill$ = %.2f \u00B1 %.2f&#34; % (params_df.loc[pt_pair, &#39;rmin&#39;], 
            #    params_df.loc[pt_pair, &#39;rmin error&#39;], params_df.loc[pt_pair, &#39;rmax&#39;], params_df.loc[pt_pair, &#39;rmax error&#39;], 
            #    params_df.loc[pt_pair, &#39;r_EC50&#39;], params_df.loc[pt_pair, &#39;r_EC50 error&#39;], params_df.loc[pt_pair, &#39;r_hill&#39;], params_df.loc[pt_pair, &#39;r_hill error&#39;])
            text = &#34;$r_{min}$ = %.2f \u00B1 %.4f\n$r_{max}$ = %.2f \u00B1 %.4f\n$EC_{50}$ = %.0f \u00B1%.0f\n$hill$ = %.2f \u00B1 %.2f&#34; % tuple(params_df.loc[pt_pair, [&#39;rmin&#39;,
            &#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;,&#39;r_EC50&#39;,&#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;]])
            
            label_coords = (0.02, 0.68)
            ylabel = &#39;Anisotropy&#39;
            
        if var.lower() == &#39;i&#39;:   # define the parameters, legend text and legend coordinates characteristic for intensity data
            params = [params_df.loc[pt_pair, &#39;Ifree&#39;], params_df.loc[pt_pair, &#39;Ibound&#39;], params_df.loc[pt_pair, &#39;I_EC50&#39;], params_df.loc[pt_pair, &#39;I_hill&#39;]]
            text = &#34;$I_{free}$ = %.0f \u00B1 %.0f\n$I_{bound}$ = %.0f \u00B1 %.0f\n$EC_{50}$ = %.0f \u00B1 %.0f\n$hill$ = %.2f \u00B1 %.2f&#34; % (params_df.loc[pt_pair, &#39;Ifree&#39;], 
                params_df.loc[pt_pair, &#39;Ifree error&#39;], params_df.loc[pt_pair, &#39;Ibound&#39;], params_df.loc[pt_pair, &#39;Ibound error&#39;], 
                params_df.loc[pt_pair, &#39;I_EC50&#39;], params_df.loc[pt_pair, &#39;I_EC50 error&#39;], params_df.loc[pt_pair, &#39;I_hill&#39;], params_df.loc[pt_pair, &#39;I_hill error&#39;])
            label_coords = (0.02, 0.03)
            ylabel = &#39;Intensity&#39;
        
        drop = data_df[data_df[&#39;Protein Concentration&#39;] != 0].dropna(subset=[&#39;mean&#39;])   # exclude the protein concentration = 0 point and any NaNs from plotting
        axs.errorbar(drop[&#39;Protein Concentration&#39;], drop[&#39;mean&#39;], yerr=drop[err], color=&#39;black&#39;, fmt=&#39;o&#39;, capsize=3, marker=&#39;s&#39;)
        axs.set_xscale(&#39;symlog&#39;)
        axs.set_ylabel(ylabel)
        axs.set_xlabel(f&#39;[{pt_pair[0]}] (nM)&#39;)
        axs.plot(drop[&#39;Protein Concentration&#39;], FA._r_func(drop[&#39;Protein Concentration&#39;], *params), color=&#39;blue&#39;)
        
        if labels == True:   # display legend and a box with fitting parameters on the graph
            axs.set_title(f&#39;Protein: {pt_pair[0]}, Tracer: {pt_pair[1]}&#39;)
            axs.legend([&#39;logistic fitted curve&#39;], frameon=False, fontsize=11)
            axs.annotate(text, xy=label_coords, xycoords=&#39;axes fraction&#39;, fontsize=11)
            
        if export == True:   # save figures in the same directory as the notebook
            fig.savefig(f&#34;{rep}_{var}_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
        
        if type(export) == str:   # save figures in the user defined directory
            fig.savefig(f&#34;{export}{rep}_{var}_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
        
        if display == False:   
            plt.close(fig)
                
   
    def plot_ani(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], err=&#39;std&#39;):   
        &#34;&#34;&#34;Plots anisotropy and intensity against protein concentration with a fitted logistic curve for specific repeats and 
        protein-tracer pairs. A separate figure for each repeat is created with anisotropy and intensity graphs for all 
        specified proteins and tracers side by side. 
        
        :param prot: List of protein names for which the graphs are created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs are created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs are created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        
        for key, value in data_dict.items():   # iterte over all repeats and create a sperate figure for each repeat
            metadata, data = value.values()
            fig, axs = plt.subplots(len(pt_pairs), 2, figsize=(2*6.4, len(pt_pairs)*4.8), tight_layout=True)   # grid for subplots has two columns and a variable number of rows, figsize automatically scales up
            fig.suptitle(f&#34;Repeat {key[-1]}&#34;, fontsize=16)

            for idx, pt_pair in enumerate(pt_pairs):   # for each portein-tracer pair plot two graphs: anisotropy and intensity
                r_data_df = data[&#39;r_mean&#39;][pt_pair]   # extract the df with anisotropy
                i_data_df = data[&#39;i_mean&#39;][pt_pair]   # and intensity
                
                if len(pt_pairs) == 1:   # for only one protein-tracer pair the subplot grid 1-dimensional
                    FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[0], err=err, var=&#39;r&#39;, rep=key, export=False, display=True, labels=True)
                    FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[1], err=err, var=&#39;i&#39;, rep=key, export=False, display=True, labels=True)
                else:   # for more than one protein-tracer pair the subplot grid 2-dimensional
                    FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[idx,0], err=err, var=&#39;r&#39;, rep=key, export=False, display=True, labels=True)
                    FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[idx,1], err=err, var=&#39;i&#39;, rep=key, export=False, display=True, labels=True)
                

    def save_ani_figs(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], var=&#39;both&#39;, path=&#39;&#39;, err=&#39;std&#39;, leg=False, dpi=250):
        &#34;&#34;&#34;Saves single figures of anisotropy and intensity for each protein-tracer pair for all repeats in the same directory as this notebook or
        in user defined directory if the path is provided.
        
        :param prot: List of protein names for which the graphs are exported, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs are exported, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs are exported, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param var: A variable for which the graphs are exported, can be either &#39;r&#39; for anisotropy or &#39;i&#39; for inteensity, defaults to &#39;both&#39;
        :type var: str
        :param path: A path to directory in which the figures are saved, defaults to &#39;&#39; (the same directory as the Jupyter Notebook)
        :type path: str
        :param err: A string representing type of error data to displayed as error bars, either &#39;std&#39; or &#39;sem&#39;, default &#39;std&#39;
        :type err: str
        :param leg: Display legend on the figures, defaults to False
        :type leg: bool
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        
        for key, value in self.data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            pairs = list(data[&#39;r_mean&#39;].keys())   # generate a list of protein-tracer names
                                
            for pt_pair in pairs:   # iterate over each protein-tracer pair in
                if var == &#39;r&#39; or var == &#39;both&#39;:
                    r_data_df = data[&#39;r_mean&#39;][pt_pair]   # extract the df with anisotropy
                    fig_r, ax_r = plt.subplots(figsize=(6.4, 4.8), tight_layout=True)   # create a figure with a single axis for anisotropy 
                    FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig_r, axs=ax_r, err=err, var=&#39;r&#39;, rep=key, export=path, display=False, labels=leg, dpi=dpi)
                
                if var == &#39;i&#39; or var == &#39;both&#39;:
                    i_data_df = data[&#39;i_mean&#39;][pt_pair]   
                    fig_i, ax_i = plt.subplots(figsize=(6.4, 4.8), tight_layout=True)   
                    FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig_i, axs=ax_i, err=err, var=&#39;i&#39;, rep=key, export=path, display=False, labels=leg, dpi=dpi)
        
        print(&#39;The figures were successfully exported.&#39;)
    
    def _plot_kd(data_df, rep, pt_pair, err, leg, exp, dpi):
        &#34;&#34;&#34;Plots amount bound against protein or tracer concentration with a fitted curve on a separate figure for a specific protein-tracer pair.
        
        :param data_df: Data frame with mean values of amount of tracer bound and their associated errors
        :type data_df: pandas df
        :param rep: Repeat number for labelling of the graph
        :type rep: &#39;str&#39;
        :param pt_pair: Protein and tracer names for which data will be plotted
        :type pt_pair: tuples
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param leg: Determines whether the legend and box with fitting parameters will be displayed on the figure, default True
        :type leg: bool
        :param exp: Determines whether the figure will be saved, can be either bool or string with directory path
        :type exp: bool or &#39;str&#39;
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        drop = data_df[ (data_df[&#39;Protein Concentration&#39;] != 0) &amp; (data_df[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
        fig, axs = plt.subplots(1, 1, figsize=(6.4, 4.8), tight_layout=True)
        
        # define the x axis data and labels for protein and tracer titration cases
        if len(drop[&#39;Tracer Concentration&#39;].unique()) == 1:   
            text = &#39;$L_{T}$ = %.2f\u00B1 %.2f\n$K_{d}$ = %.2f \u00B1 %.2f&#39; % (FA.final_fit.loc[pt_pair, &#39;LT&#39;], 
                FA.final_fit.loc[pt_pair, &#39;LT error&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;], FA.final_fit.loc[pt_pair, &#39;Kd error&#39;])  
            x_data = drop[&#39;Protein Concentration&#39;]
            x_label = pt_pair[0]
            params = [FA.final_fit.loc[pt_pair, &#39;LT&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;]]
        
        if len(drop[&#39;Protein Concentration&#39;].unique()) == 1:
            text = &#39;$P_{T}$ = %.2f\u00B1 %.2f\n$K_{d}$ = %.2f \u00B1 %.2f&#39; % (FA.final_fit.loc[pt_pair, &#39;PT&#39;], 
                FA.final_fit.loc[pt_pair, &#39;PT error&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;], FA.final_fit.loc[pt_pair, &#39;Kd error&#39;])  
            x_data = drop[&#39;Tracer Concentration&#39;]
            x_label = pt_pair[1]
            params = [FA.final_fit.loc[pt_pair, &#39;PT&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;]]
            
        axs.errorbar(x_data, drop[&#39;amount&#39;], yerr=drop[err], color=&#39;black&#39;, fmt=&#39;o&#39;, capsize=3, marker=&#39;s&#39;)
        axs.set_xscale(&#39;symlog&#39;)
        axs.set_ylabel(&#39;[Fluorescent Tracer Bound] (nM)&#39;)
        axs.set_xlabel(f&#39;[{x_label}] (nM)&#39;)
        axs.plot(x_data, FA._LB(x_data, *params), color=&#39;blue&#39;)
        
        if leg == True:   # display the figure title, legend and annotation with fitting params
            axs.set_title(f&#39;Repeat {rep[-1]}, Protein: {pt_pair[0]}, Tracer: {pt_pair[1]}&#39;)
            axs.legend([f&#39;single site fitted curve&#39;], fontsize=11, frameon=False)
            axs.annotate(text, xy=(0.02, 0.80), xycoords=&#39;axes fraction&#39;, fontsize=11)
        plt.show()
        
        if exp == True:   # save the figure to the same directory as the notebook
            fig.savefig(f&#34;{rep}_Kd_plot_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
        if type(exp) == str:   # save the figure to user defined directory
            fig.savefig(f&#34;{exp}{rep}_Kd_plot_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
    
    def _overlay_kd_plots(plate_map, data_dict, pt_pairs, err, leg, exp, dpi):   
        &#34;&#34;&#34;Creates a figure with overlayed plots for specified protein-tracer pairs and repeats 
        
        :param plate_map: Platemap
        :type plate_map: pandas df
        :param data_dict: Data dictionary containing the specific repeats for which data will be plotted
        :type data_dict: dict
        :param pt_pairs: List of protein-tracer names for which data will be plotted
        :type pt_pairs: list of tuples
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param leg: Determines whether the legend and box with fitting parameters will be displayed on the figure, default True
        :type leg: bool
        :param exp: Determines whether the figure will be saved, can be either bool or string with directory path
        :type exp: bool or &#39;str&#39;
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        # define the x axis data and labels for protein and tracer titration cases
        if len(plate_map[&#39;Tracer Concentration&#39;].dropna().unique()) == 1:     
            x_data_label, x_label, param = &#39;Protein Concentration&#39;, &#39;Protein&#39;, &#39;LT&#39;
        
        if len(plate_map[&#39;Protein Concentration&#39;].dropna().unique()) == 1:   
            x_data_label, x_label, param = &#39;Tracer Concentration&#39;, &#39;Tracer&#39;, &#39;PT&#39;

        fig, axs = plt.subplots(1, 1, figsize=(6.4, 4.8), tight_layout=True) 
        leg_text = []   # list to store the legend text
        cmaps = [&#39;Blues&#39;, &#39;Greens&#39;, &#39;Oranges&#39;, &#39;Purples&#39;, &#39;Reds&#39;, &#39;Greys&#39;, &#39;YlOrBr&#39;, &#39;YlOrRd&#39;, &#39;OrRd&#39;, &#39;PuRd&#39;, &#39;RdPu&#39;, &#39;BuPu&#39;,
            &#39;GnBu&#39;, &#39;PuBu&#39;, &#39;YlGnBu&#39;, &#39;PuBuGn&#39;, &#39;BuGn&#39;, &#39;YlGn&#39;]
        iter_cmaps = iter(cmaps)
        
        for key, value in data_dict.items():   # iterte through all repeats of the defined data_dict
            metadata, data = value.values()
            
            for pt_pair in pt_pairs:    # iterate through the list of protein-tracer names to plot its data on the same figure
                
                data_df = data[&#39;amount_bound&#39;][pt_pair]   # extract the correct df with amount bound for a given protein-tracer pair
                drop = data_df[ (data_df[&#39;Protein Concentration&#39;] != 0) &amp; (data_df[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
                x_data = drop[x_data_label]
                params = [FA.final_fit.loc[pt_pair, param], FA.final_fit.loc[pt_pair, &#39;Kd&#39;]]

                text2 = &#39;$L_{T}$ = %.2f\u00B1 %.2f\n$K_{d}$ = %.2f \u00B1 %.2f&#39; % (FA.final_fit.loc[pt_pair, &#39;LT&#39;], 
                    FA.final_fit.loc[pt_pair, f&#39;LT error&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;], FA.final_fit.loc[pt_pair, &#39;Kd error&#39;])  
                text = f&#34;rep {key[-1]}, {pt_pair[0]}, {pt_pair[1]}\n{text2}&#34;
                leg_text.append(text)
                
                cmap = plt.cm.get_cmap(next(iter_cmaps))   # take the next color map from the list 
                axs.errorbar(x_data, drop[&#39;amount&#39;], yerr=drop[err], fmt=&#39;o&#39;, capsize=3, marker=&#39;s&#39;, color=cmap(0.95))
                axs.plot(x_data, FA._LB(x_data, *params), color=cmap(0.50))  
                
        axs.set_xscale(&#39;symlog&#39;)
        axs.set_ylabel(&#39;[Fluorescent Tracer Bound] (nM)&#39;)
        axs.set_xlabel(f&#39;[{x_label}] (nM)&#39;)

        if leg == True:   # display the figure title, legend and annotation with fitting params
            axs.set_title(f&#39;Overlayed plot&#39;)
            lbox = axs.legend(leg_text, fontsize=11, frameon=False, loc=&#39;upper left&#39;, bbox_to_anchor=(1.03, 0.95))#, bbox_transform=fig.transFigure)#, xycoords=&#39;axes fraction&#39;)
            fig.canvas.draw()   # draw the  canvas so that figure and legend size is defined
            # calculate length by which the figure will be widened to accomodate the legend
            w = (lbox.get_window_extent().width + (0.06 * axs.get_window_extent().width)) / fig.dpi
            fig.set_size_inches(6.4 + w, 4.8)   # resize the figure
            
        plt.show()
        
        if exp == True:   # save the figure to the same directory as the notebook
            fig.savefig(f&#34;Overlayed_Kd_plot.png&#34;, dpi=dpi) #
        if type(exp) == str:   # save the figure to user defined directory
            fig.savefig(f&#34;{exp}Overlayed_Kd_plot.png&#34;,dpi=dpi)
        
        
    def plot_kd(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], err=&#39;std&#39;, overlay=False, legend=True, export=False, dpi=250):   
        &#34;&#34;&#34;Plots the concentration of fluorescent tracer bound to target protein against the protein (or tracer) concentration.
        
        :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param overlay: Overlayes the data on a single figure, defaults to False
        :type overlay: bool
        :param legend: Display the figure title and legend, defaults to True
        :type legend: bool
        :param export: Saves the figures as png files in the same location as the Notebook or in a specified directory
        :type export: bool or str
        :param dpi: Resolution of the exported figure in dots per inches
        :type dpi: int
        &#34;&#34;&#34;
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        
        if overlay == False:
            for key, value in data_dict.items():   # iterte through all repeats of the defined data_dict
                metadata, data = value.values()

                for pt_pair in pt_pairs:    # iterate through the list of protein-tracer names to create a separate figure for each pair
                    data_df = data[&#39;amount_bound&#39;][pt_pair]   # extract the correct df with amount bound for a given protein-tracer pair
                    FA._plot_kd(data_df=data_df, rep=key, pt_pair=pt_pair, err=err, leg=legend, exp=export, dpi=dpi)
        else:
            FA._overlay_kd_plots(plate_map=self.plate_map, data_dict=data_dict, pt_pairs=pt_pairs, err=err, leg=legend, exp=export, dpi=dpi)
        
        
    ##### Fittig params set, export and import functions #####
        
    def set_fitparams(self, pair, final=True, rep=None, **kwargs):
        &#34;&#34;&#34;Allows to set a value of any parameter in the final fit data frame (by default) or in fit_params data frame 
        for a specific protein-tracer pair.
        
        :param pair: A tuple wtih protein and tracer names for which the parameters are changed
        :type pair: tuple
        :param final: If True, the parameters will be changed in the final_fit data frame, otherwise in the fitting param data frame
        :type final: bool
        :param rep: Repeat number for which the fit_params data frame will be modified, passed only if the final=False, defaults to None
        :type rep: int
        :param **kwargs: Keyword arguments represeting the parameter and its value, e.g. lambda=1.5, rmin=0.30
        &#34;&#34;&#34;
        if final == True:
            for key, value in kwargs.items():   # iterate over the kwargs dictionary
                FA.final_fit.loc[pair, key] = value   # overwrite the parameters in fitting params df with all params passed as keyword arguments
        
        if final == False: 
            for key, value in kwargs.items():   # iterate over the kwargs dictionary
                self.data_dict[f&#39;repeat_{rep}&#39;][&#39;data&#39;][&#39;fit_params&#39;].loc[pair, key] = value   # overwrite the parameters in fitting params df with all params passed as keyword arguments

    def export_params(self, path=&#39;&#39;, file_type=&#39;csv&#39;):
        &#34;&#34;&#34;Export the final fit parameters and the fitting parameters for each repeat to csv or excel files.
        
        :param path: A path to directory in which the file is saved, defaults to &#39;&#39; (i.e. the same directory as this Jupyter Notebook)
        :type path: str
        :param file_type: Type of file generated, either &#39;csv&#39; or &#39;excel&#39; file, defaults to csv
        :type file_type: &#39;str&#39;
        &#34;&#34;&#34;
        if file_type == &#39;csv&#39;:   # export as csv file
            FA.final_fit.to_csv(path_or_buf=f&#34;{path}final_fit_parameters.csv&#34;)
        if file_type == &#39;excel&#39;:   # export as excel file
            FA.final_fit.to_excel(excel_writer=f&#34;{path}final_fit_parameters.xlsx&#34;)
    
        for key, value in self.data_dict.items():   #iterate over all repeats
            metadata, data = value.values()
            
            if file_type == &#39;csv&#39;:   # export as csv file
                data[&#39;fit_params&#39;].to_csv(path_or_buf=f&#34;{path}{key}_fitting_parameters.csv&#34;)
            if file_type == &#39;excel&#39;:   # export as excel file
                data[&#39;fit_params&#39;].to_excel(excel_writer=f&#34;{path}single_repeat_fitting_parameters.xlsx&#34;, sheet_name=f&#39;{key}&#39;)
        
        print(f&#39;The fitting parameters were exported to the {file_type} files.&#39;)
        
        
    def import_params(self, csv_file):
        &#34;&#34;&#34;Allows to import a csv file with final_fit parameters (i.e. rmin, rmax, lamda, Kd and their errors).
        
        :param csv_file: A csv file path with parameters to be imported
        :type csv_file: str
        &#34;&#34;&#34;
        with open(csv_file) as file:   # read the csv into pandas df
            df = pd.read_csv(file, sep=&#39;,&#39;, index_col=[0,1], engine=&#39;python&#39;, encoding=&#39;utf-8&#39;)   # import with multiindex
            indexes = list(df.index)   # create a list with protein-tracer names
        
        for col in df.columns:   # iterate over the imported columns
            if col not in FA.final_fit.columns:   # if there is no such column in final_fit df, raise a warning, otherwise column with wrong name will be added to final_fit
                warnings.warn(f&#34;The final_fit data frame does not contain matching columns: &#39;{col}&#39;&#34;)
            else:   # overwrite the existing values in the final_fit df with the ones from imported df
                FA.final_fit.loc[FA.final_fit.index.intersection(indexes), col] = df.loc[df.index.intersection(indexes), col]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="flu_ani_analysis.flu_ani_analysis_module.DataError"><code class="flex name class">
<span>class <span class="ident">DataError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataError(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.DataTypeError"><code class="flex name class">
<span>class <span class="ident">DataTypeError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataTypeError(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA"><code class="flex name class">
<span>class <span class="ident">FA</span></span>
<span>(</span><span>data_dict, g_factor, plate_map)</span>
</code></dt>
<dd>
<div class="desc"><p>Class used for the analysis of fluorescence anisotropy data.</p>
<p>:param data_dict: A dictionary contaning data frames with pre-processed data and metadata
:type data_dict: dict
:param g_factor: G-factor
:type g_factor: float
:param plate_map: dataframe from a plate map csv file that defines each and every well
:type plate_map: pandas dataframe</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FA:
    &#34;&#34;&#34;Class used for the analysis of fluorescence anisotropy data.
    
    :param data_dict: A dictionary contaning data frames with pre-processed data and metadata
    :type data_dict: dict
    :param g_factor: G-factor
    :type g_factor: float 
    :param plate_map: dataframe from a plate map csv file that defines each and every well
    :type plate_map: pandas dataframe
    &#34;&#34;&#34;
    
    def __init__(self, data_dict, g_factor, plate_map):
        self.data_dict = data_dict
        self.g_factor = g_factor
        self.plate_map = plate_map
        
        frames = []   # create list of all p and s data frames

        for repeat in self.data_dict.values():   
            metadata, data = repeat.values()
            p_channel, s_channel = data.values()
            frames.append(p_channel)
            frames.append(s_channel)
    
        new = pd.concat(frames, axis=1)   # join all p and s data frames into one df to run some stats
        nan = new.size - new.describe().loc[&#39;count&#39;].sum()   # find number of &#39;nan&#39; cells
        
        # create a data frame to store the final fitting params
        p_names = self.plate_map[&#39;Protein Name&#39;].dropna().unique()   # get all protein names
        t_names = self.plate_map[&#39;Tracer Name&#39;].dropna().unique()   # get all trcaer names 
        final_fit = pd.DataFrame(index=pd.MultiIndex.from_product([p_names, t_names]), columns=[&#39;rmin&#39;, &#39;rmin error&#39;, &#39;rmax&#39;, &#39;rmax error&#39;, &#39;lambda&#39;, &#39;Kd&#39;, &#39;Kd error&#39;])   # create the final fit df as a class variable
        final_fit[&#34;lambda&#34;] = 1   # set the default lambda value as 1
        FA.final_fit = final_fit   # add the final_fit df as a class vriable
            
        print(&#34;Data has been uploaded!\n&#34;)
        print(f&#34;Value of g-factor: {self.g_factor} \nNumber of repeats: {len(self.data_dict)} \nOverall number of empty cells is {int(nan)} in {len(frames)} data frames.&#34;)
              
              
    @classmethod
    def read_in_envision(cls, data_csv, platemap_csv, data_type=&#39;plate&#39;, size=384):
        &#34;&#34;&#34;Returns a dictionary of data frames, g-factor and platemap needed to construct the class object. 
        
        :param data_csv: File path of the raw data file in .csv format
        :type data_csv: str
        :param platemap_csv: File path of the platemap file in .csv format
        :type platemap_csv: str
        :param data_type: Format in which the raw data was exported (plate or list), defaults to plate
        :type data_type: str
        :param size: Size of the well plate (384 or 96), defaults to 384
        :type size: int
        :return: A dictionary contaning data frames with pre-processed data, g-factor, pandas data frame containing platemap
        :rtype: dict, float, pandas data frame &#34;&#34;&#34;
        
        # ensure the plate size is either 384 or 96
        if size not in plate_dim:
            raise PlateSizeError(&#39;Invalid size of the well plate, should be 384 or 96.&#39;)
        
        # try to read in data in plate format
        if data_type == &#39;plate&#39;:
            try:
                data_dict, g_factor = FA._read_in_plate(data_csv, size=size)
                plate_map_df = pm.plate_map(platemap_csv, size=size)
                return cls(data_dict, g_factor, plate_map_df)
            
            except (UnboundLocalError, IndexError, ValueError):
                raise DataError(f&#34;Error occured during data read in. Check your file contains data in the &#39;plate&#39; format and plate size is {size}.&#34;)
        
        # try to read in data in list format
        if data_type == &#39;list&#39;:
            try:
                data_dict, g_factor = FA._read_in_list(data_csv, size=size)
                plate_map_df = pm.plate_map(platemap_csv, size=size)
                return cls(data_dict, g_factor, plate_map_df)
            
            except (UnboundLocalError, IndexError):
                raise DataError(&#34;Error occured during data read in. Check your file contains data in the &#39;list&#39; format.&#34;)
        
        else:
            raise DataTypeError(f&#34;&#39;{data_type}&#39; is not one of the two valid data types: plate or list.&#34;)
    

    def _read_in_plate(csv_file, size):
        &#34;&#34;&#34;Reads the raw data file and finds the information needed to extract data. Passes those parameters to pre_process_plate function and executes it.
        Returns a tuple of two elemnts: dictionary of data frames and g-factor.

        :param csv_file: File path of the raw data file in .csv format
        :type csv_file: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A tuple of dictionary of data frames and the g-factor 
        :rtype: tuple &#34;&#34;&#34;
        
        with open(csv_file) as file:
            all_data_lines = list(csv.reader(file, delimiter=&#39;,&#39;))   # read the csv file and cast it into a list containing all lines

        blank_indexes = list(index for index, item in enumerate(all_data_lines) if item == [])   # list containing indices of all blank rows
        if blank_indexes == []:
            blank_indexes = list(index for index, item in enumerate(all_data_lines) if set(item) == {&#39;&#39;})
        blanks = np.array(blank_indexes)   # convert the list of blank indices to a numpy array
        read_in_info = []   # list to store the tuples with parameters needed for pandas to read in the csv file

        for index, item in enumerate(all_data_lines):   # iterate over all lines in the csv file
            if item != [] and re.findall(r&#34;Plate information&#34;, item[0]) == [&#39;Plate information&#39;] and re.search(r&#39;Results for&#39;, all_data_lines[index + 9][0]) == None and re.findall(r&#34;Formula&#34;, all_data_lines[index+1][10]) != [&#39;Formula&#39;]:
                skiprows = index + 9   # Set the skiprows parameter for raw data table
                skiprows_meta = index + 1   # Set the skiprows parameter for metadata table
                end_of_data = blanks[blanks &gt; skiprows].min()   # Calculate the end of data table by finding the smallest blank index after the beginning of data table
                read_in_info.append((skiprows, end_of_data - skiprows + 1, skiprows_meta))   # add the skiprows, caculated number of data lines and skiprows for metadata parameters to the list as a tuple
                data_format = &#39;plate1&#39;

            if item != [] and re.findall(r&#34;Plate information&#34;, item[0]) == [&#39;Plate information&#39;] and re.search(r&#39;Results for&#39;, all_data_lines[index + 9][0]) != None:
                skiprows = index + 10
                skiprows_meta = index + 1
                end_of_data = blanks[blanks &gt; skiprows].min()
                read_in_info.append((skiprows, end_of_data - skiprows - 1, skiprows_meta))
                data_format = &#39;plate2&#39;

            if item != [] and len(item) &gt; 1 and re.fullmatch(r&#34;G-factor&#34;, item[0]):
                g_factor = float(item[4])   
        
        return FA._pre_process_plate(csv_file, read_in_info, data_format, size), g_factor

    def _pre_process_plate(csv_file, read_in_info, data_format, size):    
        &#34;&#34;&#34;Extracts the data and metadata from the csv file, processes it and returns a nested dictionary containing data and metadata for each repeat and channel.

        :param csv_file: File path of the raw data file in .csv format
        :type csv_file: str
        :param read_in_info: Tuples with read in parameters for each channel.
        :type read_in_info: list
        :param data_format: Plate type (plate1 or plate2)
        :type data_format: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A dictionary containing data and metadata 
        :rtype: dict &#34;&#34;&#34; 
        
        data_frames = {}   # dictionary to store data frames
        counter = 1   # counter incremented by 0.5 to enable alternating labelling of data frames as &#39;p&#39; or &#39;s&#39;

        row_letters = list(string.ascii_uppercase)[0: plate_dim[size][0]]   # generate a list of letters for well IDs
        col_numbers = list(np.arange(1, plate_dim[size][1] + 1).astype(str))   # generate a list of numbers for well IDs
        well_ids = [&#39;%s%s&#39; % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the pre-processed data frames
        
        for index, item in enumerate(read_in_info):   # iterate over all tuples in the list, each tuple contains skiprows, nrows and skiprows_meta for one channel 

            if data_format == &#39;plate1&#39;:   # raw data table does not have row and column names so &#39;names&#39; parameter passed to omit the last column
                raw_data = pd.read_csv(csv_file, sep=&#39;,&#39;, names=col_numbers, index_col=False, engine=&#39;python&#39;, skiprows=item[0], nrows=item[1], encoding=&#39;utf-8&#39;)

            if data_format == &#39;plate2&#39;:   # raw data table has row and column names, so index_col=0 to set the first column as row labels
                raw_data = pd.read_csv(csv_file, sep=&#39;,&#39;, index_col=0, engine=&#39;python&#39;, skiprows=item[0], nrows=item[1], encoding=&#39;utf-8&#39;)
                if len(raw_data.columns) in [13, 25]:    
                    raw_data.drop(raw_data.columns[-1], axis=1, inplace=True)    # delete the last column because it is empty

            # generate df for metadata (number of rows of metadata table is always 1) and convert measurement time into datetime object   
            metadata = pd.read_csv(csv_file, sep=&#39;,&#39;, engine=&#39;python&#39;, skiprows=item[2], nrows=1, encoding=&#39;utf-8&#39;).astype({&#39;Measurement date&#39;: &#39;datetime64[ns]&#39;})
            # convert and reshape data frame into 1D array
            data_as_array = np.reshape(raw_data.to_numpy(), (int(size), 1)) 

            if counter % 1 == 0: 
                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=[&#39;p&#39;])   # generate new 384 (or 96) by 1 data frame with p channel data
                data_frames[f&#39;repeat_{int(counter)}&#39;] = {&#39;metadata&#39;:metadata, &#39;data&#39;: {&#39;p&#39;: new_data, &#39;s&#39;:&#39;&#39;}}   # add p channel data and metadata dfs to dictionary

            if counter % 1 != 0:
                new_data = pd.DataFrame(data=data_as_array, index=well_ids, columns=[&#39;s&#39;])   # generate new 384 (or 96) by 1 data frame with s channel data
                data_frames[f&#39;repeat_{int(counter-0.5)}&#39;][&#39;data&#39;][&#39;s&#39;] = new_data   # add s channel data to dictionary

            counter = counter + 0.5
        
        return data_frames


    def _read_in_list(csv_file, size):
        &#34;&#34;&#34;Reads the raw data file and extracts the data and metadata. Passes the raw data to pre_process_list function and executes it.
        Returns a tuple of two elemnts: dictionary of data frames and g-factor.

        :param csv_file: File path of the raw data file in .csv format
        :type csv_file: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A tuple of dictionary of data frames and the g-factor
        :rtype: tuple &#34;&#34;&#34;

        with open(csv_file) as file:  
            all_data_lines = list(csv.reader(file, delimiter=&#39;,&#39;)) # read the csv file and cast it into a list containing all lines
 
        blank_indexes = list(index for index, item in enumerate(all_data_lines) if item == [] or set(item) == {&#39;&#39;})   # list containing indexes of all blank rows
        blanks = np.array(blank_indexes)   # convert the list of blank indexes to a numpy array
        
        # iterate over all lines to find beggining of the data table (&#39;skiprows&#39;) and determine the format of data  (list A, B, or C)
        for index, item in enumerate(all_data_lines):   
            if item != [] and len(item) == 1 and re.findall(r&#34;Plate information&#34;, item[0]) == [&#34;Plate information&#34;]:
                skiprows_meta = index + 1
                end_of_metadata = blanks[blanks &gt; skiprows_meta].min()   # find the end of metadata by finding the smallest blank index after the beginning of metadata
                
            if item != [] and len(item) &gt;= 2 and re.findall(r&#34;PlateNumber&#34;, item[0]) == [&#39;PlateNumber&#39;] and re.findall(r&#34;PlateRepeat&#34;, item[1]) == [&#39;PlateRepeat&#39;]:   # find line number with the beggining of the data
                skiprows = index - 1
                data_format = &#39;listA&#39;
                end_of_data = blanks[blanks &gt; skiprows].min()

            if item != [] and len(item) &gt;= 2 and re.findall(r&#34;Plate&#34;, item[0]) == [&#39;Plate&#39;] and re.findall(r&#34;Barcode&#34;, item[1]) == [&#39;Barcode&#39;]:   # find line number with the beggining of the data
                skiprows = index
                data_format = &#39;listB&#39;
                end_of_data = blanks[blanks &gt; skiprows].min()

            if item != [] and len(item) &gt;= 2 and re.findall(r&#34;Plate&#34;, item[0]) == [&#39;Plate&#39;]  and re.findall(r&#34;Well&#34;, item[1]) == [&#39;Well&#39;]:
                skiprows = index
                data_format = &#39;listC&#39;
                end_of_data = blanks[blanks &gt; skiprows].min()

            if item != [] and re.fullmatch(r&#34;G-factor&#34;, item[0]):   # find the g factor
                g_factor = float(item[4])

        nrows = end_of_data - skiprows - 1   # calculate the length of data table
        nrows_meta = end_of_metadata - skiprows_meta - 1   # calucalte the length of metadata table (number of rows depends on the number of repeats)

        raw_data = pd.read_csv(csv_file, sep=&#39;,&#39;, engine=&#39;python&#39;, skiprows=skiprows, nrows=nrows, encoding=&#39;utf-8&#39;)
        raw_metadata = pd.read_csv(csv_file, sep=&#39;,&#39;, engine=&#39;python&#39;, skiprows=skiprows_meta, nrows=nrows_meta, encoding=&#39;utf-8&#39;)

        return FA._pre_process_list(raw_data, raw_metadata, data_format, size), g_factor

    def _pre_process_list(raw_data, raw_metadata, data_format, size):
        &#34;&#34;&#34;Extracts the data and metadata for each channel and repeat from the raw data and raw metadata 
        and returns a nested dictionary containing data and metadata for each repeat and channel.

        :param raw_data: Data frame containing raw data
        :type raw_data: pandas data frame
        :param raw_metadata: Data frame containing raw metadata
        :type raw_metadata: pandas data frame
        :param data_format: Type of list (listA, listB, or listC)
        :type data_format: str
        :param well_ids: A list of well IDs for the pre-processed data frames
        :type well_ids: list
        :return: A dictionary containing data and metadata
        :rtype: dict&#34;&#34;&#34;

        # remove the &#39;0&#39; from middle position of well numbers (A01 -&gt; A1), done by reassigning the &#39;Well&#39; column to a Series containing modified well numbers
        raw_data[&#39;Well&#39;] = raw_data[&#39;Well&#39;].apply(lambda x: x[0] + x[2] if x[1] == &#39;0&#39; else x)
        
        data_frames = {}   # dictionary to store data frames
        repeats = list(raw_metadata[&#39;Repeat&#39;].to_numpy())   # generate a list with repeats based on the metadata table, e.g. for 3 repeats -&gt; [1,2,3]

        row_letters = list(string.ascii_uppercase)[0: plate_dim[size][0]]   # generate a list of letters for well IDs
        col_numbers = list(np.arange(1, plate_dim[size][1] + 1).astype(str))   # generate a list of numbers for well IDs
        well_ids = [&#39;%s%s&#39; % (item[0], item[1]) for item in product(row_letters, col_numbers)]   # generate a list of well IDs for the pre-processed data frames
        
        for index, repeat in enumerate(repeats):   # iterate over the number of repeats
            if data_format == &#39;listA&#39;:
                groupped_data = raw_data.groupby(raw_data.PlateRepeat).get_group(repeat)   # group and extract the data by the plate repeat column, i.e. in each iteration get data only for the current repeat 

                p_groupped = groupped_data.iloc[::3, :]   # extract data only for the p channel, i.e. each third row starting from the first row
                s_groupped = groupped_data.iloc[1::3, :]   # extract data only for the s channel, i.e. each third row starting from the second row

                p_raw_data = p_groupped[[&#39;Well&#39;, &#39;Signal&#39;]]   # extract only the two relevant columns
                s_raw_data = s_groupped[[&#39;Well&#39;, &#39;Signal&#39;]]   # for each channel

            if data_format in [&#39;listB&#39;, &#39;listC&#39;]: 
                # the column naming is different for the first repeat (&#39;Signal&#39;), then it&#39;s &#39;Signal.1&#39;, &#39;Signal.2&#39;, etc.
                if repeat == 1: 
                    p_raw_data = raw_data[[&#39;Well&#39;, &#39;Signal&#39;]]   
                    s_raw_data = raw_data[[&#39;Well&#39;, f&#39;Signal.{repeat}&#39;]]
                else:
                    p_raw_data = raw_data[[&#39;Well&#39;, f&#39;Signal.{repeat + index - 1}&#39;]]   # the column cotntaining data to be extracted is calculated in each iteration
                    s_raw_data = raw_data[[&#39;Well&#39;, f&#39;Signal.{repeat + index}&#39;]]
            
            # create an empty df with no columns and indexes matching the plate size
            indexes = pd.DataFrame(well_ids, columns=[&#39;Wells&#39;])
            empty_frame = indexes.set_index(&#39;Wells&#39;)
            
            p_raw_data.set_index(&#39;Well&#39;, inplace=True)   # set the row indexes as the well numbers
            p_raw_data.set_axis([&#39;p&#39;], axis=1, inplace=True)   # rename the &#39;Signal&#39; column to &#39;p&#39;
            p_data = empty_frame.join(p_raw_data)   # join the raw data df to an empty frame based on the indexes, assigns &#39;NaN&#39; to indexes not present in the raw data table
            
            s_raw_data.set_index(&#39;Well&#39;, inplace=True) 
            s_raw_data.set_axis([&#39;s&#39;], axis=1, inplace=True)
            s_data = empty_frame.join(s_raw_data)
    
            metadata = raw_metadata.iloc[[repeat-1]].astype({&#39;Measurement date&#39;: &#39;datetime64[ns]&#39;})   # extract the row with metadata relevant for each repeat and covert date and time into a datetime object
            data_frames[f&#39;repeat_{repeat}&#39;] = {&#39;metadata&#39;: metadata, &#39;data&#39;: {&#39;p&#39;: p_data, &#39;s&#39;: s_data}}   # add data frames to the dictionary

        return data_frames
    
    
    def visualise(self, colorby=&#39;Type&#39;, labelby=&#39;Type&#39;, title=&#34;&#34;, cmap=&#39;Paired&#39;, dpi=250, export=False):
        &#34;&#34;&#34;Returns a visual representation of the plate map.
        The label and colour for each well can be customised to be a variable, for example &#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;, etc.
        It can also be the p or s anisotropy value from a specified repeat passed as a tuple of strings, for example (&#39;repeat_2&#39;, &#39;p&#39;) for p data from repeat 2
        
        :param colorby: Chooses the parameter to color code by, for example &#39;Type&#39;, &#39;Contents&#39;, &#39;Protein Concentration&#39;, (&#39;repeat_2&#39;, &#39;p&#39;), default = &#39;Type&#39;
        :type colorby: str or tuple
        :param labelby: Chooses the parameter to label code by, for example &#39;Type&#39;, &#39;Contents&#39;, &#39;Protein&#39;, (&#39;repeat_1&#39;, &#39;s&#39;), default = &#39;Type&#39;
        :type labelby: str or tuple
        :param title: Sets the title of the figure, default none
        :type title: str
        :param cmap: Sets the colormap for the color-coding, default = &#39;Paired&#39;
        :type cmap: str
        :param dpi: Size of the figure, default = 250
        :type dpi: int
        :param export: If &#39;True&#39; a .png file of the figure is saved, default = False
        :type export: bool
        :return: Visual representation of the plate map.
        :rtype: figure
        &#34;&#34;&#34;
        plate_map = self.plate_map
        size = plate_map.shape[0]
        scinot = False
        str_len = None
        
        if type(labelby) == tuple:   # option for labelling by the p or s anisotropy values
            plate_map = self.plate_map.join(self.data_dict[labelby[0]][&#39;data&#39;][labelby[1]])   # data frame containing p or s values from specified repeat is added to the platemap
            labelby = labelby[1]
        if type(colorby) == tuple:   # option for colouring by the p or s anisotropy values
            plate_map = plate_map.join(self.data_dict[colorby[0]][&#39;data&#39;][colorby[1]])
            colorby = colorby[1]
            
        if labelby in [&#39;Protein Concentration&#39;, &#39;Tracer Concentration&#39;, &#39;Competitor Concentration&#39;, &#39;p&#39;, &#39;s&#39;, &#39;p_corrected&#39;, &#39;s_corrected&#39;, &#39;r_raw&#39;, &#39;r_corrected&#39;, &#39;i_raw&#39; , &#39;i_corrected&#39;]:
            if sum((plate_map[labelby] &gt; 1000) | (plate_map[labelby] &lt; 0)) &gt; 0:   # display in sci notation if the number is greater than 1000 or less than 0
                scinot = True
                str_len = 8
        
        return pm.visualise(platemap=plate_map, title=title, size=size, export=export, cmap=cmap, colorby=colorby, labelby=labelby, dpi=dpi, scinot=scinot, str_len=str_len)
    
    def invalidate(self, valid=False, **kwargs):
        &#34;&#34;&#34;Invalidates wells, columns and/or rows. Any of the following arguments, or their combination, can be passed: wells, rows, columns. 
        For example to invalidate well A1, rows C and D and columns 7 and 8 execute the following: invalidate(wells=&#39;A1&#39;, rows=[&#39;C&#39;,&#39;D&#39;], columns=[7,8]).
        To validate previously invalidated wells, rows and/or columns, pass the additional &#39;valid&#39; argument as True.
    
        :param valid: Sets the stipulated row or rows &#39;True&#39; or &#39;False&#39;, default = False
        :type valid: bool
        :param wells: Wells to be invalidated passed as a string or a list of strings
        :type wells: str or list
        :param rows: Rows to be invalidated passed as a string or a list of strings
        :type rows: str or list
        :param columns: Columns to be invalidated passed as an integer or a list of integers
        :type columns: int or list
        &#34;&#34;&#34;
        # execute the corresponding invalidate functon from the platemapping package
        if &#39;wells&#39; in kwargs:
            pm.invalidate_wells(platemap=self.plate_map, wells=kwargs[&#39;wells&#39;], valid=valid)
        if &#39;rows&#39; in kwargs:
            rows = tuple(kwargs[&#39;rows&#39;]) # convert the rows to tuple because invalidate_rows cannot take in a list
            pm.invalidate_rows(platemap=self.plate_map, rows=rows, valid=valid)
        if &#39;columns&#39; in kwargs:
            pm.invalidate_cols(platemap=self.plate_map, cols=kwargs[&#39;columns&#39;], valid=valid)
        if len(kwargs) == 0:   # return error if neither of the keyword arguments is passed
            raise TypeError(&#39;No arguments were passed. Specify the wells, rows and/or columns to be invalidated!&#39;)
      
    
    def background_correct(self):
        &#34;&#34;&#34;Calculate background corrected values for p and s channel in all repeats.
        
        Cacluclated by subtracting the mean value of blank p or s for a given concentration from each value of compound p or s for that concentration.&#34;&#34;&#34;
        
        for key, value in self.data_dict.items(): 
            metadata, data = value.values()   

            # create joined dfs of platemap and p or s
            p_df = self.plate_map.join(data[&#39;p&#39;])  
            s_df = self.plate_map.join(data[&#39;s&#39;])
            
            # calculate p and s corrected and add them to data dictionary
            self.data_dict[key][&#39;data&#39;][&#39;p_corrected&#39;] = FA._backg_correct(p_df, &#39;p_corrected&#39;)
            self.data_dict[key][&#39;data&#39;][&#39;s_corrected&#39;] = FA._backg_correct(s_df, &#39;s_corrected&#39;)
            
            print(&#39;Background correction has been successfully performed!&#39;)
            
    def _backg_correct(df, col_name):
        &#34;&#34;&#34;Calculate background corrected p or s.
        
        :param df: Joined platemap and raw p or s values 
        :type df: pandas df
        :param col_name: Name of the column with background corrected values
        :type col_name: str
        :return: Data frame with background corrected p or s values (depending on col_name parameter)
        :rtype: pandas df&#34;&#34;&#34;
        
        df[df.columns[-1]] = df[df.columns[-1]][df[&#39;Valid&#39;] == True]   # &#39;p&#39; or &#39;s&#39; values are replaced with NaN if the well is invalidated
        no_index = df.reset_index()   # move the index to df column
        mindex = pd.MultiIndex.from_frame(no_index[[&#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;]])   # create multiindex
        reindexed = no_index.set_index(mindex).drop([&#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;], axis=1)   # add multiindex to df and drop the columns from which multiindex was created
    
        mean = reindexed.groupby(level=[0,1,2]).mean().drop(&#39;Valid&#39;, axis=1)   # calculate mean for each group of three wells and remove &#39;Valid&#39; column
        mean.rename(columns={mean.columns[-1]: &#39;Mean&#39;}, inplace=True)   # rename the last column to &#39;Mean
        blank = mean.xs(&#39;blank&#39;, level=0, drop_level=True)   # take a group with blank wells
        
        joined = reindexed.join(blank, on=[&#39;Protein Name&#39;, &#39;Protein Concentration&#39;])
        joined[col_name] = joined[joined.columns[-2]] - joined[&#39;Mean&#39;]   # calculate background corrected values
        jindexed = joined.set_index(&#39;index&#39;, append=True).reset_index(level=[0,1,2]).rename_axis(None)   # set index to &#39;well id&#39; and move multiindex to df columns
        return jindexed[[col_name]]
    
    
    def calculate_r_i(self, correct=True, plot_i=True, thr=80):
        &#34;&#34;&#34;Calculates anisotropy and fluorescence intensity.
        The fluorescence intensity (I) and anisotropy (r) are calculated using the follwing formulas: I = s + (2*g*p), r = (s - (g*p)) / I and stored 
        in data_dict as i_raw and r_raw (calculated using the uncorrected p and s channel values) 
        and i_corrected and r_corrected (if calculated using the background corrected p and s channel values, as well).
        
        :param correct: Calculate the anisotropy and intensity using the background corrected values of p and s, as well, default=True
        :type correct: bool
        :param plot_i: Displays plots of the percentage intensity against well ids for all repeats, defaults to True
        :type plot_i: bool
        :param th: Percentage intensity value above which the wells id will be reported
        :type th: int
        &#34;&#34;&#34;
        FA.th = thr   # assign the threshold value to the class variable so that it can be accessed outside of this function
    
        for key, value in self.data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            
            # calculate raw intensity and anisotropy and add them to data dictionary
            i, r = FA._calc_r_I(data[&#39;p&#39;], data[&#39;s&#39;], self.g_factor, &#39;raw&#39;)
            self.data_dict[key][&#39;data&#39;][&#39;i_raw&#39;] = i   
            self.data_dict[key][&#39;data&#39;][&#39;r_raw&#39;] = r   
            
            if correct:   # calculate intensity and anisotropy using background corrected values of p and s
                if &#39;p_corrected&#39; and &#39;s_corrected&#39; not in data:   # check if background subtraction has been done
                    raise AttributeError(&#39;The corrected anisotropy and intensity can only be calculated after background correction of the raw p and s channel data.&#39;)
                
                i_c, r_c = FA._calc_r_I(data[&#39;p_corrected&#39;], data[&#39;s_corrected&#39;], self.g_factor, &#39;corrected&#39;)
                self.data_dict[key][&#39;data&#39;][&#39;i_corrected&#39;] = i_c   
                self.data_dict[key][&#39;data&#39;][&#39;r_corrected&#39;] = r_c    
                
                self.data_dict[key][&#39;data&#39;][&#39;i_percent&#39;] = FA._calc_I_percent(i, i_c, self.plate_map)
        
        print(&#39;The fluorescence intensity and anisotropy have been successfully calculated!\n&#39;)
        
        if plot_i:   # plot the percentage intensity against the well ids for all repeats
            FA._plot_i_percent(self.data_dict, self.plate_map)

    def _calc_r_I(p, s, g, col_suffix):
        &#34;&#34;&#34;Calculates either anisotropy or intensity and labels the resulting dfs according to the parameters passed
        
        :param p: Pandas data frame with p channel data (can be both raw and background corrected)
        :type p: pandas df 
        :param s: Pandas data frame with s channel data (can be both raw and background corrected)
        :type s: pandas df
        :param g: G-factor
        :type g: float
        :param col_suffix: Suffix to add to column name of the resulting intensity or anisotropy data frame, e.g. &#39;raw&#39;, &#39;corrected&#39;
        :type col_suffix: str
        :return: Data frames with calculated anisotropy and intensity values
        :rtype: pandas df&#34;&#34;&#34;
        
        p_rn = p.rename(columns={p.columns[0]: s.columns[0]})   # rename the col name in p data frame so that both p and s dfs have the same col names to enable calculation on dfs
        i = s + (2 * g * p_rn)       # calculate intensity
        r = (s - (g * p_rn)) / i     # and anisotropy
        i_rn = i.rename(columns={i.columns[0]: &#39;i_&#39;+col_suffix})   # rename the col name using the column suffix argument
        r_rn = r.rename(columns={r.columns[0]: &#39;r_&#39;+col_suffix})           
        return i_rn, r_rn  
    
    def _calc_I_percent(ir, ic, platemap):
        &#34;&#34;&#34;Calculate the percentage intensity of blank wells compared to non-blank wells.
        
        :param ir: Data frame with corrected intensity 
        :type ir: pandas df
        :param ic: Data frame with raw intensity
        :type ic: pandas df
        :param platemap: Platemap
        :type platemap: pandas df
        :return: df containing only the non-blank and non-empty columns
        :rtype: pandas df&#34;&#34;&#34;
        
        ir_rn = ir.rename(columns={ir.columns[0]:ic.columns[0]})   # rename the col name in raw intensity df so that it&#39;s the same as in corrected intensity df
        percent = (ir_rn - ic)/ir_rn * 100   
        percent.rename(columns={&#39;i_corrected&#39;:&#39;i_percent&#39;}, inplace=True)
        joined = platemap.join(percent)   # join the percent data to platemap
        return joined[[&#39;i_percent&#39;]]
        
    def _plot_i_percent(data_d, platemap):
        &#34;&#34;&#34;Plot the percentage intensity against the well ids with a horizotanl threshold bar and preint the list of wells above the threshold for all repeats
        
        :param data_d: Dictionary with data for all repeats
        :type data_d: dict &#34;&#34;&#34;
        
        st = &#39;&#39;   # empty string to which lists of wells to be printed are appended after checking data from each repeat
        fig = plt.figure(figsize=(8*int((len(data_d) + 2 - abs(len(data_d) - 2))/2), 4*int( math.ceil((len(data_d))/2)) ), tight_layout=True)   # plot a figure with variable size depending on the number subplots (i.e. repeats)
        #fig.suptitle(&#39;The percentage intensity of a non-blank well was plotted for all repeats&#39;, fontsize=14)   # add the figure title
        
        for key, value in data_d.items():   # iterate over all repeats
            metadata, data = value.values()
            df = platemap.join(data[&#39;i_percent&#39;])
            df_per = df[(df[&#39;Type&#39;] != &#39;blank&#39;) &amp; (df[&#39;Type&#39;] != &#39;empty&#39;)]   # subset only the non-blank and non-empty columns
            
            plt.subplot(int( math.ceil((len(data_d))/2) ), int( (len(data_d) + 2 - abs(len(data_d) - 2))/2 ), int(key[-1]))
            plt.bar(df_per.index, df_per[&#39;i_percent&#39;])   # plot a bar plot with intensity percentage data 
            plt.axhline(FA.th, color=&#39;red&#39;)   # plot a horizontal line representing the threshold on the bar plot
            ax = plt.gca()   # get the axis object
            ax.set_ylabel(&#39;&#39;)
            ax.set_xlabel(&#39;wells&#39;)
            ax.set_title(key)
            ax.yaxis.set_major_formatter(mtick.PercentFormatter())   # set formatting of the y axis as percentage
            xlabels = [i if len(i) == 2 and i[1] == &#39;1&#39; else &#39;&#39; for i in list(df_per.index)]   # create a list of xtics and xticklabels consiting only of the first wells from a each row
            ax.set_xticks(xlabels)
            ax.set_xticklabels(xlabels)
        
            wells = list(df_per[df_per[&#39;i_percent&#39;] &gt; FA.th].index)   # get a list of well ids above the threshold for this repeat
            if wells != []:   # append wells above the threshold and the repective repeat number to the string with appropriate formatting
                st = st + f&#39;\t{key}: {str(wells)}\n&#39;
        
        plt.show()   # ensure the figure is displayed before printing the summary message

        if st != &#39;&#39;:   # display the summary of wells above the threshold
            print(f&#39;In the following wells the percentage intensity value was above the {FA.th}% threshold:&#39;)
            print(st)
        else:
            print(f&#39;None of the wells has the percentage intensity value above the {FA.th}% threshold.&#39;)
            
    def plot_i_percent(self):
        &#34;&#34;&#34;This function only displays the results calculated by the calculate_r_i function and does not recalculate it.&#34;&#34;&#34;
        return FA._plot_i_percent(self.data_dict, self.plate_map)
    
    
    def calc_data_to_fit(self):
        &#34;&#34;&#34;Calculates data required for fitting a curve to the plot of anisotropy (or intensity) against protein concentration.
        The following data is calcualted for both intensity and anisotropy for all repeats: mean, standard devition and standard error.
        
        Data frames for storing fitting parametres for each repeat (&#39;fit_params&#39;) and a data frame for storing
        final values of rmin, rmax and lambda for each protein-tracer pair are created.
        &#34;&#34;&#34;
        for key, value in self.data_dict.items():
            metadata, data = value.values()
               
            data[&#39;r_mean&#39;] = FA._fitting_data(data[&#39;r_corrected&#39;], self.plate_map)   # create dictionary &#39;r_mean&#39; with mean anisotropy data frames for each protein-tracer pair
            data[&#39;i_mean&#39;] = FA._fitting_data(data[&#39;i_corrected&#39;], self.plate_map)   # create dictionary &#39;i_mean&#39; with mean intensity data frames for each protein-tracer pair
            # create data frame for storing the fitting params 
            data[&#39;fit_params&#39;] = pd.DataFrame(index=FA.final_fit.index, columns=[&#39;rmin&#39;,&#39;rmin error&#39;, &#39;rmax&#39;, f&#39;rmax error&#39;, &#39;r_EC50&#39;, &#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;, &#39;Ifree&#39;, &#39;Ifree error&#39;, &#39;Ibound&#39;, &#39;Ibound error&#39;, &#39;I_EC50&#39;, &#39;I_EC50 error&#39;, &#39;I_hill&#39;, &#39;I_hill error&#39;, &#39;lambda&#39;])   # create new df for storing the fitting parameters
            data[&#39;fit_params&#39;][&#39;lambda&#39;] = 1
       
    def _fitting_data(df, plate_map):
        &#34;&#34;&#34;Calculates mean anisotropy for each protein concentration value, its standard deviation and standard error.
        Creates an empty data frame for storing the fitting parameters for each repeat and sets the lambda value as 1.
        
        :param df: Data frame with anisotropy or intensity values
        :type df: pandas df
        :param plate_map: Plate map data frame
        :type plate_map: pandas df
        :return: A dictionary with data frames for each unique protein-tracer pair and data frame for storing the fitting parameter
        :rtype: tuple (dict, pandas df)&#34;&#34;&#34;
        
        join = plate_map.join(df)   # join anisotropy values to platemap
        subset = join[(join[&#39;Type&#39;] != &#39;blank&#39;) &amp; (join[&#39;Type&#39;] != &#39;empty&#39;)]   # take only non-blank and non-empty cells
        noidx = subset.reset_index()
        group = noidx.groupby([&#39;Protein Concentration&#39;, &#39;Protein Name&#39;, &#39;Tracer Name&#39;])
        mean = group.mean()   
        std = group.std()     
        sem = group.sem()    
        meanr = mean.rename(columns={mean.columns[-1]: &#39;mean&#39;})
        stdr = std.rename(columns={std.columns[-1]: &#39;std&#39;}).drop(&#39;Valid&#39;, axis=1)   # rename the std column and remove the &#39;Valid&#39; column
        semr = sem.rename(columns={sem.columns[-1]: &#39;sem&#39;}).drop(&#39;Valid&#39;, axis=1)   # rename the sem column and remove the &#39;Valid&#39; column
        merge = pd.concat([meanr, stdr, semr], axis=1)
        tosplit = merge.reset_index()   # remove multiindex
        split = dict(tuple(tosplit.groupby([&#39;Protein Name&#39;, &#39;Tracer Name&#39;])))   # split df based on multiindex so that a new df is created for each unique combination of protein and tracer
        
        return split
            
    def calc_lambda(self, approve=True):
        &#34;&#34;&#34;Calculates lambda value for each protein-tracer pair for all repeats. 

        If &#39;approve=True&#39;, a list with calcualted lambda values with checkboxes will be displayed. To approve the proposed value 
        tick the selected checkboxes and click &#39;Update&#39; button. If &#39;approve=False&#39;, all of the calculated values will be saved and 
        the list with checkboxes will not be displayed. You can still amend any values in the fitting parameters data frame using the &#39;set_fitparams function.

        :param approve: If True a list of checkboxes will be displayed to choose the lambda values that will be saved, default True
        :type approve: bool
        :return: If approve=True, return a list of calculated lambda values along with checkboxes to be approved, 
        else save the calulated lambda values in the fitting params data frames for each repeat 
        &#34;&#34;&#34;
        w_info = []   # list of tuples with info (rep no, lambda value, etc) for generation of widgets
        
        for key, value in self.data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            df = data[&#39;fit_params&#39;].copy()    # create a copy of the fitting params df
            df[&#39;lambda&#39;] = df[&#39;Ibound&#39;]/df[&#39;Ifree&#39;]   # calculate the lambda value in a copied data frame
            
            if approve == False:   # if the user does not want to manually approve the proposed values
                self.data_dict[key][&#39;data&#39;][&#39;fit_params&#39;][&#39;lambda&#39;] = df[&#39;lambda&#39;]   # add the lambda values to fitting params df
                print(&#39;The lambda values were calculated and saved.&#39;)
            else:
                indexes = list(df.index)   # create list of tuples with protein-tracer names
                for item in indexes:   # iterate over each protein-tracer pair and create tuples with info needed for generation of widgets
                    rating = 100
                    tp = (key, item, rating, df.loc[item, &#34;lambda&#34;],  data[&#39;fit_params&#39;].loc[item, &#34;rmin&#34;],  data[&#39;fit_params&#39;].loc[item, &#34;rmax&#34;])   # tuples conataining repeat no., calculated lambda, and protein-tracer names
                    w_info.append(tp)

        if approve == True:   # execute the function for displying and handling the widgets
            return FA._widget(self.data_dict, w_info, df)
            
    def _widget(data_dict, w_info, df):
        &#34;&#34;&#34;Function for generating and displaying the widgets with lambda values.
        It generates widgets for each tuple in the w_info list.
        
        :param data_dict: Data dictionary with all repeats
        :type data_dict: dict
        :param w_info: A list of tuples containg information needed for the generation of widgets
        :type w_info: list
        :param df: Data frame with calculated lambda values
        :type df: pandas df
        &#34;&#34;&#34;
        w_info.sort(key=lambda x: x[1])   # sort the tuples by the protein name so that the widgets are displayed by protein-tracer name
        reps = [wg.HTML(f&#34;{i[0]}&#34;) for i in w_info]   # list of text widgets with repeat numbres
        proteins = [wg.HTML(f&#34;{i[1][0]}&#34;) for i in w_info]   # list of text widgets with protein names
        tracers = [wg.HTML(f&#34;{i[1][1]}&#34;) for i in w_info]   # list of text widgets with tracer names
        scores = [wg.HTML(f&#34;Score: {i[2]}&#34;) for i in w_info]   
        lambdas = [wg.Checkbox(value=False, description=&#34;lambda=%.4f&#34; % (i[3])) for i in w_info]   # list of checkbox widgets with lambda values
        rminmax = [wg.Checkbox(value=False, description=&#34;rmin=%.5f, rmax=%.5f&#34; % (i[4], i[5])) for i in w_info]   # list of checkbox widgets with rmin and rmax values
            
        v_lambdas = wg.VBox(lambdas)   # group all lambda checkbox widgets into a vertical list layout
        v_proteins = wg.VBox(proteins)   # group all protein name widgets into a vertical list layout
        v_tracers = wg.VBox(tracers)   # group all tracer name widgets into a vertical list layout
        v_reps = wg.VBox(reps)   # group all repeat number widgets into a vertical list layout
        v_scores = wg.VBox(scores)
        v_rminmax = wg.VBox(rminmax)   # group all rmin and rmax checkbox widgets into a vertical list layout
            
        hbox = wg.HBox([v_proteins, v_tracers, v_reps, v_scores, v_lambdas, v_rminmax])   # arrange the six vertical boxes into one widget box&#39;
        button = wg.Button(description=&#39;Save&#39;)   # create a button for saving the selected values
        print(&#34;&#34;&#34;Choose the lambda values that will be saved for each protein-tracer pair. \nIf you choose more than one lambda value for a given protein-tracer pair, only the first choice will be saved.\nIf you do not choose any lambda value for a given protein-trcacer pair, then you have select the rmin and rmax for this pair.&#34;&#34;&#34;)
        display(hbox, button)   # display the box with widgets and the button
            
        def btn_eventhandler(obj): 
            &#34;&#34;&#34;Function that is executed when the &#39;Save&#39; button is clicked. It checks which checkboxes were ticked and 
            updates the final fit df with the calcualted lambda values and/or rmin and rmax values. 
            Only the first value of lambda for a given protein-tracer will be saved.
            &#34;&#34;&#34;
            added_lambda = []   # protein-tracer pairs for which lambda values were added
            added_rminmax = []   # protein-tracer pairs for which rmin and rmax values were added
            
            for i in range(0, len(lambdas)):   # iterate over each checkbox widget
                index = (proteins[i].value, tracers[i].value)   # get the tuple with protein-tracer names
                
                if lambdas[i].value == True:   # if the lambda checkbox was ticked, the widget&#39;s &#39;value&#39; attribute is True 
                    if index not in added_lambda:   # if lambda for this protein-tracer pair has not yet been added 
                        FA.final_fit.loc[index, &#34;lambda&#34;] = df.loc[index, &#34;lambda&#34;]   # add the calculated lambda to the final_fit d
                        FA.final_fit.loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]] = data_dict[reps[i].value][&#39;data&#39;][&#39;fit_params&#39;].loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]]   #add rmin, rmax and their errors to the final_fit df
                        added_lambda.append(index)  
                        
                if rminmax[i].value == True:
                    if index not in added_lambda and index not in added_rminmax:   # if neither lambda nor rmin/rmax for this protein-tracer pair have been added 
                        FA.final_fit.loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]] = data_dict[reps[i].value][&#39;data&#39;][&#39;fit_params&#39;].loc[index, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;]]
                        added_rminmax.append(index)
            
            print(&#39;Selected values were saved.&#39;)
        button.on_click(btn_eventhandler)   #link the button event handler function with actual clicking of the button using &#39;on_click&#39; function
        
    
    def _amount_bound(df, platemap, final_fit):

        join_pm = platemap.join(df)   # join df with corrected anisotropy to the platemap df
        subset = join_pm[(join_pm[&#39;Type&#39;] != &#39;blank&#39;) &amp; (join_pm[&#39;Type&#39;] != &#39;empty&#39;)]   # take only non-blank and non-empty wells

        re_idx = subset.set_index(pd.MultiIndex.from_frame(subset[[&#39;Protein Name&#39;, &#39;Tracer Name&#39;]])).rename_axis([None,None])   # replace the index with multiindex (protein-tracer name) and remove its names
        join_ff = re_idx.join(final_fit)   # join the final fitting parameters to the anisotropy df on multiindex (protein-tracer)

        # calcualte the amount bound (all parameters needed are already in the data frame)
        join_ff[&#39;amount&#39;] = (((((join_ff[&#34;lambda&#34;] * (join_ff[&#39;rmax&#39;]-join_ff[&#39;r_corrected&#39;])) / (join_ff[&#39;r_corrected&#39;] - join_ff[&#39;rmin&#39;]))) +1) **(-1)) * join_ff[&#39;Tracer Concentration&#39;]   

        # remove the redundant columns and set dtype of &#39;amount&#39; column as float to avoid pandas DataError
        drop = join_ff.drop([&#39;r_corrected&#39;,&#39;Valid&#39;, &#39;rmin&#39;, &#39;rmax&#39;, &#39;rmin error&#39;, &#39;rmax error&#39;, &#34;lambda&#34;, &#39;Kd&#39;], axis=1).astype({&#39;amount&#39;: &#39;float64&#39;}) 
        
        group = drop.groupby([&#39;Protein Concentration&#39;, &#39;Tracer Concentration&#39;, &#39;Protein Name&#39;, &#39;Tracer Name&#39;])
        mean = group.mean()   
        std = group.std()     
        sem = group.sem()   
        stdr = std.rename(columns={std.columns[-1]: &#39;std&#39;})  # rename column to &#39;std&#39; 
        semr = sem.rename(columns={sem.columns[-1]: &#39;sem&#39;})  # rename column to &#39;sem&#39;
        
        merge = pd.concat([mean, stdr, semr], axis=1)   # merge the amount, std and sem data frames into one df
        tosplit = merge.reset_index()   # remove multiindex
        split = dict(tuple(tosplit.groupby([&#39;Protein Name&#39;, &#39;Tracer Name&#39;])))   # dictionary a data frame for each protein-tracer pair
        return split
            
    def calc_amountbound(self):
        &#34;&#34;&#34;Calcualtes the fraction of tracer bound to the protein using the following formula: 
        L_B =( ( (λ*(rmin-rmax⁡)) / (r-rmin ) +1) )^(-1) * L_T
        Where L_B is the concentration of fluorescent tracer bound to the target protein, 
        L_T is the total tracer concertation,
        &#34;&#34;&#34;
        l = list(FA.final_fit[FA.final_fit[&#39;rmin&#39;].isna()].index)   # list of indexes for which rmin and rmax are not defined
        
        if l != []: 
            raise DataError(f&#34;The &#39;rmin&#39; and &#39;rmax&#39; values are not defined for the following protein-tracer pairs: {l}.\nUse &#39;calc_lambda&#39; function or &#39;set_fitparams&#39; to choose &#39;rmin&#39; and &#39;rmax&#39; values.&#34;)
                            
        for key, value in self.data_dict.items():
            metadata, data = value.values()
            data[&#39;amount_bound&#39;] = FA._amount_bound(data[&#39;r_corrected&#39;], self.plate_map, FA.final_fit)   # create dictionary &#39;r_mean&#39; with mean anisotropy data frames for each protein-tracer pair
            
            
    ##### Curve fitting functions #####        
            
    def _r_func(pc, rmin, rmax, EC50, hill):
        &#34;&#34;&#34;Function for fitting a curve to the plot of anisotropy (or intensity) against protein concentration, 
        where pc is protein concentration, rmin is the lower asymptote, rmax is the upper asymptote, 
        EC50 is midpoint of transition (pc at point of inflection), hill is the slope
        &#34;&#34;&#34;
        return (rmin - rmax) / (1 + (pc/EC50)**hill) + rmax
    
    def _init_params(df):
        &#34;&#34;&#34;Estimates initial parameters for the r_func that are passed to the curve fitting function
        
        :param df: Data frame containing mean values of anisotropy or intensity
        :type df: pandas df
        :return: List with estiamted parameters of min, max and EC50, hill is assumed to be 1
        :rtype: list
        &#34;&#34;&#34;
        rmin = df[&#39;mean&#39;].min()
        rmax = df[&#39;mean&#39;].max()
        mid = (rmax + rmin) / 2
        mid_idx = df[&#39;mean&#39;].sub(mid).abs().argmin()
        EC50 = df.iloc[mid_idx][&#39;Protein Concentration&#39;]
        init_param = [rmin, rmax, EC50, 1]
        return init_param
    
    def _logistic_fit(df, **kwargs):
        &#34;&#34;&#34;Fits a curve to the plot of anisotropy (or intensity) against protein concentration
        
        :param df: Data frame containing mean values of anisotropy (or intensity)
        :type df: pandas df
        :param sig: A string specifying the error data passed to the SciPy curve_fit function, either &#39;std&#39; or &#39;sem&#39;, default None
        :type sig: str
        :param **kwargs: Keyword arguments that can be passed into the scipy curve_fit function
        :return: A list of fitting parameters along with their error in proper order so that it can be added to the fitting params data frame
        :rtype: list
        &#34;&#34;&#34;
        drop = df[df[&#39;Protein Concentration&#39;] != 0].dropna(subset=[&#39;mean&#39;])   # exclude the protein concentration = 0 point and any NaN mean values from data fitting
        
        if &#39;sigma&#39; in kwargs:  
            sigma = drop[kwargs.pop(&#39;sigma&#39;)]   # take the column with std or sem error data
        else:
            sigma = None
            
        if &#39;p0&#39; not in kwargs:   # user did not pass their initial guess
            p0 = FA._init_params(drop)
        else:   # user provided initial guess, remove p0 from kwargs and assign to p0 argument so that there is only one p0 arg passed to curve fit 
            p0 = kwargs.pop(&#39;p0&#39;)
                              
        popt, pcov = curve_fit(FA._r_func, drop[&#39;Protein Concentration&#39;], drop[&#39;mean&#39;], p0=p0, sigma=sigma, **kwargs)
        perr = np.sqrt(np.diag(pcov))   # calculate the error of the fitting params
        all_params = np.insert(popt, obj=[1,2,3,4], values=perr)   # insert the errors after the respective fitting parameter value
        return list(all_params) 
    
    def logistic_fit(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], var=&#39;both&#39;, **kwargs):
        &#34;&#34;&#34;Fits a logistic curve to the plot of anisotropy (or intensity) against protein concentration.
        Returns the fitting parameters with associated errors for each repeat that are stored in the fitting paramters data frame in data dict.
        The calc_data_to_fit function must be executed prior to data fitting.
        
        :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param var: A variable for which the graphs are exported, can be either &#39;r&#39; for anisotropy or &#39;i&#39; for inteensity, defaults to &#39;both&#39;
        :type var: str
        :param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        errors = []   # list for storing the details of errors due to failed fitting
        
        for rep, value in data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            
            for pt_pair in pt_pairs:   # iterate over all protein-tracer pairs
                if var == &#39;r&#39; or var == &#39;both&#39;:
                    try:   # try fitting the curve to anisotropy data 
                        r_mean = data[&#39;r_mean&#39;][pt_pair]   # extract the df with mean anisotropy for a given protein-tracer pair
                        params_r = FA._logistic_fit(r_mean, **kwargs)   # fit the data to logistic curve using the initial parameteers
                        data[&#39;fit_params&#39;].loc[pt_pair, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;, &#39;rmax error&#39;, &#39;r_EC50&#39;, &#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;]] = params_r   # add the fitting parameters to the respective df

                    except RuntimeError as e:   # if fitting fails, added details about the error to the errors list and proceed intensity data fitting
                        r_errorinfo = (rep, &#39;r&#39;, pt_pair, e)
                        errors.append(r_errorinfo)
                
                if var == &#39;i&#39; or var == &#39;both&#39;:
                    try:   # try fitting the curve to intensity data
                        i_mean = data[&#39;i_mean&#39;][pt_pair]   # extract the df with i mean for a given protein-tracer pair
                        params_i = FA._logistic_fit(i_mean, **kwargs)
                        data[&#39;fit_params&#39;].loc[pt_pair, [&#39;Ifree&#39;, &#39;Ifree error&#39;, &#39;Ibound&#39;,&#39;Ibound error&#39;, &#39;I_EC50&#39;, &#39;I_EC50 error&#39;, &#39;I_hill&#39;, &#39;I_hill error&#39;]] = params_i

                    except RuntimeError as e:   # if fitting fails, added details about the error to the errors list and proceed to to the next protein-tracer pair
                        i_errorinfo = (rep, &#39;i&#39;, pt_pair, e)
                        errors.append(i_errorinfo)

        if errors != []:   # raise a warning if fitting failed for any protein-tracer pair
            warnings.warn(f&#34;The curve fitting failed in the following cases:\n\n{errors}\n\nTry passing additional keyword arguments to the fitting function.&#34;, RuntimeWarning)
                    
            
    def _LB(LT, PT, Kd):
        &#34;&#34;&#34;Function for fitting a curve to the plot of concentration of fluorescent tracer bound to the target protein against
        protein concentration.
        LB is the concentration of fluorescent tracer bound to the target protein
        LT is total protein concentration
        PT is total tracer concentration
        Kd is dissociation constant
        &#34;&#34;&#34;
        return ( (LT+PT+Kd) - np.sqrt( ( ((LT+PT+Kd)**2) - (4*LT*PT) ) ) ) / 2 
    

    def single_site_fit(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], **kwargs):
        &#34;&#34;&#34;Fits a curve to the plot of concentration of fluorescent tracer bound to the target protein against the 
        total protein concentration. 
        
        :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        errors = []   # list for storing the details of errors due to failed fitting
        
        if &#39;sigma&#39; in kwargs:  
            sigma = drop[kwargs.pop(&#39;sigma&#39;)]   # take the column with std or sem error data
        else:
            sigma = None
        
        for rep, value in data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            keys = list(data[&#39;amount_bound&#39;].keys())   # create a list of unique protein-tracer pairs
            
            for pt_pair in pt_pairs:   # iterate over all protein-tracer pairs
                try:   # try fitting the curve to anisotropy data 
                    amount_b = data[&#39;amount_bound&#39;][pt_pair]   # extract the df with mean amount bound for a given protein-tracer pair
                    drop = amount_b[ (amount_b[&#39;Protein Concentration&#39;] != 0) &amp; (amount_b[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
                    
                    if len(drop[&#39;Tracer Concentration&#39;].dropna().unique()) == 1:   # check if the protein is titrated to a constant amount of tracer
                        x_data, label = drop[&#39;Protein Concentration&#39;], [&#39;LT&#39;, &#39;LT error&#39;]   
                    if len(drop[&#39;Protein Concentration&#39;].dropna().unique()) == 1:   # check if the tracer is titrated to a constant amount of protein
                        x_data, label = drop[&#39;Tracer Concentration&#39;], [&#39;PT&#39;, &#39;PT error&#39;]
                    
                    popt, pcov = curve_fit(FA._LB, x_data, drop[&#39;amount&#39;], sigma=sigma, **kwargs)
                    err = np.sqrt(np.diag(pcov))
                    FA.final_fit.loc[pt_pair, ([&#39;Kd&#39;, &#39;Kd error&#39;]+label)] = [popt[1], err[1], popt[0], err[0]]   # add Kd and its error to final fit df
                    
                except RuntimeError as e:  
                    error_info = (rep, pt_pair, e)
                    errors.append(error_info)
                
        if errors != []:   # raise a warning if fitting failed for any protein-tracer pair
            warnings.warn(f&#34;The curve fitting failed in the following cases:\n\n{errors}\n\nTry passing additional keyword arguments to the fitting function&#34;, RuntimeWarning)
    
    ##### Anisotropy and biniding constant plotting functions #####
    
    def _get_items_to_plot(data_d, platemap, prot, trac, rep):
        &#34;&#34;&#34;Creates a list of tuples with protein-tracer names based on the &#39;prot&#39; and &#39;trac&#39; parameters 
        and a subset of data_dict based on the &#39;rep&#39; parameter.
        &#34;&#34;&#34;
        if prot[0] == &#39;all&#39; and trac[0] == &#39;all&#39;:   # all proteins and all tracers
            pt_pairs = list(data_d[&#39;repeat_1&#39;][&#39;data&#39;][&#39;r_mean&#39;].keys())   # &#39;r_mean&#39; dict contains all protein-tracer names as dict keys
            
        elif prot[0] != &#39;all&#39; and trac[0] == &#39;all&#39;:   # all tracers and some proteins
            trac = list(platemap[&#39;Tracer Name&#39;].dropna().unique())   # take all tracer names from the platemap
            pt_pairs = [item for item in product(prot, trac)]
            
        elif prot[0] == &#39;all&#39; and trac[0] != &#39;all&#39;:   # all proteins and some tracers
            prot = list(platemap[&#39;Protein Name&#39;].dropna().unique())   # take all protein names from the platemap
            pt_pairs = [item for item in product(prot, trac)]
            
        elif prot[0] != &#39;all&#39; and trac[0] != &#39;all&#39;:   # some proteins and some tracers
            pt_pairs = [item for item in product(prot, trac)]
        
        # define a data dictionary to iterate through based on the &#39;rep&#39; parameter:
        if rep[0] == &#39;all&#39;:   # for all repeats use the whole data_dict
            data_dict = data_d
        else:   # for specific repeats use the subset of data_dict containg only the repeats specified in &#39;rep&#39; parameter
            data_dict = {key: value for key, value in data_d.items() if int(key[-1]) in rep}
        
        return data_dict, pt_pairs
    
    
    def _plot_ani(data_df, params_df, pt_pair, fig, axs, err, var, rep, export, display, labels, dpi=250):
        &#34;&#34;&#34;General function for plotting the anisotropy and intensity and saving the figures.
        
        :param data_df: Data frame with mean values of anisotropy or intensity and their associated errors
        :type data_df: pandas df
        :params_df: Data frame with fitting parameters
        :type params_df: pandas df
        :param pt_pair: protein-tracer pair for which the graph is to be generated
        :type pt_pair: tuple
        :param fig: Figure on which the data is plotted, needed for saving the figure as png file
        :type fig: matplotlib Figure
        :param axs: Indexed axis object on which the data is to be plotted, (e.g. axs[0, 1])
        :type axs: matplotlib AxesSubplot
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param var: Variable for which the plot is to be generated (&#39;r&#39; or &#39;i&#39;)
        :type var: str
        :param repeat: Repeat number for labelling of the graph
        :type repeat: &#39;str&#39;
        :param export: Determines whether the figure will be saved, can be either bool or string with directory path
        :type export: bool or &#39;str&#39;
        :param display: Determines whether the figure will be displayed after plotting, default True
        :type display: bool
        :param labels: Determines whether the legend and box with fitting parameters will be displayed on the figure, default True
        :type labels: bool
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        #r = [i for i in list(params_df.columns) if i[0]==&#39;r&#39; and i[-1] != &#39;r&#39;]
        #rp = params_df.loc[pt_pair, r].to_list()
        if var == &#39;r&#39;:   # define the parameters, legend text and legend coordinates characteristic for anisotropy data
            params = [params_df.loc[pt_pair, &#39;rmin&#39;], params_df.loc[pt_pair, &#39;rmax&#39;], params_df.loc[pt_pair, &#39;r_EC50&#39;], params_df.loc[pt_pair, &#39;r_hill&#39;]]
            #text = &#34;$r_{min}$ = %.2f \u00B1 %.4f\n$r_{max}$ = %.2f \u00B1 %.4f\n$EC_{50}$ = %.0f \u00B1%.0f\n$hill$ = %.2f \u00B1 %.2f&#34; % (params_df.loc[pt_pair, &#39;rmin&#39;], 
            #    params_df.loc[pt_pair, &#39;rmin error&#39;], params_df.loc[pt_pair, &#39;rmax&#39;], params_df.loc[pt_pair, &#39;rmax error&#39;], 
            #    params_df.loc[pt_pair, &#39;r_EC50&#39;], params_df.loc[pt_pair, &#39;r_EC50 error&#39;], params_df.loc[pt_pair, &#39;r_hill&#39;], params_df.loc[pt_pair, &#39;r_hill error&#39;])
            text = &#34;$r_{min}$ = %.2f \u00B1 %.4f\n$r_{max}$ = %.2f \u00B1 %.4f\n$EC_{50}$ = %.0f \u00B1%.0f\n$hill$ = %.2f \u00B1 %.2f&#34; % tuple(params_df.loc[pt_pair, [&#39;rmin&#39;,
            &#39;rmin error&#39;,&#39;rmax&#39;,&#39;rmax error&#39;,&#39;r_EC50&#39;,&#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;]])
            
            label_coords = (0.02, 0.68)
            ylabel = &#39;Anisotropy&#39;
            
        if var.lower() == &#39;i&#39;:   # define the parameters, legend text and legend coordinates characteristic for intensity data
            params = [params_df.loc[pt_pair, &#39;Ifree&#39;], params_df.loc[pt_pair, &#39;Ibound&#39;], params_df.loc[pt_pair, &#39;I_EC50&#39;], params_df.loc[pt_pair, &#39;I_hill&#39;]]
            text = &#34;$I_{free}$ = %.0f \u00B1 %.0f\n$I_{bound}$ = %.0f \u00B1 %.0f\n$EC_{50}$ = %.0f \u00B1 %.0f\n$hill$ = %.2f \u00B1 %.2f&#34; % (params_df.loc[pt_pair, &#39;Ifree&#39;], 
                params_df.loc[pt_pair, &#39;Ifree error&#39;], params_df.loc[pt_pair, &#39;Ibound&#39;], params_df.loc[pt_pair, &#39;Ibound error&#39;], 
                params_df.loc[pt_pair, &#39;I_EC50&#39;], params_df.loc[pt_pair, &#39;I_EC50 error&#39;], params_df.loc[pt_pair, &#39;I_hill&#39;], params_df.loc[pt_pair, &#39;I_hill error&#39;])
            label_coords = (0.02, 0.03)
            ylabel = &#39;Intensity&#39;
        
        drop = data_df[data_df[&#39;Protein Concentration&#39;] != 0].dropna(subset=[&#39;mean&#39;])   # exclude the protein concentration = 0 point and any NaNs from plotting
        axs.errorbar(drop[&#39;Protein Concentration&#39;], drop[&#39;mean&#39;], yerr=drop[err], color=&#39;black&#39;, fmt=&#39;o&#39;, capsize=3, marker=&#39;s&#39;)
        axs.set_xscale(&#39;symlog&#39;)
        axs.set_ylabel(ylabel)
        axs.set_xlabel(f&#39;[{pt_pair[0]}] (nM)&#39;)
        axs.plot(drop[&#39;Protein Concentration&#39;], FA._r_func(drop[&#39;Protein Concentration&#39;], *params), color=&#39;blue&#39;)
        
        if labels == True:   # display legend and a box with fitting parameters on the graph
            axs.set_title(f&#39;Protein: {pt_pair[0]}, Tracer: {pt_pair[1]}&#39;)
            axs.legend([&#39;logistic fitted curve&#39;], frameon=False, fontsize=11)
            axs.annotate(text, xy=label_coords, xycoords=&#39;axes fraction&#39;, fontsize=11)
            
        if export == True:   # save figures in the same directory as the notebook
            fig.savefig(f&#34;{rep}_{var}_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
        
        if type(export) == str:   # save figures in the user defined directory
            fig.savefig(f&#34;{export}{rep}_{var}_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
        
        if display == False:   
            plt.close(fig)
                
   
    def plot_ani(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], err=&#39;std&#39;):   
        &#34;&#34;&#34;Plots anisotropy and intensity against protein concentration with a fitted logistic curve for specific repeats and 
        protein-tracer pairs. A separate figure for each repeat is created with anisotropy and intensity graphs for all 
        specified proteins and tracers side by side. 
        
        :param prot: List of protein names for which the graphs are created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs are created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs are created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        
        for key, value in data_dict.items():   # iterte over all repeats and create a sperate figure for each repeat
            metadata, data = value.values()
            fig, axs = plt.subplots(len(pt_pairs), 2, figsize=(2*6.4, len(pt_pairs)*4.8), tight_layout=True)   # grid for subplots has two columns and a variable number of rows, figsize automatically scales up
            fig.suptitle(f&#34;Repeat {key[-1]}&#34;, fontsize=16)

            for idx, pt_pair in enumerate(pt_pairs):   # for each portein-tracer pair plot two graphs: anisotropy and intensity
                r_data_df = data[&#39;r_mean&#39;][pt_pair]   # extract the df with anisotropy
                i_data_df = data[&#39;i_mean&#39;][pt_pair]   # and intensity
                
                if len(pt_pairs) == 1:   # for only one protein-tracer pair the subplot grid 1-dimensional
                    FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[0], err=err, var=&#39;r&#39;, rep=key, export=False, display=True, labels=True)
                    FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[1], err=err, var=&#39;i&#39;, rep=key, export=False, display=True, labels=True)
                else:   # for more than one protein-tracer pair the subplot grid 2-dimensional
                    FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[idx,0], err=err, var=&#39;r&#39;, rep=key, export=False, display=True, labels=True)
                    FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[idx,1], err=err, var=&#39;i&#39;, rep=key, export=False, display=True, labels=True)
                

    def save_ani_figs(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], var=&#39;both&#39;, path=&#39;&#39;, err=&#39;std&#39;, leg=False, dpi=250):
        &#34;&#34;&#34;Saves single figures of anisotropy and intensity for each protein-tracer pair for all repeats in the same directory as this notebook or
        in user defined directory if the path is provided.
        
        :param prot: List of protein names for which the graphs are exported, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs are exported, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs are exported, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param var: A variable for which the graphs are exported, can be either &#39;r&#39; for anisotropy or &#39;i&#39; for inteensity, defaults to &#39;both&#39;
        :type var: str
        :param path: A path to directory in which the figures are saved, defaults to &#39;&#39; (the same directory as the Jupyter Notebook)
        :type path: str
        :param err: A string representing type of error data to displayed as error bars, either &#39;std&#39; or &#39;sem&#39;, default &#39;std&#39;
        :type err: str
        :param leg: Display legend on the figures, defaults to False
        :type leg: bool
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        # get data_dict and a list of protein-tracer names
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        
        for key, value in self.data_dict.items():   # iterate over all repeats
            metadata, data = value.values()
            pairs = list(data[&#39;r_mean&#39;].keys())   # generate a list of protein-tracer names
                                
            for pt_pair in pairs:   # iterate over each protein-tracer pair in
                if var == &#39;r&#39; or var == &#39;both&#39;:
                    r_data_df = data[&#39;r_mean&#39;][pt_pair]   # extract the df with anisotropy
                    fig_r, ax_r = plt.subplots(figsize=(6.4, 4.8), tight_layout=True)   # create a figure with a single axis for anisotropy 
                    FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig_r, axs=ax_r, err=err, var=&#39;r&#39;, rep=key, export=path, display=False, labels=leg, dpi=dpi)
                
                if var == &#39;i&#39; or var == &#39;both&#39;:
                    i_data_df = data[&#39;i_mean&#39;][pt_pair]   
                    fig_i, ax_i = plt.subplots(figsize=(6.4, 4.8), tight_layout=True)   
                    FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig_i, axs=ax_i, err=err, var=&#39;i&#39;, rep=key, export=path, display=False, labels=leg, dpi=dpi)
        
        print(&#39;The figures were successfully exported.&#39;)
    
    def _plot_kd(data_df, rep, pt_pair, err, leg, exp, dpi):
        &#34;&#34;&#34;Plots amount bound against protein or tracer concentration with a fitted curve on a separate figure for a specific protein-tracer pair.
        
        :param data_df: Data frame with mean values of amount of tracer bound and their associated errors
        :type data_df: pandas df
        :param rep: Repeat number for labelling of the graph
        :type rep: &#39;str&#39;
        :param pt_pair: Protein and tracer names for which data will be plotted
        :type pt_pair: tuples
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param leg: Determines whether the legend and box with fitting parameters will be displayed on the figure, default True
        :type leg: bool
        :param exp: Determines whether the figure will be saved, can be either bool or string with directory path
        :type exp: bool or &#39;str&#39;
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        drop = data_df[ (data_df[&#39;Protein Concentration&#39;] != 0) &amp; (data_df[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
        fig, axs = plt.subplots(1, 1, figsize=(6.4, 4.8), tight_layout=True)
        
        # define the x axis data and labels for protein and tracer titration cases
        if len(drop[&#39;Tracer Concentration&#39;].unique()) == 1:   
            text = &#39;$L_{T}$ = %.2f\u00B1 %.2f\n$K_{d}$ = %.2f \u00B1 %.2f&#39; % (FA.final_fit.loc[pt_pair, &#39;LT&#39;], 
                FA.final_fit.loc[pt_pair, &#39;LT error&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;], FA.final_fit.loc[pt_pair, &#39;Kd error&#39;])  
            x_data = drop[&#39;Protein Concentration&#39;]
            x_label = pt_pair[0]
            params = [FA.final_fit.loc[pt_pair, &#39;LT&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;]]
        
        if len(drop[&#39;Protein Concentration&#39;].unique()) == 1:
            text = &#39;$P_{T}$ = %.2f\u00B1 %.2f\n$K_{d}$ = %.2f \u00B1 %.2f&#39; % (FA.final_fit.loc[pt_pair, &#39;PT&#39;], 
                FA.final_fit.loc[pt_pair, &#39;PT error&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;], FA.final_fit.loc[pt_pair, &#39;Kd error&#39;])  
            x_data = drop[&#39;Tracer Concentration&#39;]
            x_label = pt_pair[1]
            params = [FA.final_fit.loc[pt_pair, &#39;PT&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;]]
            
        axs.errorbar(x_data, drop[&#39;amount&#39;], yerr=drop[err], color=&#39;black&#39;, fmt=&#39;o&#39;, capsize=3, marker=&#39;s&#39;)
        axs.set_xscale(&#39;symlog&#39;)
        axs.set_ylabel(&#39;[Fluorescent Tracer Bound] (nM)&#39;)
        axs.set_xlabel(f&#39;[{x_label}] (nM)&#39;)
        axs.plot(x_data, FA._LB(x_data, *params), color=&#39;blue&#39;)
        
        if leg == True:   # display the figure title, legend and annotation with fitting params
            axs.set_title(f&#39;Repeat {rep[-1]}, Protein: {pt_pair[0]}, Tracer: {pt_pair[1]}&#39;)
            axs.legend([f&#39;single site fitted curve&#39;], fontsize=11, frameon=False)
            axs.annotate(text, xy=(0.02, 0.80), xycoords=&#39;axes fraction&#39;, fontsize=11)
        plt.show()
        
        if exp == True:   # save the figure to the same directory as the notebook
            fig.savefig(f&#34;{rep}_Kd_plot_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
        if type(exp) == str:   # save the figure to user defined directory
            fig.savefig(f&#34;{exp}{rep}_Kd_plot_{str(pt_pair[0])}_{str(pt_pair[1])}.png&#34;, dpi=dpi)
    
    def _overlay_kd_plots(plate_map, data_dict, pt_pairs, err, leg, exp, dpi):   
        &#34;&#34;&#34;Creates a figure with overlayed plots for specified protein-tracer pairs and repeats 
        
        :param plate_map: Platemap
        :type plate_map: pandas df
        :param data_dict: Data dictionary containing the specific repeats for which data will be plotted
        :type data_dict: dict
        :param pt_pairs: List of protein-tracer names for which data will be plotted
        :type pt_pairs: list of tuples
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param leg: Determines whether the legend and box with fitting parameters will be displayed on the figure, default True
        :type leg: bool
        :param exp: Determines whether the figure will be saved, can be either bool or string with directory path
        :type exp: bool or &#39;str&#39;
        :param dpi: Resolution of the figure in points per inch
        :type dpi: int
        &#34;&#34;&#34;
        # define the x axis data and labels for protein and tracer titration cases
        if len(plate_map[&#39;Tracer Concentration&#39;].dropna().unique()) == 1:     
            x_data_label, x_label, param = &#39;Protein Concentration&#39;, &#39;Protein&#39;, &#39;LT&#39;
        
        if len(plate_map[&#39;Protein Concentration&#39;].dropna().unique()) == 1:   
            x_data_label, x_label, param = &#39;Tracer Concentration&#39;, &#39;Tracer&#39;, &#39;PT&#39;

        fig, axs = plt.subplots(1, 1, figsize=(6.4, 4.8), tight_layout=True) 
        leg_text = []   # list to store the legend text
        cmaps = [&#39;Blues&#39;, &#39;Greens&#39;, &#39;Oranges&#39;, &#39;Purples&#39;, &#39;Reds&#39;, &#39;Greys&#39;, &#39;YlOrBr&#39;, &#39;YlOrRd&#39;, &#39;OrRd&#39;, &#39;PuRd&#39;, &#39;RdPu&#39;, &#39;BuPu&#39;,
            &#39;GnBu&#39;, &#39;PuBu&#39;, &#39;YlGnBu&#39;, &#39;PuBuGn&#39;, &#39;BuGn&#39;, &#39;YlGn&#39;]
        iter_cmaps = iter(cmaps)
        
        for key, value in data_dict.items():   # iterte through all repeats of the defined data_dict
            metadata, data = value.values()
            
            for pt_pair in pt_pairs:    # iterate through the list of protein-tracer names to plot its data on the same figure
                
                data_df = data[&#39;amount_bound&#39;][pt_pair]   # extract the correct df with amount bound for a given protein-tracer pair
                drop = data_df[ (data_df[&#39;Protein Concentration&#39;] != 0) &amp; (data_df[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
                x_data = drop[x_data_label]
                params = [FA.final_fit.loc[pt_pair, param], FA.final_fit.loc[pt_pair, &#39;Kd&#39;]]

                text2 = &#39;$L_{T}$ = %.2f\u00B1 %.2f\n$K_{d}$ = %.2f \u00B1 %.2f&#39; % (FA.final_fit.loc[pt_pair, &#39;LT&#39;], 
                    FA.final_fit.loc[pt_pair, f&#39;LT error&#39;], FA.final_fit.loc[pt_pair, &#39;Kd&#39;], FA.final_fit.loc[pt_pair, &#39;Kd error&#39;])  
                text = f&#34;rep {key[-1]}, {pt_pair[0]}, {pt_pair[1]}\n{text2}&#34;
                leg_text.append(text)
                
                cmap = plt.cm.get_cmap(next(iter_cmaps))   # take the next color map from the list 
                axs.errorbar(x_data, drop[&#39;amount&#39;], yerr=drop[err], fmt=&#39;o&#39;, capsize=3, marker=&#39;s&#39;, color=cmap(0.95))
                axs.plot(x_data, FA._LB(x_data, *params), color=cmap(0.50))  
                
        axs.set_xscale(&#39;symlog&#39;)
        axs.set_ylabel(&#39;[Fluorescent Tracer Bound] (nM)&#39;)
        axs.set_xlabel(f&#39;[{x_label}] (nM)&#39;)

        if leg == True:   # display the figure title, legend and annotation with fitting params
            axs.set_title(f&#39;Overlayed plot&#39;)
            lbox = axs.legend(leg_text, fontsize=11, frameon=False, loc=&#39;upper left&#39;, bbox_to_anchor=(1.03, 0.95))#, bbox_transform=fig.transFigure)#, xycoords=&#39;axes fraction&#39;)
            fig.canvas.draw()   # draw the  canvas so that figure and legend size is defined
            # calculate length by which the figure will be widened to accomodate the legend
            w = (lbox.get_window_extent().width + (0.06 * axs.get_window_extent().width)) / fig.dpi
            fig.set_size_inches(6.4 + w, 4.8)   # resize the figure
            
        plt.show()
        
        if exp == True:   # save the figure to the same directory as the notebook
            fig.savefig(f&#34;Overlayed_Kd_plot.png&#34;, dpi=dpi) #
        if type(exp) == str:   # save the figure to user defined directory
            fig.savefig(f&#34;{exp}Overlayed_Kd_plot.png&#34;,dpi=dpi)
        
        
    def plot_kd(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], err=&#39;std&#39;, overlay=False, legend=True, export=False, dpi=250):   
        &#34;&#34;&#34;Plots the concentration of fluorescent tracer bound to target protein against the protein (or tracer) concentration.
        
        :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type prot: list of str
        :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
        :type trac: list of str
        :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
        :type rep: list of ints
        :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
        :type err: str
        :param overlay: Overlayes the data on a single figure, defaults to False
        :type overlay: bool
        :param legend: Display the figure title and legend, defaults to True
        :type legend: bool
        :param export: Saves the figures as png files in the same location as the Notebook or in a specified directory
        :type export: bool or str
        :param dpi: Resolution of the exported figure in dots per inches
        :type dpi: int
        &#34;&#34;&#34;
        data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
        
        if overlay == False:
            for key, value in data_dict.items():   # iterte through all repeats of the defined data_dict
                metadata, data = value.values()

                for pt_pair in pt_pairs:    # iterate through the list of protein-tracer names to create a separate figure for each pair
                    data_df = data[&#39;amount_bound&#39;][pt_pair]   # extract the correct df with amount bound for a given protein-tracer pair
                    FA._plot_kd(data_df=data_df, rep=key, pt_pair=pt_pair, err=err, leg=legend, exp=export, dpi=dpi)
        else:
            FA._overlay_kd_plots(plate_map=self.plate_map, data_dict=data_dict, pt_pairs=pt_pairs, err=err, leg=legend, exp=export, dpi=dpi)
        
        
    ##### Fittig params set, export and import functions #####
        
    def set_fitparams(self, pair, final=True, rep=None, **kwargs):
        &#34;&#34;&#34;Allows to set a value of any parameter in the final fit data frame (by default) or in fit_params data frame 
        for a specific protein-tracer pair.
        
        :param pair: A tuple wtih protein and tracer names for which the parameters are changed
        :type pair: tuple
        :param final: If True, the parameters will be changed in the final_fit data frame, otherwise in the fitting param data frame
        :type final: bool
        :param rep: Repeat number for which the fit_params data frame will be modified, passed only if the final=False, defaults to None
        :type rep: int
        :param **kwargs: Keyword arguments represeting the parameter and its value, e.g. lambda=1.5, rmin=0.30
        &#34;&#34;&#34;
        if final == True:
            for key, value in kwargs.items():   # iterate over the kwargs dictionary
                FA.final_fit.loc[pair, key] = value   # overwrite the parameters in fitting params df with all params passed as keyword arguments
        
        if final == False: 
            for key, value in kwargs.items():   # iterate over the kwargs dictionary
                self.data_dict[f&#39;repeat_{rep}&#39;][&#39;data&#39;][&#39;fit_params&#39;].loc[pair, key] = value   # overwrite the parameters in fitting params df with all params passed as keyword arguments

    def export_params(self, path=&#39;&#39;, file_type=&#39;csv&#39;):
        &#34;&#34;&#34;Export the final fit parameters and the fitting parameters for each repeat to csv or excel files.
        
        :param path: A path to directory in which the file is saved, defaults to &#39;&#39; (i.e. the same directory as this Jupyter Notebook)
        :type path: str
        :param file_type: Type of file generated, either &#39;csv&#39; or &#39;excel&#39; file, defaults to csv
        :type file_type: &#39;str&#39;
        &#34;&#34;&#34;
        if file_type == &#39;csv&#39;:   # export as csv file
            FA.final_fit.to_csv(path_or_buf=f&#34;{path}final_fit_parameters.csv&#34;)
        if file_type == &#39;excel&#39;:   # export as excel file
            FA.final_fit.to_excel(excel_writer=f&#34;{path}final_fit_parameters.xlsx&#34;)
    
        for key, value in self.data_dict.items():   #iterate over all repeats
            metadata, data = value.values()
            
            if file_type == &#39;csv&#39;:   # export as csv file
                data[&#39;fit_params&#39;].to_csv(path_or_buf=f&#34;{path}{key}_fitting_parameters.csv&#34;)
            if file_type == &#39;excel&#39;:   # export as excel file
                data[&#39;fit_params&#39;].to_excel(excel_writer=f&#34;{path}single_repeat_fitting_parameters.xlsx&#34;, sheet_name=f&#39;{key}&#39;)
        
        print(f&#39;The fitting parameters were exported to the {file_type} files.&#39;)
        
        
    def import_params(self, csv_file):
        &#34;&#34;&#34;Allows to import a csv file with final_fit parameters (i.e. rmin, rmax, lamda, Kd and their errors).
        
        :param csv_file: A csv file path with parameters to be imported
        :type csv_file: str
        &#34;&#34;&#34;
        with open(csv_file) as file:   # read the csv into pandas df
            df = pd.read_csv(file, sep=&#39;,&#39;, index_col=[0,1], engine=&#39;python&#39;, encoding=&#39;utf-8&#39;)   # import with multiindex
            indexes = list(df.index)   # create a list with protein-tracer names
        
        for col in df.columns:   # iterate over the imported columns
            if col not in FA.final_fit.columns:   # if there is no such column in final_fit df, raise a warning, otherwise column with wrong name will be added to final_fit
                warnings.warn(f&#34;The final_fit data frame does not contain matching columns: &#39;{col}&#39;&#34;)
            else:   # overwrite the existing values in the final_fit df with the ones from imported df
                FA.final_fit.loc[FA.final_fit.index.intersection(indexes), col] = df.loc[df.index.intersection(indexes), col]</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.read_in_envision"><code class="name flex">
<span>def <span class="ident">read_in_envision</span></span>(<span>data_csv, platemap_csv, data_type='plate', size=384)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dictionary of data frames, g-factor and platemap needed to construct the class object. </p>
<p>:param data_csv: File path of the raw data file in .csv format
:type data_csv: str
:param platemap_csv: File path of the platemap file in .csv format
:type platemap_csv: str
:param data_type: Format in which the raw data was exported (plate or list), defaults to plate
:type data_type: str
:param size: Size of the well plate (384 or 96), defaults to 384
:type size: int
:return: A dictionary contaning data frames with pre-processed data, g-factor, pandas data frame containing platemap
:rtype: dict, float, pandas data frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def read_in_envision(cls, data_csv, platemap_csv, data_type=&#39;plate&#39;, size=384):
    &#34;&#34;&#34;Returns a dictionary of data frames, g-factor and platemap needed to construct the class object. 
    
    :param data_csv: File path of the raw data file in .csv format
    :type data_csv: str
    :param platemap_csv: File path of the platemap file in .csv format
    :type platemap_csv: str
    :param data_type: Format in which the raw data was exported (plate or list), defaults to plate
    :type data_type: str
    :param size: Size of the well plate (384 or 96), defaults to 384
    :type size: int
    :return: A dictionary contaning data frames with pre-processed data, g-factor, pandas data frame containing platemap
    :rtype: dict, float, pandas data frame &#34;&#34;&#34;
    
    # ensure the plate size is either 384 or 96
    if size not in plate_dim:
        raise PlateSizeError(&#39;Invalid size of the well plate, should be 384 or 96.&#39;)
    
    # try to read in data in plate format
    if data_type == &#39;plate&#39;:
        try:
            data_dict, g_factor = FA._read_in_plate(data_csv, size=size)
            plate_map_df = pm.plate_map(platemap_csv, size=size)
            return cls(data_dict, g_factor, plate_map_df)
        
        except (UnboundLocalError, IndexError, ValueError):
            raise DataError(f&#34;Error occured during data read in. Check your file contains data in the &#39;plate&#39; format and plate size is {size}.&#34;)
    
    # try to read in data in list format
    if data_type == &#39;list&#39;:
        try:
            data_dict, g_factor = FA._read_in_list(data_csv, size=size)
            plate_map_df = pm.plate_map(platemap_csv, size=size)
            return cls(data_dict, g_factor, plate_map_df)
        
        except (UnboundLocalError, IndexError):
            raise DataError(&#34;Error occured during data read in. Check your file contains data in the &#39;list&#39; format.&#34;)
    
    else:
        raise DataTypeError(f&#34;&#39;{data_type}&#39; is not one of the two valid data types: plate or list.&#34;)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.background_correct"><code class="name flex">
<span>def <span class="ident">background_correct</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate background corrected values for p and s channel in all repeats.</p>
<p>Cacluclated by subtracting the mean value of blank p or s for a given concentration from each value of compound p or s for that concentration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def background_correct(self):
    &#34;&#34;&#34;Calculate background corrected values for p and s channel in all repeats.
    
    Cacluclated by subtracting the mean value of blank p or s for a given concentration from each value of compound p or s for that concentration.&#34;&#34;&#34;
    
    for key, value in self.data_dict.items(): 
        metadata, data = value.values()   

        # create joined dfs of platemap and p or s
        p_df = self.plate_map.join(data[&#39;p&#39;])  
        s_df = self.plate_map.join(data[&#39;s&#39;])
        
        # calculate p and s corrected and add them to data dictionary
        self.data_dict[key][&#39;data&#39;][&#39;p_corrected&#39;] = FA._backg_correct(p_df, &#39;p_corrected&#39;)
        self.data_dict[key][&#39;data&#39;][&#39;s_corrected&#39;] = FA._backg_correct(s_df, &#39;s_corrected&#39;)
        
        print(&#39;Background correction has been successfully performed!&#39;)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.calc_amountbound"><code class="name flex">
<span>def <span class="ident">calc_amountbound</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calcualtes the fraction of tracer bound to the protein using the following formula:
L_B =( ( (λ*(rmin-rmax⁡)) / (r-rmin ) +1) )^(-1) * L_T
Where L_B is the concentration of fluorescent tracer bound to the target protein,
L_T is the total tracer concertation,</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_amountbound(self):
    &#34;&#34;&#34;Calcualtes the fraction of tracer bound to the protein using the following formula: 
    L_B =( ( (λ*(rmin-rmax⁡)) / (r-rmin ) +1) )^(-1) * L_T
    Where L_B is the concentration of fluorescent tracer bound to the target protein, 
    L_T is the total tracer concertation,
    &#34;&#34;&#34;
    l = list(FA.final_fit[FA.final_fit[&#39;rmin&#39;].isna()].index)   # list of indexes for which rmin and rmax are not defined
    
    if l != []: 
        raise DataError(f&#34;The &#39;rmin&#39; and &#39;rmax&#39; values are not defined for the following protein-tracer pairs: {l}.\nUse &#39;calc_lambda&#39; function or &#39;set_fitparams&#39; to choose &#39;rmin&#39; and &#39;rmax&#39; values.&#34;)
                        
    for key, value in self.data_dict.items():
        metadata, data = value.values()
        data[&#39;amount_bound&#39;] = FA._amount_bound(data[&#39;r_corrected&#39;], self.plate_map, FA.final_fit)   # create dictionary &#39;r_mean&#39; with mean anisotropy data frames for each protein-tracer pair</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.calc_data_to_fit"><code class="name flex">
<span>def <span class="ident">calc_data_to_fit</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates data required for fitting a curve to the plot of anisotropy (or intensity) against protein concentration.
The following data is calcualted for both intensity and anisotropy for all repeats: mean, standard devition and standard error.</p>
<p>Data frames for storing fitting parametres for each repeat ('fit_params') and a data frame for storing
final values of rmin, rmax and lambda for each protein-tracer pair are created.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_data_to_fit(self):
    &#34;&#34;&#34;Calculates data required for fitting a curve to the plot of anisotropy (or intensity) against protein concentration.
    The following data is calcualted for both intensity and anisotropy for all repeats: mean, standard devition and standard error.
    
    Data frames for storing fitting parametres for each repeat (&#39;fit_params&#39;) and a data frame for storing
    final values of rmin, rmax and lambda for each protein-tracer pair are created.
    &#34;&#34;&#34;
    for key, value in self.data_dict.items():
        metadata, data = value.values()
           
        data[&#39;r_mean&#39;] = FA._fitting_data(data[&#39;r_corrected&#39;], self.plate_map)   # create dictionary &#39;r_mean&#39; with mean anisotropy data frames for each protein-tracer pair
        data[&#39;i_mean&#39;] = FA._fitting_data(data[&#39;i_corrected&#39;], self.plate_map)   # create dictionary &#39;i_mean&#39; with mean intensity data frames for each protein-tracer pair
        # create data frame for storing the fitting params 
        data[&#39;fit_params&#39;] = pd.DataFrame(index=FA.final_fit.index, columns=[&#39;rmin&#39;,&#39;rmin error&#39;, &#39;rmax&#39;, f&#39;rmax error&#39;, &#39;r_EC50&#39;, &#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;, &#39;Ifree&#39;, &#39;Ifree error&#39;, &#39;Ibound&#39;, &#39;Ibound error&#39;, &#39;I_EC50&#39;, &#39;I_EC50 error&#39;, &#39;I_hill&#39;, &#39;I_hill error&#39;, &#39;lambda&#39;])   # create new df for storing the fitting parameters
        data[&#39;fit_params&#39;][&#39;lambda&#39;] = 1</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.calc_lambda"><code class="name flex">
<span>def <span class="ident">calc_lambda</span></span>(<span>self, approve=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates lambda value for each protein-tracer pair for all repeats. </p>
<p>If 'approve=True', a list with calcualted lambda values with checkboxes will be displayed. To approve the proposed value
tick the selected checkboxes and click 'Update' button. If 'approve=False', all of the calculated values will be saved and
the list with checkboxes will not be displayed. You can still amend any values in the fitting parameters data frame using the 'set_fitparams function.</p>
<p>:param approve: If True a list of checkboxes will be displayed to choose the lambda values that will be saved, default True
:type approve: bool
:return: If approve=True, return a list of calculated lambda values along with checkboxes to be approved,
else save the calulated lambda values in the fitting params data frames for each repeat</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_lambda(self, approve=True):
    &#34;&#34;&#34;Calculates lambda value for each protein-tracer pair for all repeats. 

    If &#39;approve=True&#39;, a list with calcualted lambda values with checkboxes will be displayed. To approve the proposed value 
    tick the selected checkboxes and click &#39;Update&#39; button. If &#39;approve=False&#39;, all of the calculated values will be saved and 
    the list with checkboxes will not be displayed. You can still amend any values in the fitting parameters data frame using the &#39;set_fitparams function.

    :param approve: If True a list of checkboxes will be displayed to choose the lambda values that will be saved, default True
    :type approve: bool
    :return: If approve=True, return a list of calculated lambda values along with checkboxes to be approved, 
    else save the calulated lambda values in the fitting params data frames for each repeat 
    &#34;&#34;&#34;
    w_info = []   # list of tuples with info (rep no, lambda value, etc) for generation of widgets
    
    for key, value in self.data_dict.items():   # iterate over all repeats
        metadata, data = value.values()
        df = data[&#39;fit_params&#39;].copy()    # create a copy of the fitting params df
        df[&#39;lambda&#39;] = df[&#39;Ibound&#39;]/df[&#39;Ifree&#39;]   # calculate the lambda value in a copied data frame
        
        if approve == False:   # if the user does not want to manually approve the proposed values
            self.data_dict[key][&#39;data&#39;][&#39;fit_params&#39;][&#39;lambda&#39;] = df[&#39;lambda&#39;]   # add the lambda values to fitting params df
            print(&#39;The lambda values were calculated and saved.&#39;)
        else:
            indexes = list(df.index)   # create list of tuples with protein-tracer names
            for item in indexes:   # iterate over each protein-tracer pair and create tuples with info needed for generation of widgets
                rating = 100
                tp = (key, item, rating, df.loc[item, &#34;lambda&#34;],  data[&#39;fit_params&#39;].loc[item, &#34;rmin&#34;],  data[&#39;fit_params&#39;].loc[item, &#34;rmax&#34;])   # tuples conataining repeat no., calculated lambda, and protein-tracer names
                w_info.append(tp)

    if approve == True:   # execute the function for displying and handling the widgets
        return FA._widget(self.data_dict, w_info, df)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.calculate_r_i"><code class="name flex">
<span>def <span class="ident">calculate_r_i</span></span>(<span>self, correct=True, plot_i=True, thr=80)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates anisotropy and fluorescence intensity.
The fluorescence intensity (I) and anisotropy (r) are calculated using the follwing formulas: I = s + (2<em>g</em>p), r = (s - (g*p)) / I and stored
in data_dict as i_raw and r_raw (calculated using the uncorrected p and s channel values)
and i_corrected and r_corrected (if calculated using the background corrected p and s channel values, as well).</p>
<p>:param correct: Calculate the anisotropy and intensity using the background corrected values of p and s, as well, default=True
:type correct: bool
:param plot_i: Displays plots of the percentage intensity against well ids for all repeats, defaults to True
:type plot_i: bool
:param th: Percentage intensity value above which the wells id will be reported
:type th: int</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_r_i(self, correct=True, plot_i=True, thr=80):
    &#34;&#34;&#34;Calculates anisotropy and fluorescence intensity.
    The fluorescence intensity (I) and anisotropy (r) are calculated using the follwing formulas: I = s + (2*g*p), r = (s - (g*p)) / I and stored 
    in data_dict as i_raw and r_raw (calculated using the uncorrected p and s channel values) 
    and i_corrected and r_corrected (if calculated using the background corrected p and s channel values, as well).
    
    :param correct: Calculate the anisotropy and intensity using the background corrected values of p and s, as well, default=True
    :type correct: bool
    :param plot_i: Displays plots of the percentage intensity against well ids for all repeats, defaults to True
    :type plot_i: bool
    :param th: Percentage intensity value above which the wells id will be reported
    :type th: int
    &#34;&#34;&#34;
    FA.th = thr   # assign the threshold value to the class variable so that it can be accessed outside of this function

    for key, value in self.data_dict.items():   # iterate over all repeats
        metadata, data = value.values()
        
        # calculate raw intensity and anisotropy and add them to data dictionary
        i, r = FA._calc_r_I(data[&#39;p&#39;], data[&#39;s&#39;], self.g_factor, &#39;raw&#39;)
        self.data_dict[key][&#39;data&#39;][&#39;i_raw&#39;] = i   
        self.data_dict[key][&#39;data&#39;][&#39;r_raw&#39;] = r   
        
        if correct:   # calculate intensity and anisotropy using background corrected values of p and s
            if &#39;p_corrected&#39; and &#39;s_corrected&#39; not in data:   # check if background subtraction has been done
                raise AttributeError(&#39;The corrected anisotropy and intensity can only be calculated after background correction of the raw p and s channel data.&#39;)
            
            i_c, r_c = FA._calc_r_I(data[&#39;p_corrected&#39;], data[&#39;s_corrected&#39;], self.g_factor, &#39;corrected&#39;)
            self.data_dict[key][&#39;data&#39;][&#39;i_corrected&#39;] = i_c   
            self.data_dict[key][&#39;data&#39;][&#39;r_corrected&#39;] = r_c    
            
            self.data_dict[key][&#39;data&#39;][&#39;i_percent&#39;] = FA._calc_I_percent(i, i_c, self.plate_map)
    
    print(&#39;The fluorescence intensity and anisotropy have been successfully calculated!\n&#39;)
    
    if plot_i:   # plot the percentage intensity against the well ids for all repeats
        FA._plot_i_percent(self.data_dict, self.plate_map)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.export_params"><code class="name flex">
<span>def <span class="ident">export_params</span></span>(<span>self, path='', file_type='csv')</span>
</code></dt>
<dd>
<div class="desc"><p>Export the final fit parameters and the fitting parameters for each repeat to csv or excel files.</p>
<p>:param path: A path to directory in which the file is saved, defaults to '' (i.e. the same directory as this Jupyter Notebook)
:type path: str
:param file_type: Type of file generated, either 'csv' or 'excel' file, defaults to csv
:type file_type: 'str'</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_params(self, path=&#39;&#39;, file_type=&#39;csv&#39;):
    &#34;&#34;&#34;Export the final fit parameters and the fitting parameters for each repeat to csv or excel files.
    
    :param path: A path to directory in which the file is saved, defaults to &#39;&#39; (i.e. the same directory as this Jupyter Notebook)
    :type path: str
    :param file_type: Type of file generated, either &#39;csv&#39; or &#39;excel&#39; file, defaults to csv
    :type file_type: &#39;str&#39;
    &#34;&#34;&#34;
    if file_type == &#39;csv&#39;:   # export as csv file
        FA.final_fit.to_csv(path_or_buf=f&#34;{path}final_fit_parameters.csv&#34;)
    if file_type == &#39;excel&#39;:   # export as excel file
        FA.final_fit.to_excel(excel_writer=f&#34;{path}final_fit_parameters.xlsx&#34;)

    for key, value in self.data_dict.items():   #iterate over all repeats
        metadata, data = value.values()
        
        if file_type == &#39;csv&#39;:   # export as csv file
            data[&#39;fit_params&#39;].to_csv(path_or_buf=f&#34;{path}{key}_fitting_parameters.csv&#34;)
        if file_type == &#39;excel&#39;:   # export as excel file
            data[&#39;fit_params&#39;].to_excel(excel_writer=f&#34;{path}single_repeat_fitting_parameters.xlsx&#34;, sheet_name=f&#39;{key}&#39;)
    
    print(f&#39;The fitting parameters were exported to the {file_type} files.&#39;)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.import_params"><code class="name flex">
<span>def <span class="ident">import_params</span></span>(<span>self, csv_file)</span>
</code></dt>
<dd>
<div class="desc"><p>Allows to import a csv file with final_fit parameters (i.e. rmin, rmax, lamda, Kd and their errors).</p>
<p>:param csv_file: A csv file path with parameters to be imported
:type csv_file: str</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def import_params(self, csv_file):
    &#34;&#34;&#34;Allows to import a csv file with final_fit parameters (i.e. rmin, rmax, lamda, Kd and their errors).
    
    :param csv_file: A csv file path with parameters to be imported
    :type csv_file: str
    &#34;&#34;&#34;
    with open(csv_file) as file:   # read the csv into pandas df
        df = pd.read_csv(file, sep=&#39;,&#39;, index_col=[0,1], engine=&#39;python&#39;, encoding=&#39;utf-8&#39;)   # import with multiindex
        indexes = list(df.index)   # create a list with protein-tracer names
    
    for col in df.columns:   # iterate over the imported columns
        if col not in FA.final_fit.columns:   # if there is no such column in final_fit df, raise a warning, otherwise column with wrong name will be added to final_fit
            warnings.warn(f&#34;The final_fit data frame does not contain matching columns: &#39;{col}&#39;&#34;)
        else:   # overwrite the existing values in the final_fit df with the ones from imported df
            FA.final_fit.loc[FA.final_fit.index.intersection(indexes), col] = df.loc[df.index.intersection(indexes), col]</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.invalidate"><code class="name flex">
<span>def <span class="ident">invalidate</span></span>(<span>self, valid=False, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Invalidates wells, columns and/or rows. Any of the following arguments, or their combination, can be passed: wells, rows, columns.
For example to invalidate well A1, rows C and D and columns 7 and 8 execute the following: invalidate(wells='A1', rows=['C','D'], columns=[7,8]).
To validate previously invalidated wells, rows and/or columns, pass the additional 'valid' argument as True.</p>
<p>:param valid: Sets the stipulated row or rows 'True' or 'False', default = False
:type valid: bool
:param wells: Wells to be invalidated passed as a string or a list of strings
:type wells: str or list
:param rows: Rows to be invalidated passed as a string or a list of strings
:type rows: str or list
:param columns: Columns to be invalidated passed as an integer or a list of integers
:type columns: int or list</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def invalidate(self, valid=False, **kwargs):
    &#34;&#34;&#34;Invalidates wells, columns and/or rows. Any of the following arguments, or their combination, can be passed: wells, rows, columns. 
    For example to invalidate well A1, rows C and D and columns 7 and 8 execute the following: invalidate(wells=&#39;A1&#39;, rows=[&#39;C&#39;,&#39;D&#39;], columns=[7,8]).
    To validate previously invalidated wells, rows and/or columns, pass the additional &#39;valid&#39; argument as True.

    :param valid: Sets the stipulated row or rows &#39;True&#39; or &#39;False&#39;, default = False
    :type valid: bool
    :param wells: Wells to be invalidated passed as a string or a list of strings
    :type wells: str or list
    :param rows: Rows to be invalidated passed as a string or a list of strings
    :type rows: str or list
    :param columns: Columns to be invalidated passed as an integer or a list of integers
    :type columns: int or list
    &#34;&#34;&#34;
    # execute the corresponding invalidate functon from the platemapping package
    if &#39;wells&#39; in kwargs:
        pm.invalidate_wells(platemap=self.plate_map, wells=kwargs[&#39;wells&#39;], valid=valid)
    if &#39;rows&#39; in kwargs:
        rows = tuple(kwargs[&#39;rows&#39;]) # convert the rows to tuple because invalidate_rows cannot take in a list
        pm.invalidate_rows(platemap=self.plate_map, rows=rows, valid=valid)
    if &#39;columns&#39; in kwargs:
        pm.invalidate_cols(platemap=self.plate_map, cols=kwargs[&#39;columns&#39;], valid=valid)
    if len(kwargs) == 0:   # return error if neither of the keyword arguments is passed
        raise TypeError(&#39;No arguments were passed. Specify the wells, rows and/or columns to be invalidated!&#39;)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.logistic_fit"><code class="name flex">
<span>def <span class="ident">logistic_fit</span></span>(<span>self, prot=['all'], trac=['all'], rep=['all'], var='both', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits a logistic curve to the plot of anisotropy (or intensity) against protein concentration.
Returns the fitting parameters with associated errors for each repeat that are stored in the fitting paramters data frame in data dict.
The calc_data_to_fit function must be executed prior to data fitting.</p>
<p>:param prot: List of protein names for which the graphs will be created, defaults to ['all']
:type prot: list of str
:param trac: List of tracer names for which the graphs will be created, defaults to ['all']
:type trac: list of str
:param rep: List of repeat numbers for which the graphs will be created, defaults to ['all']
:type rep: list of ints
:param var: A variable for which the graphs are exported, can be either 'r' for anisotropy or 'i' for inteensity, defaults to 'both'
:type var: str
:param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def logistic_fit(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], var=&#39;both&#39;, **kwargs):
    &#34;&#34;&#34;Fits a logistic curve to the plot of anisotropy (or intensity) against protein concentration.
    Returns the fitting parameters with associated errors for each repeat that are stored in the fitting paramters data frame in data dict.
    The calc_data_to_fit function must be executed prior to data fitting.
    
    :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
    :type prot: list of str
    :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
    :type trac: list of str
    :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
    :type rep: list of ints
    :param var: A variable for which the graphs are exported, can be either &#39;r&#39; for anisotropy or &#39;i&#39; for inteensity, defaults to &#39;both&#39;
    :type var: str
    :param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function
    &#34;&#34;&#34;
    # get data_dict and a list of protein-tracer names
    data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
    errors = []   # list for storing the details of errors due to failed fitting
    
    for rep, value in data_dict.items():   # iterate over all repeats
        metadata, data = value.values()
        
        for pt_pair in pt_pairs:   # iterate over all protein-tracer pairs
            if var == &#39;r&#39; or var == &#39;both&#39;:
                try:   # try fitting the curve to anisotropy data 
                    r_mean = data[&#39;r_mean&#39;][pt_pair]   # extract the df with mean anisotropy for a given protein-tracer pair
                    params_r = FA._logistic_fit(r_mean, **kwargs)   # fit the data to logistic curve using the initial parameteers
                    data[&#39;fit_params&#39;].loc[pt_pair, [&#39;rmin&#39;,&#39;rmin error&#39;,&#39;rmax&#39;, &#39;rmax error&#39;, &#39;r_EC50&#39;, &#39;r_EC50 error&#39;, &#39;r_hill&#39;, &#39;r_hill error&#39;]] = params_r   # add the fitting parameters to the respective df

                except RuntimeError as e:   # if fitting fails, added details about the error to the errors list and proceed intensity data fitting
                    r_errorinfo = (rep, &#39;r&#39;, pt_pair, e)
                    errors.append(r_errorinfo)
            
            if var == &#39;i&#39; or var == &#39;both&#39;:
                try:   # try fitting the curve to intensity data
                    i_mean = data[&#39;i_mean&#39;][pt_pair]   # extract the df with i mean for a given protein-tracer pair
                    params_i = FA._logistic_fit(i_mean, **kwargs)
                    data[&#39;fit_params&#39;].loc[pt_pair, [&#39;Ifree&#39;, &#39;Ifree error&#39;, &#39;Ibound&#39;,&#39;Ibound error&#39;, &#39;I_EC50&#39;, &#39;I_EC50 error&#39;, &#39;I_hill&#39;, &#39;I_hill error&#39;]] = params_i

                except RuntimeError as e:   # if fitting fails, added details about the error to the errors list and proceed to to the next protein-tracer pair
                    i_errorinfo = (rep, &#39;i&#39;, pt_pair, e)
                    errors.append(i_errorinfo)

    if errors != []:   # raise a warning if fitting failed for any protein-tracer pair
        warnings.warn(f&#34;The curve fitting failed in the following cases:\n\n{errors}\n\nTry passing additional keyword arguments to the fitting function.&#34;, RuntimeWarning)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.plot_ani"><code class="name flex">
<span>def <span class="ident">plot_ani</span></span>(<span>self, prot=['all'], trac=['all'], rep=['all'], err='std')</span>
</code></dt>
<dd>
<div class="desc"><p>Plots anisotropy and intensity against protein concentration with a fitted logistic curve for specific repeats and
protein-tracer pairs. A separate figure for each repeat is created with anisotropy and intensity graphs for all
specified proteins and tracers side by side. </p>
<p>:param prot: List of protein names for which the graphs are created, defaults to ['all']
:type prot: list of str
:param trac: List of tracer names for which the graphs are created, defaults to ['all']
:type trac: list of str
:param rep: List of repeat numbers for which the graphs are created, defaults to ['all']
:type rep: list of ints
:param err: Type of error data displayed as error bars, either standard deviation ('std') or standard error ('sem')
:type err: str</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_ani(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], err=&#39;std&#39;):   
    &#34;&#34;&#34;Plots anisotropy and intensity against protein concentration with a fitted logistic curve for specific repeats and 
    protein-tracer pairs. A separate figure for each repeat is created with anisotropy and intensity graphs for all 
    specified proteins and tracers side by side. 
    
    :param prot: List of protein names for which the graphs are created, defaults to [&#39;all&#39;]
    :type prot: list of str
    :param trac: List of tracer names for which the graphs are created, defaults to [&#39;all&#39;]
    :type trac: list of str
    :param rep: List of repeat numbers for which the graphs are created, defaults to [&#39;all&#39;]
    :type rep: list of ints
    :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
    :type err: str
    &#34;&#34;&#34;
    # get data_dict and a list of protein-tracer names
    data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
    
    for key, value in data_dict.items():   # iterte over all repeats and create a sperate figure for each repeat
        metadata, data = value.values()
        fig, axs = plt.subplots(len(pt_pairs), 2, figsize=(2*6.4, len(pt_pairs)*4.8), tight_layout=True)   # grid for subplots has two columns and a variable number of rows, figsize automatically scales up
        fig.suptitle(f&#34;Repeat {key[-1]}&#34;, fontsize=16)

        for idx, pt_pair in enumerate(pt_pairs):   # for each portein-tracer pair plot two graphs: anisotropy and intensity
            r_data_df = data[&#39;r_mean&#39;][pt_pair]   # extract the df with anisotropy
            i_data_df = data[&#39;i_mean&#39;][pt_pair]   # and intensity
            
            if len(pt_pairs) == 1:   # for only one protein-tracer pair the subplot grid 1-dimensional
                FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[0], err=err, var=&#39;r&#39;, rep=key, export=False, display=True, labels=True)
                FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[1], err=err, var=&#39;i&#39;, rep=key, export=False, display=True, labels=True)
            else:   # for more than one protein-tracer pair the subplot grid 2-dimensional
                FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[idx,0], err=err, var=&#39;r&#39;, rep=key, export=False, display=True, labels=True)
                FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig, axs=axs[idx,1], err=err, var=&#39;i&#39;, rep=key, export=False, display=True, labels=True)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.plot_i_percent"><code class="name flex">
<span>def <span class="ident">plot_i_percent</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This function only displays the results calculated by the calculate_r_i function and does not recalculate it.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_i_percent(self):
    &#34;&#34;&#34;This function only displays the results calculated by the calculate_r_i function and does not recalculate it.&#34;&#34;&#34;
    return FA._plot_i_percent(self.data_dict, self.plate_map)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.plot_kd"><code class="name flex">
<span>def <span class="ident">plot_kd</span></span>(<span>self, prot=['all'], trac=['all'], rep=['all'], err='std', overlay=False, legend=True, export=False, dpi=250)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots the concentration of fluorescent tracer bound to target protein against the protein (or tracer) concentration.</p>
<p>:param prot: List of protein names for which the graphs will be created, defaults to ['all']
:type prot: list of str
:param trac: List of tracer names for which the graphs will be created, defaults to ['all']
:type trac: list of str
:param rep: List of repeat numbers for which the graphs will be created, defaults to ['all']
:type rep: list of ints
:param err: Type of error data displayed as error bars, either standard deviation ('std') or standard error ('sem')
:type err: str
:param overlay: Overlayes the data on a single figure, defaults to False
:type overlay: bool
:param legend: Display the figure title and legend, defaults to True
:type legend: bool
:param export: Saves the figures as png files in the same location as the Notebook or in a specified directory
:type export: bool or str
:param dpi: Resolution of the exported figure in dots per inches
:type dpi: int</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_kd(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], err=&#39;std&#39;, overlay=False, legend=True, export=False, dpi=250):   
    &#34;&#34;&#34;Plots the concentration of fluorescent tracer bound to target protein against the protein (or tracer) concentration.
    
    :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
    :type prot: list of str
    :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
    :type trac: list of str
    :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
    :type rep: list of ints
    :param err: Type of error data displayed as error bars, either standard deviation (&#39;std&#39;) or standard error (&#39;sem&#39;)
    :type err: str
    :param overlay: Overlayes the data on a single figure, defaults to False
    :type overlay: bool
    :param legend: Display the figure title and legend, defaults to True
    :type legend: bool
    :param export: Saves the figures as png files in the same location as the Notebook or in a specified directory
    :type export: bool or str
    :param dpi: Resolution of the exported figure in dots per inches
    :type dpi: int
    &#34;&#34;&#34;
    data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
    
    if overlay == False:
        for key, value in data_dict.items():   # iterte through all repeats of the defined data_dict
            metadata, data = value.values()

            for pt_pair in pt_pairs:    # iterate through the list of protein-tracer names to create a separate figure for each pair
                data_df = data[&#39;amount_bound&#39;][pt_pair]   # extract the correct df with amount bound for a given protein-tracer pair
                FA._plot_kd(data_df=data_df, rep=key, pt_pair=pt_pair, err=err, leg=legend, exp=export, dpi=dpi)
    else:
        FA._overlay_kd_plots(plate_map=self.plate_map, data_dict=data_dict, pt_pairs=pt_pairs, err=err, leg=legend, exp=export, dpi=dpi)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.save_ani_figs"><code class="name flex">
<span>def <span class="ident">save_ani_figs</span></span>(<span>self, prot=['all'], trac=['all'], rep=['all'], var='both', path='', err='std', leg=False, dpi=250)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves single figures of anisotropy and intensity for each protein-tracer pair for all repeats in the same directory as this notebook or
in user defined directory if the path is provided.</p>
<p>:param prot: List of protein names for which the graphs are exported, defaults to ['all']
:type prot: list of str
:param trac: List of tracer names for which the graphs are exported, defaults to ['all']
:type trac: list of str
:param rep: List of repeat numbers for which the graphs are exported, defaults to ['all']
:type rep: list of ints
:param var: A variable for which the graphs are exported, can be either 'r' for anisotropy or 'i' for inteensity, defaults to 'both'
:type var: str
:param path: A path to directory in which the figures are saved, defaults to '' (the same directory as the Jupyter Notebook)
:type path: str
:param err: A string representing type of error data to displayed as error bars, either 'std' or 'sem', default 'std'
:type err: str
:param leg: Display legend on the figures, defaults to False
:type leg: bool
:param dpi: Resolution of the figure in points per inch
:type dpi: int</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_ani_figs(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], var=&#39;both&#39;, path=&#39;&#39;, err=&#39;std&#39;, leg=False, dpi=250):
    &#34;&#34;&#34;Saves single figures of anisotropy and intensity for each protein-tracer pair for all repeats in the same directory as this notebook or
    in user defined directory if the path is provided.
    
    :param prot: List of protein names for which the graphs are exported, defaults to [&#39;all&#39;]
    :type prot: list of str
    :param trac: List of tracer names for which the graphs are exported, defaults to [&#39;all&#39;]
    :type trac: list of str
    :param rep: List of repeat numbers for which the graphs are exported, defaults to [&#39;all&#39;]
    :type rep: list of ints
    :param var: A variable for which the graphs are exported, can be either &#39;r&#39; for anisotropy or &#39;i&#39; for inteensity, defaults to &#39;both&#39;
    :type var: str
    :param path: A path to directory in which the figures are saved, defaults to &#39;&#39; (the same directory as the Jupyter Notebook)
    :type path: str
    :param err: A string representing type of error data to displayed as error bars, either &#39;std&#39; or &#39;sem&#39;, default &#39;std&#39;
    :type err: str
    :param leg: Display legend on the figures, defaults to False
    :type leg: bool
    :param dpi: Resolution of the figure in points per inch
    :type dpi: int
    &#34;&#34;&#34;
    # get data_dict and a list of protein-tracer names
    data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
    
    for key, value in self.data_dict.items():   # iterate over all repeats
        metadata, data = value.values()
        pairs = list(data[&#39;r_mean&#39;].keys())   # generate a list of protein-tracer names
                            
        for pt_pair in pairs:   # iterate over each protein-tracer pair in
            if var == &#39;r&#39; or var == &#39;both&#39;:
                r_data_df = data[&#39;r_mean&#39;][pt_pair]   # extract the df with anisotropy
                fig_r, ax_r = plt.subplots(figsize=(6.4, 4.8), tight_layout=True)   # create a figure with a single axis for anisotropy 
                FA._plot_ani(data_df=r_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig_r, axs=ax_r, err=err, var=&#39;r&#39;, rep=key, export=path, display=False, labels=leg, dpi=dpi)
            
            if var == &#39;i&#39; or var == &#39;both&#39;:
                i_data_df = data[&#39;i_mean&#39;][pt_pair]   
                fig_i, ax_i = plt.subplots(figsize=(6.4, 4.8), tight_layout=True)   
                FA._plot_ani(data_df=i_data_df, params_df=data[&#39;fit_params&#39;], pt_pair=pt_pair, fig=fig_i, axs=ax_i, err=err, var=&#39;i&#39;, rep=key, export=path, display=False, labels=leg, dpi=dpi)
    
    print(&#39;The figures were successfully exported.&#39;)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.set_fitparams"><code class="name flex">
<span>def <span class="ident">set_fitparams</span></span>(<span>self, pair, final=True, rep=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Allows to set a value of any parameter in the final fit data frame (by default) or in fit_params data frame
for a specific protein-tracer pair.</p>
<p>:param pair: A tuple wtih protein and tracer names for which the parameters are changed
:type pair: tuple
:param final: If True, the parameters will be changed in the final_fit data frame, otherwise in the fitting param data frame
:type final: bool
:param rep: Repeat number for which the fit_params data frame will be modified, passed only if the final=False, defaults to None
:type rep: int
:param **kwargs: Keyword arguments represeting the parameter and its value, e.g. lambda=1.5, rmin=0.30</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_fitparams(self, pair, final=True, rep=None, **kwargs):
    &#34;&#34;&#34;Allows to set a value of any parameter in the final fit data frame (by default) or in fit_params data frame 
    for a specific protein-tracer pair.
    
    :param pair: A tuple wtih protein and tracer names for which the parameters are changed
    :type pair: tuple
    :param final: If True, the parameters will be changed in the final_fit data frame, otherwise in the fitting param data frame
    :type final: bool
    :param rep: Repeat number for which the fit_params data frame will be modified, passed only if the final=False, defaults to None
    :type rep: int
    :param **kwargs: Keyword arguments represeting the parameter and its value, e.g. lambda=1.5, rmin=0.30
    &#34;&#34;&#34;
    if final == True:
        for key, value in kwargs.items():   # iterate over the kwargs dictionary
            FA.final_fit.loc[pair, key] = value   # overwrite the parameters in fitting params df with all params passed as keyword arguments
    
    if final == False: 
        for key, value in kwargs.items():   # iterate over the kwargs dictionary
            self.data_dict[f&#39;repeat_{rep}&#39;][&#39;data&#39;][&#39;fit_params&#39;].loc[pair, key] = value   # overwrite the parameters in fitting params df with all params passed as keyword arguments</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.single_site_fit"><code class="name flex">
<span>def <span class="ident">single_site_fit</span></span>(<span>self, prot=['all'], trac=['all'], rep=['all'], **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits a curve to the plot of concentration of fluorescent tracer bound to the target protein against the
total protein concentration. </p>
<p>:param prot: List of protein names for which the graphs will be created, defaults to ['all']
:type prot: list of str
:param trac: List of tracer names for which the graphs will be created, defaults to ['all']
:type trac: list of str
:param rep: List of repeat numbers for which the graphs will be created, defaults to ['all']
:type rep: list of ints
:param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def single_site_fit(self, prot=[&#39;all&#39;], trac=[&#39;all&#39;], rep=[&#39;all&#39;], **kwargs):
    &#34;&#34;&#34;Fits a curve to the plot of concentration of fluorescent tracer bound to the target protein against the 
    total protein concentration. 
    
    :param prot: List of protein names for which the graphs will be created, defaults to [&#39;all&#39;]
    :type prot: list of str
    :param trac: List of tracer names for which the graphs will be created, defaults to [&#39;all&#39;]
    :type trac: list of str
    :param rep: List of repeat numbers for which the graphs will be created, defaults to [&#39;all&#39;]
    :type rep: list of ints
    :param **kwargs: Keyword arguments that can be passed to the SciPy curve_fit function
    &#34;&#34;&#34;
    # get data_dict and a list of protein-tracer names
    data_dict, pt_pairs = FA._get_items_to_plot(self.data_dict, self.plate_map, prot, trac, rep)
    errors = []   # list for storing the details of errors due to failed fitting
    
    if &#39;sigma&#39; in kwargs:  
        sigma = drop[kwargs.pop(&#39;sigma&#39;)]   # take the column with std or sem error data
    else:
        sigma = None
    
    for rep, value in data_dict.items():   # iterate over all repeats
        metadata, data = value.values()
        keys = list(data[&#39;amount_bound&#39;].keys())   # create a list of unique protein-tracer pairs
        
        for pt_pair in pt_pairs:   # iterate over all protein-tracer pairs
            try:   # try fitting the curve to anisotropy data 
                amount_b = data[&#39;amount_bound&#39;][pt_pair]   # extract the df with mean amount bound for a given protein-tracer pair
                drop = amount_b[ (amount_b[&#39;Protein Concentration&#39;] != 0) &amp; (amount_b[&#39;Tracer Concentration&#39;] != 0)].dropna(subset=[&#39;amount&#39;])   # exclude the protein concentration = 0 point and any NaNs from data fitting
                
                if len(drop[&#39;Tracer Concentration&#39;].dropna().unique()) == 1:   # check if the protein is titrated to a constant amount of tracer
                    x_data, label = drop[&#39;Protein Concentration&#39;], [&#39;LT&#39;, &#39;LT error&#39;]   
                if len(drop[&#39;Protein Concentration&#39;].dropna().unique()) == 1:   # check if the tracer is titrated to a constant amount of protein
                    x_data, label = drop[&#39;Tracer Concentration&#39;], [&#39;PT&#39;, &#39;PT error&#39;]
                
                popt, pcov = curve_fit(FA._LB, x_data, drop[&#39;amount&#39;], sigma=sigma, **kwargs)
                err = np.sqrt(np.diag(pcov))
                FA.final_fit.loc[pt_pair, ([&#39;Kd&#39;, &#39;Kd error&#39;]+label)] = [popt[1], err[1], popt[0], err[0]]   # add Kd and its error to final fit df
                
            except RuntimeError as e:  
                error_info = (rep, pt_pair, e)
                errors.append(error_info)
            
    if errors != []:   # raise a warning if fitting failed for any protein-tracer pair
        warnings.warn(f&#34;The curve fitting failed in the following cases:\n\n{errors}\n\nTry passing additional keyword arguments to the fitting function&#34;, RuntimeWarning)</code></pre>
</details>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.FA.visualise"><code class="name flex">
<span>def <span class="ident">visualise</span></span>(<span>self, colorby='Type', labelby='Type', title='', cmap='Paired', dpi=250, export=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a visual representation of the plate map.
The label and colour for each well can be customised to be a variable, for example 'Type', 'Protein Name', 'Protein Concentration', etc.
It can also be the p or s anisotropy value from a specified repeat passed as a tuple of strings, for example ('repeat_2', 'p') for p data from repeat 2</p>
<p>:param colorby: Chooses the parameter to color code by, for example 'Type', 'Contents', 'Protein Concentration', ('repeat_2', 'p'), default = 'Type'
:type colorby: str or tuple
:param labelby: Chooses the parameter to label code by, for example 'Type', 'Contents', 'Protein', ('repeat_1', 's'), default = 'Type'
:type labelby: str or tuple
:param title: Sets the title of the figure, default none
:type title: str
:param cmap: Sets the colormap for the color-coding, default = 'Paired'
:type cmap: str
:param dpi: Size of the figure, default = 250
:type dpi: int
:param export: If 'True' a .png file of the figure is saved, default = False
:type export: bool
:return: Visual representation of the plate map.
:rtype: figure</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualise(self, colorby=&#39;Type&#39;, labelby=&#39;Type&#39;, title=&#34;&#34;, cmap=&#39;Paired&#39;, dpi=250, export=False):
    &#34;&#34;&#34;Returns a visual representation of the plate map.
    The label and colour for each well can be customised to be a variable, for example &#39;Type&#39;, &#39;Protein Name&#39;, &#39;Protein Concentration&#39;, etc.
    It can also be the p or s anisotropy value from a specified repeat passed as a tuple of strings, for example (&#39;repeat_2&#39;, &#39;p&#39;) for p data from repeat 2
    
    :param colorby: Chooses the parameter to color code by, for example &#39;Type&#39;, &#39;Contents&#39;, &#39;Protein Concentration&#39;, (&#39;repeat_2&#39;, &#39;p&#39;), default = &#39;Type&#39;
    :type colorby: str or tuple
    :param labelby: Chooses the parameter to label code by, for example &#39;Type&#39;, &#39;Contents&#39;, &#39;Protein&#39;, (&#39;repeat_1&#39;, &#39;s&#39;), default = &#39;Type&#39;
    :type labelby: str or tuple
    :param title: Sets the title of the figure, default none
    :type title: str
    :param cmap: Sets the colormap for the color-coding, default = &#39;Paired&#39;
    :type cmap: str
    :param dpi: Size of the figure, default = 250
    :type dpi: int
    :param export: If &#39;True&#39; a .png file of the figure is saved, default = False
    :type export: bool
    :return: Visual representation of the plate map.
    :rtype: figure
    &#34;&#34;&#34;
    plate_map = self.plate_map
    size = plate_map.shape[0]
    scinot = False
    str_len = None
    
    if type(labelby) == tuple:   # option for labelling by the p or s anisotropy values
        plate_map = self.plate_map.join(self.data_dict[labelby[0]][&#39;data&#39;][labelby[1]])   # data frame containing p or s values from specified repeat is added to the platemap
        labelby = labelby[1]
    if type(colorby) == tuple:   # option for colouring by the p or s anisotropy values
        plate_map = plate_map.join(self.data_dict[colorby[0]][&#39;data&#39;][colorby[1]])
        colorby = colorby[1]
        
    if labelby in [&#39;Protein Concentration&#39;, &#39;Tracer Concentration&#39;, &#39;Competitor Concentration&#39;, &#39;p&#39;, &#39;s&#39;, &#39;p_corrected&#39;, &#39;s_corrected&#39;, &#39;r_raw&#39;, &#39;r_corrected&#39;, &#39;i_raw&#39; , &#39;i_corrected&#39;]:
        if sum((plate_map[labelby] &gt; 1000) | (plate_map[labelby] &lt; 0)) &gt; 0:   # display in sci notation if the number is greater than 1000 or less than 0
            scinot = True
            str_len = 8
    
    return pm.visualise(platemap=plate_map, title=title, size=size, export=export, cmap=cmap, colorby=colorby, labelby=labelby, dpi=dpi, scinot=scinot, str_len=str_len)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="flu_ani_analysis.flu_ani_analysis_module.PlateSizeError"><code class="flex name class">
<span>class <span class="ident">PlateSizeError</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all non-exit exceptions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PlateSizeError(Exception):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="flu_ani_analysis" href="index.html">flu_ani_analysis</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="flu_ani_analysis.flu_ani_analysis_module.DataError" href="#flu_ani_analysis.flu_ani_analysis_module.DataError">DataError</a></code></h4>
</li>
<li>
<h4><code><a title="flu_ani_analysis.flu_ani_analysis_module.DataTypeError" href="#flu_ani_analysis.flu_ani_analysis_module.DataTypeError">DataTypeError</a></code></h4>
</li>
<li>
<h4><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA" href="#flu_ani_analysis.flu_ani_analysis_module.FA">FA</a></code></h4>
<ul class="two-column">
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.background_correct" href="#flu_ani_analysis.flu_ani_analysis_module.FA.background_correct">background_correct</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.calc_amountbound" href="#flu_ani_analysis.flu_ani_analysis_module.FA.calc_amountbound">calc_amountbound</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.calc_data_to_fit" href="#flu_ani_analysis.flu_ani_analysis_module.FA.calc_data_to_fit">calc_data_to_fit</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.calc_lambda" href="#flu_ani_analysis.flu_ani_analysis_module.FA.calc_lambda">calc_lambda</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.calculate_r_i" href="#flu_ani_analysis.flu_ani_analysis_module.FA.calculate_r_i">calculate_r_i</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.export_params" href="#flu_ani_analysis.flu_ani_analysis_module.FA.export_params">export_params</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.import_params" href="#flu_ani_analysis.flu_ani_analysis_module.FA.import_params">import_params</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.invalidate" href="#flu_ani_analysis.flu_ani_analysis_module.FA.invalidate">invalidate</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.logistic_fit" href="#flu_ani_analysis.flu_ani_analysis_module.FA.logistic_fit">logistic_fit</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.plot_ani" href="#flu_ani_analysis.flu_ani_analysis_module.FA.plot_ani">plot_ani</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.plot_i_percent" href="#flu_ani_analysis.flu_ani_analysis_module.FA.plot_i_percent">plot_i_percent</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.plot_kd" href="#flu_ani_analysis.flu_ani_analysis_module.FA.plot_kd">plot_kd</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.read_in_envision" href="#flu_ani_analysis.flu_ani_analysis_module.FA.read_in_envision">read_in_envision</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.save_ani_figs" href="#flu_ani_analysis.flu_ani_analysis_module.FA.save_ani_figs">save_ani_figs</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.set_fitparams" href="#flu_ani_analysis.flu_ani_analysis_module.FA.set_fitparams">set_fitparams</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.single_site_fit" href="#flu_ani_analysis.flu_ani_analysis_module.FA.single_site_fit">single_site_fit</a></code></li>
<li><code><a title="flu_ani_analysis.flu_ani_analysis_module.FA.visualise" href="#flu_ani_analysis.flu_ani_analysis_module.FA.visualise">visualise</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="flu_ani_analysis.flu_ani_analysis_module.PlateSizeError" href="#flu_ani_analysis.flu_ani_analysis_module.PlateSizeError">PlateSizeError</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>